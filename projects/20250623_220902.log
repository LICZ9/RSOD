2025/06/23 22:09:03 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.21 (main, Dec 11 2024, 16:24:11) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1638902711
    GPU 0,1: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.0, V11.0.221
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
    PyTorch: 2.0.0
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.15.2a0
    OpenCV: 4.11.0
    MMEngine: 0.10.6

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1638902711
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/06/23 22:09:07 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16)
backend_args = None
batch_size = 5
branch_field = [
    'sup',
    'unsup_teacher',
    'unsup_student',
]
color_space = [
    [
        dict(type='ColorTransform'),
    ],
    [
        dict(type='AutoContrast'),
    ],
    [
        dict(type='Equalize'),
    ],
    [
        dict(type='Sharpness'),
    ],
    [
        dict(type='Posterize'),
    ],
    [
        dict(type='Solarize'),
    ],
    [
        dict(type='Color'),
    ],
    [
        dict(type='Contrast'),
    ],
    [
        dict(type='Brightness'),
    ],
]
custom_hooks = [
    dict(gamma=4, momentum=0.0002, type='MeanTeacherHook'),
]
custom_imports = dict(
    allow_failed_imports=False,
    imports=[
        'projects.MixPL.mixpl',
        'mmdet.models.losses.reliability_aware_L1_loss',
        'mmdet.models.losses.reliability_aware_loss',
        'projects.MixPL.models.necks.fine_grained_fpn',
    ])
data_root = '/sharefiles2/lichengzhou/datasets/oursonar/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=20000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
detector = dict(
    backbone=dict(
        depth=50,
        frozen_stages=1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='BN'),
        norm_eval=True,
        num_stages=4,
        out_indices=(3, ),
        style='pytorch',
        type='ResNet'),
    bbox_head=dict(
        embed_dims=256,
        loss_bbox=dict(loss_weight=5.0, type='L1Loss'),
        loss_cls=dict(
            bg_cls_weight=0.1,
            class_weight=1.0,
            loss_weight=1.0,
            type='CrossEntropyLoss',
            use_sigmoid=False),
        loss_iou=dict(loss_weight=2.0, type='GIoULoss'),
        num_classes=10,
        type='DETRHead'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            103.53,
            116.28,
            123.675,
        ],
        pad_size_divisor=1,
        std=[
            1.0,
            1.0,
            1.0,
        ],
        type='DetDataPreprocessor'),
    decoder=dict(
        layer_cfg=dict(
            cross_attn_cfg=dict(
                batch_first=True, dropout=0.1, embed_dims=256, num_heads=8),
            ffn_cfg=dict(
                act_cfg=dict(inplace=True, type='ReLU'),
                embed_dims=256,
                feedforward_channels=2048,
                ffn_drop=0.1,
                num_fcs=2),
            self_attn_cfg=dict(
                batch_first=True, dropout=0.1, embed_dims=256, num_heads=8)),
        num_layers=6),
    encoder=dict(
        layer_cfg=dict(
            ffn_cfg=dict(
                act_cfg=dict(inplace=True, type='ReLU'),
                embed_dims=256,
                feedforward_channels=2048,
                ffn_drop=0.1,
                num_fcs=2),
            self_attn_cfg=dict(
                batch_first=True, dropout=0.1, embed_dims=256, num_heads=8)),
        num_layers=6),
    neck=dict(
        act_cfg=None,
        in_channels=[
            2048,
        ],
        kernel_size=1,
        norm_cfg=None,
        num_outs=1,
        out_channels=256,
        type='ChannelMapper'),
    num_queries=100,
    positional_encoding=dict(normalize=True, num_feats=128),
    test_cfg=dict(max_per_img=100),
    train_cfg=dict(
        assigner=dict(
            match_costs=[
                dict(type='ClassificationCost', weight=1.0),
                dict(box_format='xywh', type='BBoxL1Cost', weight=5.0),
                dict(iou_mode='giou', type='IoUCost', weight=2.0),
            ],
            type='HungarianAssigner')),
    type='DETR')
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
geometric = [
    [
        dict(type='Rotate'),
    ],
    [
        dict(type='ShearX'),
    ],
    [
        dict(type='ShearY'),
    ],
    [
        dict(type='TranslateX'),
    ],
    [
        dict(type='TranslateY'),
    ],
]
labeled_dataset = dict(
    ann_file='annotations/instances_05train.json',
    data_prefix=dict(img='train/'),
    data_root='/sharefiles2/lichengzhou/datasets/oursonar/',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    metainfo=dict(
        classes=(
            'Pot',
            'Steel Frame',
            'Block',
            'Tire',
            'Steel Plate',
            'Concrete Column',
            'Underwater Robot',
            'SquareCage',
            'Circle Cage',
            'Diver',
        ),
        palette=[
            (
                220,
                20,
                60,
            ),
            (
                119,
                11,
                32,
            ),
            (
                0,
                0,
                142,
            ),
            (
                0,
                0,
                230,
            ),
            (
                106,
                0,
                228,
            ),
            (
                0,
                60,
                100,
            ),
            (
                0,
                80,
                100,
            ),
            (
                0,
                0,
                70,
            ),
            (
                0,
                0,
                192,
            ),
            (
                250,
                170,
                30,
            ),
        ]),
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations', with_bbox=True),
        dict(
            keep_ratio=True,
            scale=[
                (
                    1333,
                    400,
                ),
                (
                    1333,
                    1200,
                ),
            ],
            type='RandomResize'),
        dict(prob=0.5, type='RandomFlip'),
        dict(
            aug_num=1,
            aug_space=[
                [
                    dict(type='ColorTransform'),
                ],
                [
                    dict(type='AutoContrast'),
                ],
                [
                    dict(type='Equalize'),
                ],
                [
                    dict(type='Sharpness'),
                ],
                [
                    dict(type='Posterize'),
                ],
                [
                    dict(type='Solarize'),
                ],
                [
                    dict(type='Color'),
                ],
                [
                    dict(type='Contrast'),
                ],
                [
                    dict(type='Brightness'),
                ],
            ],
            type='RandAugment'),
        dict(min_gt_bbox_wh=(
            0.01,
            0.01,
        ), type='FilterAnnotations'),
        dict(
            branch_field=[
                'sup',
                'unsup_teacher',
                'unsup_student',
            ],
            sup=dict(type='PackDetInputs'),
            type='MultiBranch'),
    ],
    type='CocoDataset')
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False, type='LogProcessor', window_size=50)
metainfo = dict(
    classes=(
        'Pot',
        'Steel Frame',
        'Block',
        'Tire',
        'Steel Plate',
        'Concrete Column',
        'Underwater Robot',
        'SquareCage',
        'Circle Cage',
        'Diver',
    ),
    palette=[
        (
            220,
            20,
            60,
        ),
        (
            119,
            11,
            32,
        ),
        (
            0,
            0,
            142,
        ),
        (
            0,
            0,
            230,
        ),
        (
            106,
            0,
            228,
        ),
        (
            0,
            60,
            100,
        ),
        (
            0,
            80,
            100,
        ),
        (
            0,
            0,
            70,
        ),
        (
            0,
            0,
            192,
        ),
        (
            250,
            170,
            30,
        ),
    ])
model = dict(
    data_preprocessor=dict(
        data_preprocessor=dict(
            bgr_to_rgb=True,
            mean=[
                103.53,
                116.28,
                123.675,
            ],
            pad_size_divisor=1,
            std=[
                1.0,
                1.0,
                1.0,
            ],
            type='DetDataPreprocessor'),
        type='MultiBranchDataPreprocessor'),
    detector=dict(
        backbone=dict(
            depth=50,
            frozen_stages=1,
            init_cfg=dict(
                checkpoint='torchvision://resnet50', type='Pretrained'),
            norm_cfg=dict(requires_grad=False, type='BN'),
            norm_eval=True,
            num_stages=4,
            out_indices=(3, ),
            style='pytorch',
            type='ResNet'),
        bbox_head=dict(
            embed_dims=256,
            loss_bbox=dict(loss_weight=5.0, type='L1Loss'),
            loss_cls=dict(
                bg_cls_weight=0.1,
                class_weight=1.0,
                loss_weight=1.0,
                type='CrossEntropyLoss',
                use_sigmoid=False),
            loss_iou=dict(loss_weight=2.0, type='GIoULoss'),
            num_classes=10,
            type='DETRHead'),
        data_preprocessor=dict(
            bgr_to_rgb=True,
            mean=[
                103.53,
                116.28,
                123.675,
            ],
            pad_size_divisor=1,
            std=[
                1.0,
                1.0,
                1.0,
            ],
            type='DetDataPreprocessor'),
        decoder=dict(
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    batch_first=True, dropout=0.1, embed_dims=256,
                    num_heads=8),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.1,
                    num_fcs=2),
                self_attn_cfg=dict(
                    batch_first=True, dropout=0.1, embed_dims=256,
                    num_heads=8)),
            num_layers=6),
        encoder=dict(
            layer_cfg=dict(
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.1,
                    num_fcs=2),
                self_attn_cfg=dict(
                    batch_first=True, dropout=0.1, embed_dims=256,
                    num_heads=8)),
            num_layers=6),
        neck=dict(
            act_cfg=None,
            in_channels=[
                2048,
            ],
            kernel_size=1,
            norm_cfg=None,
            num_outs=1,
            out_channels=256,
            type='ChannelMapper'),
        num_queries=100,
        positional_encoding=dict(normalize=True, num_feats=128),
        test_cfg=dict(max_per_img=100),
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='ClassificationCost', weight=1.0),
                    dict(box_format='xywh', type='BBoxL1Cost', weight=5.0),
                    dict(iou_mode='giou', type='IoUCost', weight=2.0),
                ],
                type='HungarianAssigner')),
        type='DETR'),
    semi_test_cfg=dict(predict_on='teacher'),
    semi_train_cfg=dict(
        cache_size=8,
        cls_pseudo_thr=0.1,
        compile=True,
        erase=True,
        erase_patches=(
            1,
            20,
        ),
        erase_ratio=(
            0,
            0.1,
        ),
        erase_thr=0.7,
        freeze_teacher=True,
        least_num=1,
        max_iters=240000,
        max_scale=1.2,
        min_pseudo_bbox_wh=(
            0.01,
            0.01,
        ),
        min_scale=0.8,
        mixup=True,
        mosaic=True,
        mosaic_shape=[
            (
                400,
                400,
            ),
            (
                800,
                800,
            ),
        ],
        mosaic_weight=0.5,
        sup_weight=1.0,
        temp=0.2,
        unsup_weight=2.0),
    type='MixPL')
num_workers = 5
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.1, norm_type=2),
    optimizer=dict(lr=0.0001, type='AdamW', weight_decay=0.0001),
    paramwise_cfg=dict(
        custom_keys=dict(backbone=dict(decay_mult=1.0, lr_mult=0.1))),
    type='OptimWrapper')
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=5000,
        start_factor=0.0001,
        type='LinearLR'),
    dict(
        begin=500,
        by_epoch=False,
        end=240000,
        gamma=0.1,
        milestones=[
            160000,
        ],
        type='MultiStepLR'),
]
resume = False
scale = [
    (
        1333,
        400,
    ),
    (
        1333,
        1200,
    ),
]
strong_pipeline = [
    dict(
        keep_ratio=True,
        scale=[
            (
                1333,
                400,
            ),
            (
                1333,
                1200,
            ),
        ],
        type='RandomResize'),
    dict(prob=0.5, type='RandomFlip'),
    dict(
        transforms=[
            dict(
                aug_num=1,
                aug_space=[
                    [
                        dict(type='ColorTransform'),
                    ],
                    [
                        dict(type='AutoContrast'),
                    ],
                    [
                        dict(type='Equalize'),
                    ],
                    [
                        dict(type='Sharpness'),
                    ],
                    [
                        dict(type='Posterize'),
                    ],
                    [
                        dict(type='Solarize'),
                    ],
                    [
                        dict(type='Color'),
                    ],
                    [
                        dict(type='Contrast'),
                    ],
                    [
                        dict(type='Brightness'),
                    ],
                ],
                type='RandAugment'),
            dict(
                aug_num=1,
                aug_space=[
                    [
                        dict(type='Rotate'),
                    ],
                    [
                        dict(type='ShearX'),
                    ],
                    [
                        dict(type='ShearY'),
                    ],
                    [
                        dict(type='TranslateX'),
                    ],
                    [
                        dict(type='TranslateY'),
                    ],
                ],
                type='RandAugment'),
        ],
        type='RandomOrder'),
    dict(min_gt_bbox_wh=(
        0.01,
        0.01,
    ), type='FilterAnnotations'),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
            'flip',
            'flip_direction',
            'homography_matrix',
        ),
        type='PackDetInputs'),
]
sup_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        keep_ratio=True,
        scale=[
            (
                1333,
                400,
            ),
            (
                1333,
                1200,
            ),
        ],
        type='RandomResize'),
    dict(prob=0.5, type='RandomFlip'),
    dict(
        aug_num=1,
        aug_space=[
            [
                dict(type='ColorTransform'),
            ],
            [
                dict(type='AutoContrast'),
            ],
            [
                dict(type='Equalize'),
            ],
            [
                dict(type='Sharpness'),
            ],
            [
                dict(type='Posterize'),
            ],
            [
                dict(type='Solarize'),
            ],
            [
                dict(type='Color'),
            ],
            [
                dict(type='Contrast'),
            ],
            [
                dict(type='Brightness'),
            ],
        ],
        type='RandAugment'),
    dict(min_gt_bbox_wh=(
        0.01,
        0.01,
    ), type='FilterAnnotations'),
    dict(
        branch_field=[
            'sup',
            'unsup_teacher',
            'unsup_student',
        ],
        sup=dict(type='PackDetInputs'),
        type='MultiBranch'),
]
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='annotations/instances_val.json',
        backend_args=None,
        data_prefix=dict(img='val/'),
        data_root='/sharefiles2/lichengzhou/datasets/oursonar/',
        metainfo=dict(
            classes=(
                'Pot',
                'Steel Frame',
                'Block',
                'Tire',
                'Steel Plate',
                'Concrete Column',
                'Underwater Robot',
                'SquareCage',
                'Circle Cage',
                'Diver',
            ),
            palette=[
                (
                    220,
                    20,
                    60,
                ),
                (
                    119,
                    11,
                    32,
                ),
                (
                    0,
                    0,
                    142,
                ),
                (
                    0,
                    0,
                    230,
                ),
                (
                    106,
                    0,
                    228,
                ),
                (
                    0,
                    60,
                    100,
                ),
                (
                    0,
                    80,
                    100,
                ),
                (
                    0,
                    0,
                    70,
                ),
                (
                    0,
                    0,
                    192,
                ),
                (
                    250,
                    170,
                    30,
                ),
            ]),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file=
    '/sharefiles2/lichengzhou/datasets/oursonar/annotations/instances_val.json',
    format_only=False,
    metric='bbox',
    type='CocoMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        1333,
        800,
    ), type='Resize'),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
train_cfg = dict(
    max_iters=240000, type='IterBasedTrainLoop', val_interval=4000)
train_dataloader = dict(
    batch_size=4,
    dataset=dict(
        datasets=[
            dict(
                ann_file='annotations/instances_05train.json',
                data_prefix=dict(img='train/'),
                data_root='/sharefiles2/lichengzhou/datasets/oursonar/',
                filter_cfg=dict(filter_empty_gt=True, min_size=32),
                metainfo=dict(
                    classes=(
                        'Pot',
                        'Steel Frame',
                        'Block',
                        'Tire',
                        'Steel Plate',
                        'Concrete Column',
                        'Underwater Robot',
                        'SquareCage',
                        'Circle Cage',
                        'Diver',
                    ),
                    palette=[
                        (
                            220,
                            20,
                            60,
                        ),
                        (
                            119,
                            11,
                            32,
                        ),
                        (
                            0,
                            0,
                            142,
                        ),
                        (
                            0,
                            0,
                            230,
                        ),
                        (
                            106,
                            0,
                            228,
                        ),
                        (
                            0,
                            60,
                            100,
                        ),
                        (
                            0,
                            80,
                            100,
                        ),
                        (
                            0,
                            0,
                            70,
                        ),
                        (
                            0,
                            0,
                            192,
                        ),
                        (
                            250,
                            170,
                            30,
                        ),
                    ]),
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations', with_bbox=True),
                    dict(
                        keep_ratio=True,
                        scale=[
                            (
                                1333,
                                400,
                            ),
                            (
                                1333,
                                1200,
                            ),
                        ],
                        type='RandomResize'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(
                        aug_num=1,
                        aug_space=[
                            [
                                dict(type='ColorTransform'),
                            ],
                            [
                                dict(type='AutoContrast'),
                            ],
                            [
                                dict(type='Equalize'),
                            ],
                            [
                                dict(type='Sharpness'),
                            ],
                            [
                                dict(type='Posterize'),
                            ],
                            [
                                dict(type='Solarize'),
                            ],
                            [
                                dict(type='Color'),
                            ],
                            [
                                dict(type='Contrast'),
                            ],
                            [
                                dict(type='Brightness'),
                            ],
                        ],
                        type='RandAugment'),
                    dict(
                        min_gt_bbox_wh=(
                            0.01,
                            0.01,
                        ),
                        type='FilterAnnotations'),
                    dict(
                        branch_field=[
                            'sup',
                            'unsup_teacher',
                            'unsup_student',
                        ],
                        sup=dict(type='PackDetInputs'),
                        type='MultiBranch'),
                ],
                type='CocoDataset'),
            dict(
                ann_file='annotations/instances_05unlabeled.json',
                data_prefix=dict(img='train/'),
                data_root='/sharefiles2/lichengzhou/datasets/oursonar/',
                filter_cfg=dict(filter_empty_gt=False),
                metainfo=dict(
                    classes=(
                        'Pot',
                        'Steel Frame',
                        'Block',
                        'Tire',
                        'Steel Plate',
                        'Concrete Column',
                        'Underwater Robot',
                        'SquareCage',
                        'Circle Cage',
                        'Diver',
                    ),
                    palette=[
                        (
                            220,
                            20,
                            60,
                        ),
                        (
                            119,
                            11,
                            32,
                        ),
                        (
                            0,
                            0,
                            142,
                        ),
                        (
                            0,
                            0,
                            230,
                        ),
                        (
                            106,
                            0,
                            228,
                        ),
                        (
                            0,
                            60,
                            100,
                        ),
                        (
                            0,
                            80,
                            100,
                        ),
                        (
                            0,
                            0,
                            70,
                        ),
                        (
                            0,
                            0,
                            192,
                        ),
                        (
                            250,
                            170,
                            30,
                        ),
                    ]),
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations', with_bbox=True),
                    dict(
                        branch_field=[
                            'sup',
                            'unsup_teacher',
                            'unsup_student',
                        ],
                        type='MultiBranch',
                        unsup_student=[
                            dict(
                                keep_ratio=True,
                                scale=[
                                    (
                                        1333,
                                        400,
                                    ),
                                    (
                                        1333,
                                        1200,
                                    ),
                                ],
                                type='RandomResize'),
                            dict(prob=0.5, type='RandomFlip'),
                            dict(
                                transforms=[
                                    dict(
                                        aug_num=1,
                                        aug_space=[
                                            [
                                                dict(type='ColorTransform'),
                                            ],
                                            [
                                                dict(type='AutoContrast'),
                                            ],
                                            [
                                                dict(type='Equalize'),
                                            ],
                                            [
                                                dict(type='Sharpness'),
                                            ],
                                            [
                                                dict(type='Posterize'),
                                            ],
                                            [
                                                dict(type='Solarize'),
                                            ],
                                            [
                                                dict(type='Color'),
                                            ],
                                            [
                                                dict(type='Contrast'),
                                            ],
                                            [
                                                dict(type='Brightness'),
                                            ],
                                        ],
                                        type='RandAugment'),
                                    dict(
                                        aug_num=1,
                                        aug_space=[
                                            [
                                                dict(type='Rotate'),
                                            ],
                                            [
                                                dict(type='ShearX'),
                                            ],
                                            [
                                                dict(type='ShearY'),
                                            ],
                                            [
                                                dict(type='TranslateX'),
                                            ],
                                            [
                                                dict(type='TranslateY'),
                                            ],
                                        ],
                                        type='RandAugment'),
                                ],
                                type='RandomOrder'),
                            dict(
                                min_gt_bbox_wh=(
                                    0.01,
                                    0.01,
                                ),
                                type='FilterAnnotations'),
                            dict(
                                meta_keys=(
                                    'img_id',
                                    'img_path',
                                    'ori_shape',
                                    'img_shape',
                                    'scale_factor',
                                    'flip',
                                    'flip_direction',
                                    'homography_matrix',
                                ),
                                type='PackDetInputs'),
                        ],
                        unsup_teacher=[
                            dict(
                                keep_ratio=True,
                                scale=[
                                    (
                                        1333,
                                        400,
                                    ),
                                    (
                                        1333,
                                        1200,
                                    ),
                                ],
                                type='RandomResize'),
                            dict(prob=0.5, type='RandomFlip'),
                            dict(
                                meta_keys=(
                                    'img_id',
                                    'img_path',
                                    'ori_shape',
                                    'img_shape',
                                    'scale_factor',
                                    'flip',
                                    'flip_direction',
                                    'homography_matrix',
                                ),
                                type='PackDetInputs'),
                        ]),
                ],
                type='CocoDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(
        batch_size=4, source_ratio=[
            1,
            3,
        ], type='GroupMultiSourceSampler'))
unlabeled_dataset = dict(
    ann_file='annotations/instances_05unlabeled.json',
    data_prefix=dict(img='train/'),
    data_root='/sharefiles2/lichengzhou/datasets/oursonar/',
    filter_cfg=dict(filter_empty_gt=False),
    metainfo=dict(
        classes=(
            'Pot',
            'Steel Frame',
            'Block',
            'Tire',
            'Steel Plate',
            'Concrete Column',
            'Underwater Robot',
            'SquareCage',
            'Circle Cage',
            'Diver',
        ),
        palette=[
            (
                220,
                20,
                60,
            ),
            (
                119,
                11,
                32,
            ),
            (
                0,
                0,
                142,
            ),
            (
                0,
                0,
                230,
            ),
            (
                106,
                0,
                228,
            ),
            (
                0,
                60,
                100,
            ),
            (
                0,
                80,
                100,
            ),
            (
                0,
                0,
                70,
            ),
            (
                0,
                0,
                192,
            ),
            (
                250,
                170,
                30,
            ),
        ]),
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations', with_bbox=True),
        dict(
            branch_field=[
                'sup',
                'unsup_teacher',
                'unsup_student',
            ],
            type='MultiBranch',
            unsup_student=[
                dict(
                    keep_ratio=True,
                    scale=[
                        (
                            1333,
                            400,
                        ),
                        (
                            1333,
                            1200,
                        ),
                    ],
                    type='RandomResize'),
                dict(prob=0.5, type='RandomFlip'),
                dict(
                    transforms=[
                        dict(
                            aug_num=1,
                            aug_space=[
                                [
                                    dict(type='ColorTransform'),
                                ],
                                [
                                    dict(type='AutoContrast'),
                                ],
                                [
                                    dict(type='Equalize'),
                                ],
                                [
                                    dict(type='Sharpness'),
                                ],
                                [
                                    dict(type='Posterize'),
                                ],
                                [
                                    dict(type='Solarize'),
                                ],
                                [
                                    dict(type='Color'),
                                ],
                                [
                                    dict(type='Contrast'),
                                ],
                                [
                                    dict(type='Brightness'),
                                ],
                            ],
                            type='RandAugment'),
                        dict(
                            aug_num=1,
                            aug_space=[
                                [
                                    dict(type='Rotate'),
                                ],
                                [
                                    dict(type='ShearX'),
                                ],
                                [
                                    dict(type='ShearY'),
                                ],
                                [
                                    dict(type='TranslateX'),
                                ],
                                [
                                    dict(type='TranslateY'),
                                ],
                            ],
                            type='RandAugment'),
                    ],
                    type='RandomOrder'),
                dict(min_gt_bbox_wh=(
                    0.01,
                    0.01,
                ), type='FilterAnnotations'),
                dict(
                    meta_keys=(
                        'img_id',
                        'img_path',
                        'ori_shape',
                        'img_shape',
                        'scale_factor',
                        'flip',
                        'flip_direction',
                        'homography_matrix',
                    ),
                    type='PackDetInputs'),
            ],
            unsup_teacher=[
                dict(
                    keep_ratio=True,
                    scale=[
                        (
                            1333,
                            400,
                        ),
                        (
                            1333,
                            1200,
                        ),
                    ],
                    type='RandomResize'),
                dict(prob=0.5, type='RandomFlip'),
                dict(
                    meta_keys=(
                        'img_id',
                        'img_path',
                        'ori_shape',
                        'img_shape',
                        'scale_factor',
                        'flip',
                        'flip_direction',
                        'homography_matrix',
                    ),
                    type='PackDetInputs'),
            ]),
    ],
    type='CocoDataset')
unsup_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        branch_field=[
            'sup',
            'unsup_teacher',
            'unsup_student',
        ],
        type='MultiBranch',
        unsup_student=[
            dict(
                keep_ratio=True,
                scale=[
                    (
                        1333,
                        400,
                    ),
                    (
                        1333,
                        1200,
                    ),
                ],
                type='RandomResize'),
            dict(prob=0.5, type='RandomFlip'),
            dict(
                transforms=[
                    dict(
                        aug_num=1,
                        aug_space=[
                            [
                                dict(type='ColorTransform'),
                            ],
                            [
                                dict(type='AutoContrast'),
                            ],
                            [
                                dict(type='Equalize'),
                            ],
                            [
                                dict(type='Sharpness'),
                            ],
                            [
                                dict(type='Posterize'),
                            ],
                            [
                                dict(type='Solarize'),
                            ],
                            [
                                dict(type='Color'),
                            ],
                            [
                                dict(type='Contrast'),
                            ],
                            [
                                dict(type='Brightness'),
                            ],
                        ],
                        type='RandAugment'),
                    dict(
                        aug_num=1,
                        aug_space=[
                            [
                                dict(type='Rotate'),
                            ],
                            [
                                dict(type='ShearX'),
                            ],
                            [
                                dict(type='ShearY'),
                            ],
                            [
                                dict(type='TranslateX'),
                            ],
                            [
                                dict(type='TranslateY'),
                            ],
                        ],
                        type='RandAugment'),
                ],
                type='RandomOrder'),
            dict(min_gt_bbox_wh=(
                0.01,
                0.01,
            ), type='FilterAnnotations'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'flip',
                    'flip_direction',
                    'homography_matrix',
                ),
                type='PackDetInputs'),
        ],
        unsup_teacher=[
            dict(
                keep_ratio=True,
                scale=[
                    (
                        1333,
                        400,
                    ),
                    (
                        1333,
                        1200,
                    ),
                ],
                type='RandomResize'),
            dict(prob=0.5, type='RandomFlip'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'flip',
                    'flip_direction',
                    'homography_matrix',
                ),
                type='PackDetInputs'),
        ]),
]
val_cfg = dict(type='TeacherStudentValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='annotations/instances_val.json',
        backend_args=None,
        data_prefix=dict(img='val/'),
        data_root='/sharefiles2/lichengzhou/datasets/oursonar/',
        metainfo=dict(
            classes=(
                'Pot',
                'Steel Frame',
                'Block',
                'Tire',
                'Steel Plate',
                'Concrete Column',
                'Underwater Robot',
                'SquareCage',
                'Circle Cage',
                'Diver',
            ),
            palette=[
                (
                    220,
                    20,
                    60,
                ),
                (
                    119,
                    11,
                    32,
                ),
                (
                    0,
                    0,
                    142,
                ),
                (
                    0,
                    0,
                    230,
                ),
                (
                    106,
                    0,
                    228,
                ),
                (
                    0,
                    60,
                    100,
                ),
                (
                    0,
                    80,
                    100,
                ),
                (
                    0,
                    0,
                    70,
                ),
                (
                    0,
                    0,
                    192,
                ),
                (
                    250,
                    170,
                    30,
                ),
            ]),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file=
    '/sharefiles2/lichengzhou/datasets/oursonar/annotations/instances_val.json',
    format_only=False,
    metric='bbox',
    type='CocoMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='DetLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
weak_pipeline = [
    dict(
        keep_ratio=True,
        scale=[
            (
                1333,
                400,
            ),
            (
                1333,
                1200,
            ),
        ],
        type='RandomResize'),
    dict(prob=0.5, type='RandomFlip'),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
            'flip',
            'flip_direction',
            'homography_matrix',
        ),
        type='PackDetInputs'),
]
work_dir = './work_dirs/Newdatamixpl05_detr_r50_100_sonar-s1-p10'

2025/06/23 22:09:12 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/06/23 22:09:12 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) MeanTeacherHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) MeanTeacherHook                    
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.downsample.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.1.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.1.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.1.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.2.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.2.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.2.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.downsample.0.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.downsample.0.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.downsample.0.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.0.downsample.0.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.1.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.2.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer2.3.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.downsample.0.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.downsample.0.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.downsample.0.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.0.downsample.0.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.1.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.2.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.3.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.4.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer3.5.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.downsample.0.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.downsample.0.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.downsample.0.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.0.downsample.0.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.1.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv1.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv1.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv1.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv1.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv2.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv2.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv2.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv2.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv3.weight:lr=1e-05
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv3.weight:weight_decay=0.0001
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv3.weight:lr_mult=0.1
2025/06/23 22:09:16 - mmengine - INFO - paramwise_options -- student.backbone.layer4.2.conv3.weight:decay_mult=1.0
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - student.backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.downsample.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.1.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.1.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.1.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.2.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.2.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.2.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.downsample.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.1.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.1.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.1.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.2.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.2.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.2.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.3.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.3.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.3.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.downsample.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.1.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.1.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.1.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.2.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.2.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.2.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.3.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.3.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.3.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.4.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.4.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.4.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.5.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.5.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.5.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.downsample.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.1.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.1.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.1.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.2.conv1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.2.conv2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.2.conv3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.neck.convs.0.conv.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.neck.convs.0.conv.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.bbox_head.fc_cls.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.bbox_head.fc_cls.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.bbox_head.reg_ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.bbox_head.reg_ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.bbox_head.reg_ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.bbox_head.reg_ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.bbox_head.fc_reg.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.bbox_head.fc_reg.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.0.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.1.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.2.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.3.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.4.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.encoder.layers.5.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.cross_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.cross_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.cross_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.cross_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.norms.2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.0.norms.2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.cross_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.cross_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.cross_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.cross_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.norms.2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.1.norms.2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.cross_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.cross_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.cross_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.cross_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.norms.2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.2.norms.2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.cross_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.cross_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.cross_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.cross_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.norms.2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.3.norms.2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.cross_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.cross_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.cross_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.cross_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.norms.2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.4.norms.2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.self_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.self_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.self_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.self_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.cross_attn.attn.in_proj_weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.cross_attn.attn.in_proj_bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.cross_attn.attn.out_proj.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.cross_attn.attn.out_proj.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.ffn.layers.0.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.ffn.layers.0.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.ffn.layers.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.ffn.layers.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.norms.0.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.norms.0.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.norms.1.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.norms.1.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.norms.2.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.layers.5.norms.2.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.post_norm.weight is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.decoder.post_norm.bias is skipped since its requires_grad=False
2025/06/23 22:09:16 - mmengine - WARNING - teacher.query_embedding.weight is skipped since its requires_grad=False
2025/06/23 22:09:20 - mmengine - INFO - load model from: torchvision://resnet50
2025/06/23 22:09:20 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
2025/06/23 22:09:20 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2025/06/23 22:09:20 - mmengine - INFO - load model from: torchvision://resnet50
2025/06/23 22:09:20 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
Name of parameter - Initialization information

student.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

student.backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

student.neck.convs.0.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

student.neck.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.bbox_head.fc_cls.weight - torch.Size([11, 256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.bbox_head.fc_cls.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of MixPL  

student.bbox_head.reg_ffn.layers.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.bbox_head.reg_ffn.layers.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.bbox_head.reg_ffn.layers.1.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.bbox_head.reg_ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.bbox_head.fc_reg.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.bbox_head.fc_reg.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

student.decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

student.query_embedding.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

teacher.backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

teacher.neck.convs.0.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

teacher.neck.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.bbox_head.fc_cls.weight - torch.Size([11, 256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.bbox_head.fc_cls.bias - torch.Size([11]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.bbox_head.reg_ffn.layers.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.bbox_head.reg_ffn.layers.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.bbox_head.reg_ffn.layers.1.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.bbox_head.reg_ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.bbox_head.fc_reg.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.bbox_head.fc_reg.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in DETR  

teacher.decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MixPL  

teacher.query_embedding.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of MixPL  
2025/06/23 22:09:20 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/06/23 22:09:20 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/06/23 22:09:20 - mmengine - INFO - Checkpoints will be saved to /sharefiles2/lichengzhou/projects/OursCornerLoss/work_dirs/Newdatamixpl05_detr_r50_100_sonar-s1-p10.
2025/06/23 22:10:19 - mmengine - INFO - Iter(train) [    50/240000]  base_lr: 9.9010e-07 lr: 9.9010e-08  eta: 3 days, 6:23:52  time: 1.1762  data_time: 0.0276  memory: 9875  grad_norm: 2858.3590  loss: 139.3015  sup_loss_cls: 2.7560  sup_loss_bbox: 4.4053  sup_loss_iou: 1.8976  sup_d0.loss_cls: 1.6081  sup_d0.loss_bbox: 4.3972  sup_d0.loss_iou: 1.8777  sup_d1.loss_cls: 2.6505  sup_d1.loss_bbox: 4.4070  sup_d1.loss_iou: 1.8936  sup_d2.loss_cls: 2.6771  sup_d2.loss_bbox: 4.5184  sup_d2.loss_iou: 1.8851  sup_d3.loss_cls: 2.9880  sup_d3.loss_bbox: 4.4325  sup_d3.loss_iou: 1.8817  sup_d4.loss_cls: 2.6974  sup_d4.loss_bbox: 4.4799  sup_d4.loss_iou: 1.8962  mixup_unsup_loss_cls: 2.9412  mixup_unsup_loss_bbox: 1.3986  mixup_unsup_loss_iou: 1.0507  mixup_unsup_d0.loss_cls: 4.6753  mixup_unsup_d0.loss_bbox: 1.5290  mixup_unsup_d0.loss_iou: 1.1319  mixup_unsup_d1.loss_cls: 4.3311  mixup_unsup_d1.loss_bbox: 1.4554  mixup_unsup_d1.loss_iou: 1.0857  mixup_unsup_d2.loss_cls: 4.3311  mixup_unsup_d2.loss_bbox: 1.5291  mixup_unsup_d2.loss_iou: 1.1204  mixup_unsup_d3.loss_cls: 3.7275  mixup_unsup_d3.loss_bbox: 1.5584  mixup_unsup_d3.loss_iou: 1.2111  mixup_unsup_d4.loss_cls: 2.8269  mixup_unsup_d4.loss_bbox: 1.3693  mixup_unsup_d4.loss_iou: 1.0160  mosaic_unsup_loss_cls: 1.4737  mosaic_unsup_loss_bbox: 4.3546  mosaic_unsup_loss_iou: 2.1733  mosaic_unsup_d0.loss_cls: 2.3689  mosaic_unsup_d0.loss_bbox: 4.3619  mosaic_unsup_d0.loss_iou: 2.1971  mosaic_unsup_d1.loss_cls: 2.1537  mosaic_unsup_d1.loss_bbox: 4.3108  mosaic_unsup_d1.loss_iou: 2.1844  mosaic_unsup_d2.loss_cls: 2.1084  mosaic_unsup_d2.loss_bbox: 4.4430  mosaic_unsup_d2.loss_iou: 2.1558  mosaic_unsup_d3.loss_cls: 1.8153  mosaic_unsup_d3.loss_bbox: 4.4027  mosaic_unsup_d3.loss_iou: 2.1660  mosaic_unsup_d4.loss_cls: 1.4170  mosaic_unsup_d4.loss_bbox: 4.4474  mosaic_unsup_d4.loss_iou: 2.1718
2025/06/23 22:11:09 - mmengine - INFO - Iter(train) [   100/240000]  base_lr: 1.9902e-06 lr: 1.9902e-07  eta: 3 days, 0:23:15  time: 0.9963  data_time: 0.0257  memory: 9705  grad_norm: 1637.2434  loss: 121.8660  sup_loss_cls: 2.2671  sup_loss_bbox: 4.3527  sup_loss_iou: 1.9150  sup_d0.loss_cls: 1.6555  sup_d0.loss_bbox: 4.3635  sup_d0.loss_iou: 1.8952  sup_d1.loss_cls: 2.4786  sup_d1.loss_bbox: 4.3312  sup_d1.loss_iou: 1.9096  sup_d2.loss_cls: 2.4906  sup_d2.loss_bbox: 4.4704  sup_d2.loss_iou: 1.8960  sup_d3.loss_cls: 2.6935  sup_d3.loss_bbox: 4.4147  sup_d3.loss_iou: 1.8971  sup_d4.loss_cls: 2.2409  sup_d4.loss_bbox: 4.4319  sup_d4.loss_iou: 1.9205  mixup_unsup_loss_cls: 1.3835  mixup_unsup_loss_bbox: 1.4543  mixup_unsup_loss_iou: 1.1013  mixup_unsup_d0.loss_cls: 2.6573  mixup_unsup_d0.loss_bbox: 1.5523  mixup_unsup_d0.loss_iou: 1.1619  mixup_unsup_d1.loss_cls: 1.8321  mixup_unsup_d1.loss_bbox: 1.5290  mixup_unsup_d1.loss_iou: 1.1350  mixup_unsup_d2.loss_cls: 1.6502  mixup_unsup_d2.loss_bbox: 1.5344  mixup_unsup_d2.loss_iou: 1.1390  mixup_unsup_d3.loss_cls: 1.4876  mixup_unsup_d3.loss_bbox: 1.5064  mixup_unsup_d3.loss_iou: 1.1672  mixup_unsup_d4.loss_cls: 1.2080  mixup_unsup_d4.loss_bbox: 1.4439  mixup_unsup_d4.loss_iou: 1.0849  mosaic_unsup_loss_cls: 0.7127  mosaic_unsup_loss_bbox: 4.3259  mosaic_unsup_loss_iou: 2.1726  mosaic_unsup_d0.loss_cls: 1.3313  mosaic_unsup_d0.loss_bbox: 4.3140  mosaic_unsup_d0.loss_iou: 2.1937  mosaic_unsup_d1.loss_cls: 0.9196  mosaic_unsup_d1.loss_bbox: 4.2453  mosaic_unsup_d1.loss_iou: 2.2120  mosaic_unsup_d2.loss_cls: 0.8200  mosaic_unsup_d2.loss_bbox: 4.3767  mosaic_unsup_d2.loss_iou: 2.1532  mosaic_unsup_d3.loss_cls: 0.7263  mosaic_unsup_d3.loss_bbox: 4.3775  mosaic_unsup_d3.loss_iou: 2.1645  mosaic_unsup_d4.loss_cls: 0.6127  mosaic_unsup_d4.loss_bbox: 4.3885  mosaic_unsup_d4.loss_iou: 2.1673
2025/06/23 22:11:57 - mmengine - INFO - Iter(train) [   150/240000]  base_lr: 2.9903e-06 lr: 2.9903e-07  eta: 2 days, 21:39:43  time: 0.9642  data_time: 0.0252  memory: 9630  grad_norm: 1028.3937  loss: 108.5519  sup_loss_cls: 1.5792  sup_loss_bbox: 4.3352  sup_loss_iou: 1.9345  sup_d0.loss_cls: 1.7492  sup_d0.loss_bbox: 4.3888  sup_d0.loss_iou: 1.9137  sup_d1.loss_cls: 1.8791  sup_d1.loss_bbox: 4.3525  sup_d1.loss_iou: 1.9201  sup_d2.loss_cls: 1.6687  sup_d2.loss_bbox: 4.4129  sup_d2.loss_iou: 1.9251  sup_d3.loss_cls: 1.7711  sup_d3.loss_bbox: 4.4202  sup_d3.loss_iou: 1.9265  sup_d4.loss_cls: 1.5425  sup_d4.loss_bbox: 4.3882  sup_d4.loss_iou: 1.9312  mixup_unsup_loss_cls: 0.7401  mixup_unsup_loss_bbox: 1.3840  mixup_unsup_loss_iou: 1.0652  mixup_unsup_d0.loss_cls: 1.0323  mixup_unsup_d0.loss_bbox: 1.4215  mixup_unsup_d0.loss_iou: 1.0993  mixup_unsup_d1.loss_cls: 0.6845  mixup_unsup_d1.loss_bbox: 1.4131  mixup_unsup_d1.loss_iou: 1.0706  mixup_unsup_d2.loss_cls: 0.6446  mixup_unsup_d2.loss_bbox: 1.3761  mixup_unsup_d2.loss_iou: 1.0555  mixup_unsup_d3.loss_cls: 0.6595  mixup_unsup_d3.loss_bbox: 1.3303  mixup_unsup_d3.loss_iou: 1.0347  mixup_unsup_d4.loss_cls: 0.6896  mixup_unsup_d4.loss_bbox: 1.3700  mixup_unsup_d4.loss_iou: 1.0516  mosaic_unsup_loss_cls: 0.3891  mosaic_unsup_loss_bbox: 4.2588  mosaic_unsup_loss_iou: 2.2350  mosaic_unsup_d0.loss_cls: 0.5331  mosaic_unsup_d0.loss_bbox: 4.2751  mosaic_unsup_d0.loss_iou: 2.2460  mosaic_unsup_d1.loss_cls: 0.3614  mosaic_unsup_d1.loss_bbox: 4.2616  mosaic_unsup_d1.loss_iou: 2.2455  mosaic_unsup_d2.loss_cls: 0.3544  mosaic_unsup_d2.loss_bbox: 4.2814  mosaic_unsup_d2.loss_iou: 2.2270  mosaic_unsup_d3.loss_cls: 0.3367  mosaic_unsup_d3.loss_bbox: 4.2992  mosaic_unsup_d3.loss_iou: 2.2176  mosaic_unsup_d4.loss_cls: 0.3679  mosaic_unsup_d4.loss_bbox: 4.2664  mosaic_unsup_d4.loss_iou: 2.2343
2025/06/23 22:12:46 - mmengine - INFO - Iter(train) [   200/240000]  base_lr: 3.9904e-06 lr: 3.9904e-07  eta: 2 days, 20:16:57  time: 0.9636  data_time: 0.0251  memory: 9870  grad_norm: 1926.7950  loss: 96.0121  sup_loss_cls: 1.0046  sup_loss_bbox: 3.8343  sup_loss_iou: 1.8825  sup_d0.loss_cls: 1.3925  sup_d0.loss_bbox: 3.9392  sup_d0.loss_iou: 1.8690  sup_d1.loss_cls: 1.0598  sup_d1.loss_bbox: 3.9652  sup_d1.loss_iou: 1.8638  sup_d2.loss_cls: 1.0512  sup_d2.loss_bbox: 3.9804  sup_d2.loss_iou: 1.8725  sup_d3.loss_cls: 1.0704  sup_d3.loss_bbox: 3.9347  sup_d3.loss_iou: 1.8719  sup_d4.loss_cls: 0.9741  sup_d4.loss_bbox: 3.8872  sup_d4.loss_iou: 1.8775  mixup_unsup_loss_cls: 0.4007  mixup_unsup_loss_bbox: 1.0904  mixup_unsup_loss_iou: 0.9034  mixup_unsup_d0.loss_cls: 0.5667  mixup_unsup_d0.loss_bbox: 1.1253  mixup_unsup_d0.loss_iou: 0.9225  mixup_unsup_d1.loss_cls: 0.4176  mixup_unsup_d1.loss_bbox: 1.1013  mixup_unsup_d1.loss_iou: 0.9040  mixup_unsup_d2.loss_cls: 0.3786  mixup_unsup_d2.loss_bbox: 1.1059  mixup_unsup_d2.loss_iou: 0.9130  mixup_unsup_d3.loss_cls: 0.3793  mixup_unsup_d3.loss_bbox: 1.0739  mixup_unsup_d3.loss_iou: 0.8874  mixup_unsup_d4.loss_cls: 0.3932  mixup_unsup_d4.loss_bbox: 1.0901  mixup_unsup_d4.loss_iou: 0.8962  mosaic_unsup_loss_cls: 0.2087  mosaic_unsup_loss_bbox: 4.1832  mosaic_unsup_loss_iou: 2.2870  mosaic_unsup_d0.loss_cls: 0.2901  mosaic_unsup_d0.loss_bbox: 4.1257  mosaic_unsup_d0.loss_iou: 2.2952  mosaic_unsup_d1.loss_cls: 0.2326  mosaic_unsup_d1.loss_bbox: 4.1838  mosaic_unsup_d1.loss_iou: 2.3006  mosaic_unsup_d2.loss_cls: 0.2165  mosaic_unsup_d2.loss_bbox: 4.1927  mosaic_unsup_d2.loss_iou: 2.2830  mosaic_unsup_d3.loss_cls: 0.1851  mosaic_unsup_d3.loss_bbox: 4.1923  mosaic_unsup_d3.loss_iou: 2.2895  mosaic_unsup_d4.loss_cls: 0.2053  mosaic_unsup_d4.loss_bbox: 4.1670  mosaic_unsup_d4.loss_iou: 2.2934
2025/06/23 22:13:32 - mmengine - INFO - Iter(train) [   250/240000]  base_lr: 4.9905e-06 lr: 4.9905e-07  eta: 2 days, 19:03:29  time: 0.9342  data_time: 0.0251  memory: 9630  grad_norm: 2853.5845  loss: 96.0529  sup_loss_cls: 0.8254  sup_loss_bbox: 3.6543  sup_loss_iou: 1.9171  sup_d0.loss_cls: 1.1233  sup_d0.loss_bbox: 3.9398  sup_d0.loss_iou: 1.9142  sup_d1.loss_cls: 0.8334  sup_d1.loss_bbox: 3.9433  sup_d1.loss_iou: 1.9096  sup_d2.loss_cls: 0.8570  sup_d2.loss_bbox: 3.8747  sup_d2.loss_iou: 1.9062  sup_d3.loss_cls: 0.8879  sup_d3.loss_bbox: 3.8019  sup_d3.loss_iou: 1.8963  sup_d4.loss_cls: 0.8278  sup_d4.loss_bbox: 3.6654  sup_d4.loss_iou: 1.9067  mixup_unsup_loss_cls: 0.2763  mixup_unsup_loss_bbox: 1.4932  mixup_unsup_loss_iou: 1.0997  mixup_unsup_d0.loss_cls: 0.4012  mixup_unsup_d0.loss_bbox: 1.4733  mixup_unsup_d0.loss_iou: 1.1038  mixup_unsup_d1.loss_cls: 0.2859  mixup_unsup_d1.loss_bbox: 1.4774  mixup_unsup_d1.loss_iou: 1.0993  mixup_unsup_d2.loss_cls: 0.2587  mixup_unsup_d2.loss_bbox: 1.5014  mixup_unsup_d2.loss_iou: 1.1224  mixup_unsup_d3.loss_cls: 0.2419  mixup_unsup_d3.loss_bbox: 1.4747  mixup_unsup_d3.loss_iou: 1.1008  mixup_unsup_d4.loss_cls: 0.2626  mixup_unsup_d4.loss_bbox: 1.4981  mixup_unsup_d4.loss_iou: 1.0994  mosaic_unsup_loss_cls: 0.1420  mosaic_unsup_loss_bbox: 4.0539  mosaic_unsup_loss_iou: 2.3201  mosaic_unsup_d0.loss_cls: 0.2103  mosaic_unsup_d0.loss_bbox: 4.0403  mosaic_unsup_d0.loss_iou: 2.3319  mosaic_unsup_d1.loss_cls: 0.1622  mosaic_unsup_d1.loss_bbox: 4.0579  mosaic_unsup_d1.loss_iou: 2.3157  mosaic_unsup_d2.loss_cls: 0.1469  mosaic_unsup_d2.loss_bbox: 4.0222  mosaic_unsup_d2.loss_iou: 2.3190  mosaic_unsup_d3.loss_cls: 0.1143  mosaic_unsup_d3.loss_bbox: 4.0493  mosaic_unsup_d3.loss_iou: 2.3144  mosaic_unsup_d4.loss_cls: 0.1350  mosaic_unsup_d4.loss_bbox: 4.0375  mosaic_unsup_d4.loss_iou: 2.3251
2025/06/23 22:14:18 - mmengine - INFO - Iter(train) [   300/240000]  base_lr: 5.9906e-06 lr: 5.9906e-07  eta: 2 days, 17:58:23  time: 0.9104  data_time: 0.0229  memory: 9888  grad_norm: 3042.0692  loss: 93.9019  sup_loss_cls: 1.0025  sup_loss_bbox: 3.2420  sup_loss_iou: 1.9265  sup_d0.loss_cls: 1.0876  sup_d0.loss_bbox: 3.5456  sup_d0.loss_iou: 1.8994  sup_d1.loss_cls: 0.9787  sup_d1.loss_bbox: 3.5309  sup_d1.loss_iou: 1.9016  sup_d2.loss_cls: 1.0339  sup_d2.loss_bbox: 3.3901  sup_d2.loss_iou: 1.8733  sup_d3.loss_cls: 1.0503  sup_d3.loss_bbox: 3.3572  sup_d3.loss_iou: 1.8824  sup_d4.loss_cls: 1.0344  sup_d4.loss_bbox: 3.1866  sup_d4.loss_iou: 1.9147  mixup_unsup_loss_cls: 0.1766  mixup_unsup_loss_bbox: 1.5150  mixup_unsup_loss_iou: 1.1935  mixup_unsup_d0.loss_cls: 0.2839  mixup_unsup_d0.loss_bbox: 1.5201  mixup_unsup_d0.loss_iou: 1.2012  mixup_unsup_d1.loss_cls: 0.2051  mixup_unsup_d1.loss_bbox: 1.5320  mixup_unsup_d1.loss_iou: 1.2079  mixup_unsup_d2.loss_cls: 0.1890  mixup_unsup_d2.loss_bbox: 1.5720  mixup_unsup_d2.loss_iou: 1.2320  mixup_unsup_d3.loss_cls: 0.1798  mixup_unsup_d3.loss_bbox: 1.5389  mixup_unsup_d3.loss_iou: 1.2039  mixup_unsup_d4.loss_cls: 0.1850  mixup_unsup_d4.loss_bbox: 1.5335  mixup_unsup_d4.loss_iou: 1.1914  mosaic_unsup_loss_cls: 0.1336  mosaic_unsup_loss_bbox: 3.9100  mosaic_unsup_loss_iou: 2.3571  mosaic_unsup_d0.loss_cls: 0.1803  mosaic_unsup_d0.loss_bbox: 3.9069  mosaic_unsup_d0.loss_iou: 2.3475  mosaic_unsup_d1.loss_cls: 0.1577  mosaic_unsup_d1.loss_bbox: 3.9380  mosaic_unsup_d1.loss_iou: 2.3398  mosaic_unsup_d2.loss_cls: 0.1505  mosaic_unsup_d2.loss_bbox: 3.8640  mosaic_unsup_d2.loss_iou: 2.3565  mosaic_unsup_d3.loss_cls: 0.1256  mosaic_unsup_d3.loss_bbox: 3.8742  mosaic_unsup_d3.loss_iou: 2.3573  mosaic_unsup_d4.loss_cls: 0.1380  mosaic_unsup_d4.loss_bbox: 3.8936  mosaic_unsup_d4.loss_iou: 2.3731
2025/06/23 22:15:03 - mmengine - INFO - Iter(train) [   350/240000]  base_lr: 6.9907e-06 lr: 6.9907e-07  eta: 2 days, 17:10:53  time: 0.9090  data_time: 0.0244  memory: 9705  grad_norm: 2818.3403  loss: 85.1548  sup_loss_cls: 0.7147  sup_loss_bbox: 2.4298  sup_loss_iou: 1.7292  sup_d0.loss_cls: 0.8266  sup_d0.loss_bbox: 2.7125  sup_d0.loss_iou: 1.7327  sup_d1.loss_cls: 0.7092  sup_d1.loss_bbox: 2.6720  sup_d1.loss_iou: 1.7346  sup_d2.loss_cls: 0.7724  sup_d2.loss_bbox: 2.5207  sup_d2.loss_iou: 1.7107  sup_d3.loss_cls: 0.7799  sup_d3.loss_bbox: 2.5135  sup_d3.loss_iou: 1.7076  sup_d4.loss_cls: 0.7540  sup_d4.loss_bbox: 2.3177  sup_d4.loss_iou: 1.7159  mixup_unsup_loss_cls: 0.2092  mixup_unsup_loss_bbox: 1.5246  mixup_unsup_loss_iou: 1.1984  mixup_unsup_d0.loss_cls: 0.2738  mixup_unsup_d0.loss_bbox: 1.5328  mixup_unsup_d0.loss_iou: 1.2026  mixup_unsup_d1.loss_cls: 0.2286  mixup_unsup_d1.loss_bbox: 1.5146  mixup_unsup_d1.loss_iou: 1.1814  mixup_unsup_d2.loss_cls: 0.2146  mixup_unsup_d2.loss_bbox: 1.5619  mixup_unsup_d2.loss_iou: 1.2163  mixup_unsup_d3.loss_cls: 0.2005  mixup_unsup_d3.loss_bbox: 1.5244  mixup_unsup_d3.loss_iou: 1.1836  mixup_unsup_d4.loss_cls: 0.2102  mixup_unsup_d4.loss_bbox: 1.5368  mixup_unsup_d4.loss_iou: 1.1854  mosaic_unsup_loss_cls: 0.1044  mosaic_unsup_loss_bbox: 3.7276  mosaic_unsup_loss_iou: 2.4217  mosaic_unsup_d0.loss_cls: 0.1462  mosaic_unsup_d0.loss_bbox: 3.6354  mosaic_unsup_d0.loss_iou: 2.4127  mosaic_unsup_d1.loss_cls: 0.1214  mosaic_unsup_d1.loss_bbox: 3.7355  mosaic_unsup_d1.loss_iou: 2.4159  mosaic_unsup_d2.loss_cls: 0.1186  mosaic_unsup_d2.loss_bbox: 3.6474  mosaic_unsup_d2.loss_iou: 2.4272  mosaic_unsup_d3.loss_cls: 0.0927  mosaic_unsup_d3.loss_bbox: 3.7025  mosaic_unsup_d3.loss_iou: 2.4328  mosaic_unsup_d4.loss_cls: 0.1085  mosaic_unsup_d4.loss_bbox: 3.7237  mosaic_unsup_d4.loss_iou: 2.4271
2025/06/23 22:15:49 - mmengine - INFO - Iter(train) [   400/240000]  base_lr: 7.9908e-06 lr: 7.9908e-07  eta: 2 days, 16:37:36  time: 0.9141  data_time: 0.0246  memory: 9467  grad_norm: 4793.1462  loss: 88.8222  sup_loss_cls: 0.9354  sup_loss_bbox: 2.5372  sup_loss_iou: 1.9270  sup_d0.loss_cls: 0.9884  sup_d0.loss_bbox: 2.8450  sup_d0.loss_iou: 1.9203  sup_d1.loss_cls: 0.9127  sup_d1.loss_bbox: 2.7617  sup_d1.loss_iou: 1.9116  sup_d2.loss_cls: 0.9538  sup_d2.loss_bbox: 2.6106  sup_d2.loss_iou: 1.8882  sup_d3.loss_cls: 0.9485  sup_d3.loss_bbox: 2.6210  sup_d3.loss_iou: 1.8859  sup_d4.loss_cls: 0.9607  sup_d4.loss_bbox: 2.4474  sup_d4.loss_iou: 1.9013  mixup_unsup_loss_cls: 0.1535  mixup_unsup_loss_bbox: 1.6588  mixup_unsup_loss_iou: 1.3326  mixup_unsup_d0.loss_cls: 0.2220  mixup_unsup_d0.loss_bbox: 1.6652  mixup_unsup_d0.loss_iou: 1.3160  mixup_unsup_d1.loss_cls: 0.1782  mixup_unsup_d1.loss_bbox: 1.6707  mixup_unsup_d1.loss_iou: 1.3264  mixup_unsup_d2.loss_cls: 0.1719  mixup_unsup_d2.loss_bbox: 1.7317  mixup_unsup_d2.loss_iou: 1.3688  mixup_unsup_d3.loss_cls: 0.1593  mixup_unsup_d3.loss_bbox: 1.6799  mixup_unsup_d3.loss_iou: 1.3482  mixup_unsup_d4.loss_cls: 0.1613  mixup_unsup_d4.loss_bbox: 1.6769  mixup_unsup_d4.loss_iou: 1.3295  mosaic_unsup_loss_cls: 0.1918  mosaic_unsup_loss_bbox: 3.3366  mosaic_unsup_loss_iou: 2.5807  mosaic_unsup_d0.loss_cls: 0.2152  mosaic_unsup_d0.loss_bbox: 3.3656  mosaic_unsup_d0.loss_iou: 2.5319  mosaic_unsup_d1.loss_cls: 0.2234  mosaic_unsup_d1.loss_bbox: 3.4303  mosaic_unsup_d1.loss_iou: 2.5253  mosaic_unsup_d2.loss_cls: 0.2394  mosaic_unsup_d2.loss_bbox: 3.2835  mosaic_unsup_d2.loss_iou: 2.5572  mosaic_unsup_d3.loss_cls: 0.1891  mosaic_unsup_d3.loss_bbox: 3.3188  mosaic_unsup_d3.loss_iou: 2.5754  mosaic_unsup_d4.loss_cls: 0.2164  mosaic_unsup_d4.loss_bbox: 3.3338  mosaic_unsup_d4.loss_iou: 2.6004
2025/06/23 22:16:33 - mmengine - INFO - Iter(train) [   450/240000]  base_lr: 8.9909e-06 lr: 8.9909e-07  eta: 2 days, 15:58:55  time: 0.8857  data_time: 0.0242  memory: 9888  grad_norm: 4338.0458  loss: 80.7942  sup_loss_cls: 0.8744  sup_loss_bbox: 1.9318  sup_loss_iou: 1.8075  sup_d0.loss_cls: 0.8844  sup_d0.loss_bbox: 2.2093  sup_d0.loss_iou: 1.7802  sup_d1.loss_cls: 0.8348  sup_d1.loss_bbox: 2.1341  sup_d1.loss_iou: 1.7921  sup_d2.loss_cls: 0.8823  sup_d2.loss_bbox: 2.0139  sup_d2.loss_iou: 1.7781  sup_d3.loss_cls: 0.8585  sup_d3.loss_bbox: 2.0038  sup_d3.loss_iou: 1.7979  sup_d4.loss_cls: 0.8988  sup_d4.loss_bbox: 1.8495  sup_d4.loss_iou: 1.7952  mixup_unsup_loss_cls: 0.1296  mixup_unsup_loss_bbox: 1.5669  mixup_unsup_loss_iou: 1.2731  mixup_unsup_d0.loss_cls: 0.1808  mixup_unsup_d0.loss_bbox: 1.5611  mixup_unsup_d0.loss_iou: 1.2559  mixup_unsup_d1.loss_cls: 0.1423  mixup_unsup_d1.loss_bbox: 1.5576  mixup_unsup_d1.loss_iou: 1.2447  mixup_unsup_d2.loss_cls: 0.1467  mixup_unsup_d2.loss_bbox: 1.5888  mixup_unsup_d2.loss_iou: 1.2681  mixup_unsup_d3.loss_cls: 0.1397  mixup_unsup_d3.loss_bbox: 1.5656  mixup_unsup_d3.loss_iou: 1.2594  mixup_unsup_d4.loss_cls: 0.1364  mixup_unsup_d4.loss_bbox: 1.5779  mixup_unsup_d4.loss_iou: 1.2668  mosaic_unsup_loss_cls: 0.2210  mosaic_unsup_loss_bbox: 2.9491  mosaic_unsup_loss_iou: 2.6111  mosaic_unsup_d0.loss_cls: 0.2509  mosaic_unsup_d0.loss_bbox: 3.0278  mosaic_unsup_d0.loss_iou: 2.5861  mosaic_unsup_d1.loss_cls: 0.2541  mosaic_unsup_d1.loss_bbox: 3.0405  mosaic_unsup_d1.loss_iou: 2.5581  mosaic_unsup_d2.loss_cls: 0.2893  mosaic_unsup_d2.loss_bbox: 2.8689  mosaic_unsup_d2.loss_iou: 2.5835  mosaic_unsup_d3.loss_cls: 0.2270  mosaic_unsup_d3.loss_bbox: 2.9418  mosaic_unsup_d3.loss_iou: 2.5801  mosaic_unsup_d4.loss_cls: 0.2489  mosaic_unsup_d4.loss_bbox: 2.9486  mosaic_unsup_d4.loss_iou: 2.6196
2025/06/23 22:17:17 - mmengine - INFO - Iter(train) [   500/240000]  base_lr: 9.9910e-06 lr: 9.9910e-07  eta: 2 days, 15:22:36  time: 0.8726  data_time: 0.0244  memory: 9611  grad_norm: 3664.3951  loss: 77.3499  sup_loss_cls: 0.7394  sup_loss_bbox: 1.5941  sup_loss_iou: 1.7165  sup_d0.loss_cls: 0.7729  sup_d0.loss_bbox: 1.8624  sup_d0.loss_iou: 1.7133  sup_d1.loss_cls: 0.7100  sup_d1.loss_bbox: 1.7907  sup_d1.loss_iou: 1.7154  sup_d2.loss_cls: 0.7340  sup_d2.loss_bbox: 1.6648  sup_d2.loss_iou: 1.7011  sup_d3.loss_cls: 0.7340  sup_d3.loss_bbox: 1.6529  sup_d3.loss_iou: 1.6985  sup_d4.loss_cls: 0.7594  sup_d4.loss_bbox: 1.5314  sup_d4.loss_iou: 1.7044  mixup_unsup_loss_cls: 0.0967  mixup_unsup_loss_bbox: 1.3970  mixup_unsup_loss_iou: 1.1944  mixup_unsup_d0.loss_cls: 0.1301  mixup_unsup_d0.loss_bbox: 1.3900  mixup_unsup_d0.loss_iou: 1.1742  mixup_unsup_d1.loss_cls: 0.1081  mixup_unsup_d1.loss_bbox: 1.3835  mixup_unsup_d1.loss_iou: 1.1825  mixup_unsup_d2.loss_cls: 0.1127  mixup_unsup_d2.loss_bbox: 1.4128  mixup_unsup_d2.loss_iou: 1.2054  mixup_unsup_d3.loss_cls: 0.1022  mixup_unsup_d3.loss_bbox: 1.3902  mixup_unsup_d3.loss_iou: 1.1950  mixup_unsup_d4.loss_cls: 0.1032  mixup_unsup_d4.loss_bbox: 1.3996  mixup_unsup_d4.loss_iou: 1.1974  mosaic_unsup_loss_cls: 0.3351  mosaic_unsup_loss_bbox: 2.8997  mosaic_unsup_loss_iou: 2.7781  mosaic_unsup_d0.loss_cls: 0.3719  mosaic_unsup_d0.loss_bbox: 2.9966  mosaic_unsup_d0.loss_iou: 2.7704  mosaic_unsup_d1.loss_cls: 0.4018  mosaic_unsup_d1.loss_bbox: 2.9892  mosaic_unsup_d1.loss_iou: 2.7193  mosaic_unsup_d2.loss_cls: 0.4285  mosaic_unsup_d2.loss_bbox: 2.8696  mosaic_unsup_d2.loss_iou: 2.7516  mosaic_unsup_d3.loss_cls: 0.3593  mosaic_unsup_d3.loss_bbox: 2.9059  mosaic_unsup_d3.loss_iou: 2.7346  mosaic_unsup_d4.loss_cls: 0.3907  mosaic_unsup_d4.loss_bbox: 2.8939  mosaic_unsup_d4.loss_iou: 2.7834
2025/06/23 22:17:59 - mmengine - INFO - Iter(train) [   550/240000]  base_lr: 1.0991e-05 lr: 1.0991e-06  eta: 2 days, 14:44:18  time: 0.8492  data_time: 0.0248  memory: 9885  grad_norm: 3609.9423  loss: 60.6682  sup_loss_cls: 0.7094  sup_loss_bbox: 1.4660  sup_loss_iou: 1.8589  sup_d0.loss_cls: 0.7320  sup_d0.loss_bbox: 1.5878  sup_d0.loss_iou: 1.7959  sup_d1.loss_cls: 0.7216  sup_d1.loss_bbox: 1.5335  sup_d1.loss_iou: 1.8067  sup_d2.loss_cls: 0.7225  sup_d2.loss_bbox: 1.5054  sup_d2.loss_iou: 1.8155  sup_d3.loss_cls: 0.7103  sup_d3.loss_bbox: 1.4985  sup_d3.loss_iou: 1.8362  sup_d4.loss_cls: 0.7215  sup_d4.loss_bbox: 1.4534  sup_d4.loss_iou: 1.8512  mixup_unsup_loss_cls: 0.0578  mixup_unsup_loss_bbox: 0.5119  mixup_unsup_loss_iou: 0.4457  mixup_unsup_d0.loss_cls: 0.0603  mixup_unsup_d0.loss_bbox: 0.5116  mixup_unsup_d0.loss_iou: 0.4470  mixup_unsup_d1.loss_cls: 0.0595  mixup_unsup_d1.loss_bbox: 0.5000  mixup_unsup_d1.loss_iou: 0.4381  mixup_unsup_d2.loss_cls: 0.0592  mixup_unsup_d2.loss_bbox: 0.5160  mixup_unsup_d2.loss_iou: 0.4484  mixup_unsup_d3.loss_cls: 0.0566  mixup_unsup_d3.loss_bbox: 0.5071  mixup_unsup_d3.loss_iou: 0.4478  mixup_unsup_d4.loss_cls: 0.0598  mixup_unsup_d4.loss_bbox: 0.5113  mixup_unsup_d4.loss_iou: 0.4461  mosaic_unsup_loss_cls: 0.1629  mosaic_unsup_loss_bbox: 2.3241  mosaic_unsup_loss_iou: 2.4810  mosaic_unsup_d0.loss_cls: 0.2250  mosaic_unsup_d0.loss_bbox: 2.4251  mosaic_unsup_d0.loss_iou: 2.5222  mosaic_unsup_d1.loss_cls: 0.2027  mosaic_unsup_d1.loss_bbox: 2.4157  mosaic_unsup_d1.loss_iou: 2.4580  mosaic_unsup_d2.loss_cls: 0.2334  mosaic_unsup_d2.loss_bbox: 2.3303  mosaic_unsup_d2.loss_iou: 2.4852  mosaic_unsup_d3.loss_cls: 0.1922  mosaic_unsup_d3.loss_bbox: 2.3437  mosaic_unsup_d3.loss_iou: 2.4539  mosaic_unsup_d4.loss_cls: 0.2099  mosaic_unsup_d4.loss_bbox: 2.3100  mosaic_unsup_d4.loss_iou: 2.4824
2025/06/23 22:18:32 - mmengine - INFO - Exp name: Newdatamixpl05_detr_r50_100_sonar-s1-p10_20250623_220902
2025/06/23 22:18:42 - mmengine - INFO - Iter(train) [   600/240000]  base_lr: 1.1991e-05 lr: 1.1991e-06  eta: 2 days, 14:12:00  time: 0.8485  data_time: 0.0244  memory: 9886  grad_norm: 3106.0028  loss: 58.2532  sup_loss_cls: 0.5728  sup_loss_bbox: 1.3227  sup_loss_iou: 1.7750  sup_d0.loss_cls: 0.5917  sup_d0.loss_bbox: 1.3504  sup_d0.loss_iou: 1.7082  sup_d1.loss_cls: 0.5858  sup_d1.loss_bbox: 1.3186  sup_d1.loss_iou: 1.7186  sup_d2.loss_cls: 0.5829  sup_d2.loss_bbox: 1.3286  sup_d2.loss_iou: 1.7311  sup_d3.loss_cls: 0.5787  sup_d3.loss_bbox: 1.3344  sup_d3.loss_iou: 1.7257  sup_d4.loss_cls: 0.5834  sup_d4.loss_bbox: 1.2844  sup_d4.loss_iou: 1.7394  mixup_unsup_loss_cls: 0.1545  mixup_unsup_loss_bbox: 0.7742  mixup_unsup_loss_iou: 0.6370  mixup_unsup_d0.loss_cls: 0.1519  mixup_unsup_d0.loss_bbox: 0.7184  mixup_unsup_d0.loss_iou: 0.5904  mixup_unsup_d1.loss_cls: 0.1486  mixup_unsup_d1.loss_bbox: 0.7131  mixup_unsup_d1.loss_iou: 0.5928  mixup_unsup_d2.loss_cls: 0.1462  mixup_unsup_d2.loss_bbox: 0.7371  mixup_unsup_d2.loss_iou: 0.6030  mixup_unsup_d3.loss_cls: 0.1485  mixup_unsup_d3.loss_bbox: 0.7105  mixup_unsup_d3.loss_iou: 0.5906  mixup_unsup_d4.loss_cls: 0.1624  mixup_unsup_d4.loss_bbox: 0.7572  mixup_unsup_d4.loss_iou: 0.6201  mosaic_unsup_loss_cls: 0.1118  mosaic_unsup_loss_bbox: 2.1457  mosaic_unsup_loss_iou: 2.2602  mosaic_unsup_d0.loss_cls: 0.1689  mosaic_unsup_d0.loss_bbox: 2.1873  mosaic_unsup_d0.loss_iou: 2.2720  mosaic_unsup_d1.loss_cls: 0.1438  mosaic_unsup_d1.loss_bbox: 2.2191  mosaic_unsup_d1.loss_iou: 2.2335  mosaic_unsup_d2.loss_cls: 0.1588  mosaic_unsup_d2.loss_bbox: 2.1732  mosaic_unsup_d2.loss_iou: 2.2493  mosaic_unsup_d3.loss_cls: 0.1217  mosaic_unsup_d3.loss_bbox: 2.1921  mosaic_unsup_d3.loss_iou: 2.2555  mosaic_unsup_d4.loss_cls: 0.1429  mosaic_unsup_d4.loss_bbox: 2.1491  mosaic_unsup_d4.loss_iou: 2.2794
2025/06/23 22:19:23 - mmengine - INFO - Iter(train) [   650/240000]  base_lr: 1.2991e-05 lr: 1.2991e-06  eta: 2 days, 13:37:49  time: 0.8265  data_time: 0.0240  memory: 9702  grad_norm: 2473.7185  loss: 58.4184  sup_loss_cls: 0.6666  sup_loss_bbox: 1.3066  sup_loss_iou: 1.8462  sup_d0.loss_cls: 0.6549  sup_d0.loss_bbox: 1.3372  sup_d0.loss_iou: 1.7958  sup_d1.loss_cls: 0.6675  sup_d1.loss_bbox: 1.3452  sup_d1.loss_iou: 1.7991  sup_d2.loss_cls: 0.6682  sup_d2.loss_bbox: 1.3172  sup_d2.loss_iou: 1.8055  sup_d3.loss_cls: 0.6474  sup_d3.loss_bbox: 1.3299  sup_d3.loss_iou: 1.7832  sup_d4.loss_cls: 0.6574  sup_d4.loss_bbox: 1.3155  sup_d4.loss_iou: 1.8222  mixup_unsup_loss_cls: 0.0235  mixup_unsup_loss_bbox: 0.5844  mixup_unsup_loss_iou: 0.5636  mixup_unsup_d0.loss_cls: 0.0293  mixup_unsup_d0.loss_bbox: 0.5548  mixup_unsup_d0.loss_iou: 0.5338  mixup_unsup_d1.loss_cls: 0.0191  mixup_unsup_d1.loss_bbox: 0.5559  mixup_unsup_d1.loss_iou: 0.5345  mixup_unsup_d2.loss_cls: 0.0254  mixup_unsup_d2.loss_bbox: 0.5700  mixup_unsup_d2.loss_iou: 0.5494  mixup_unsup_d3.loss_cls: 0.0262  mixup_unsup_d3.loss_bbox: 0.5703  mixup_unsup_d3.loss_iou: 0.5512  mixup_unsup_d4.loss_cls: 0.0235  mixup_unsup_d4.loss_bbox: 0.5806  mixup_unsup_d4.loss_iou: 0.5573  mosaic_unsup_loss_cls: 0.0779  mosaic_unsup_loss_bbox: 2.1722  mosaic_unsup_loss_iou: 2.4699  mosaic_unsup_d0.loss_cls: 0.1234  mosaic_unsup_d0.loss_bbox: 2.2461  mosaic_unsup_d0.loss_iou: 2.5090  mosaic_unsup_d1.loss_cls: 0.0892  mosaic_unsup_d1.loss_bbox: 2.2562  mosaic_unsup_d1.loss_iou: 2.4728  mosaic_unsup_d2.loss_cls: 0.1084  mosaic_unsup_d2.loss_bbox: 2.1915  mosaic_unsup_d2.loss_iou: 2.5101  mosaic_unsup_d3.loss_cls: 0.0929  mosaic_unsup_d3.loss_bbox: 2.2160  mosaic_unsup_d3.loss_iou: 2.4924  mosaic_unsup_d4.loss_cls: 0.0898  mosaic_unsup_d4.loss_bbox: 2.1901  mosaic_unsup_d4.loss_iou: 2.4921
2025/06/23 22:20:04 - mmengine - INFO - Iter(train) [   700/240000]  base_lr: 1.3991e-05 lr: 1.3991e-06  eta: 2 days, 13:04:38  time: 0.8132  data_time: 0.0233  memory: 9819  grad_norm: 4272.3501  loss: 62.8382  sup_loss_cls: 0.6693  sup_loss_bbox: 1.4451  sup_loss_iou: 2.0388  sup_d0.loss_cls: 0.6401  sup_d0.loss_bbox: 1.3823  sup_d0.loss_iou: 1.9396  sup_d1.loss_cls: 0.6676  sup_d1.loss_bbox: 1.4265  sup_d1.loss_iou: 2.0069  sup_d2.loss_cls: 0.6684  sup_d2.loss_bbox: 1.4106  sup_d2.loss_iou: 1.9786  sup_d3.loss_cls: 0.6648  sup_d3.loss_bbox: 1.4573  sup_d3.loss_iou: 1.9831  sup_d4.loss_cls: 0.6762  sup_d4.loss_bbox: 1.4317  sup_d4.loss_iou: 2.0452  mixup_unsup_loss_cls: 0.0402  mixup_unsup_loss_bbox: 0.6277  mixup_unsup_loss_iou: 0.5597  mixup_unsup_d0.loss_cls: 0.0609  mixup_unsup_d0.loss_bbox: 0.5798  mixup_unsup_d0.loss_iou: 0.5289  mixup_unsup_d1.loss_cls: 0.0431  mixup_unsup_d1.loss_bbox: 0.5904  mixup_unsup_d1.loss_iou: 0.5370  mixup_unsup_d2.loss_cls: 0.0446  mixup_unsup_d2.loss_bbox: 0.6113  mixup_unsup_d2.loss_iou: 0.5427  mixup_unsup_d3.loss_cls: 0.0413  mixup_unsup_d3.loss_bbox: 0.5913  mixup_unsup_d3.loss_iou: 0.5367  mixup_unsup_d4.loss_cls: 0.0376  mixup_unsup_d4.loss_bbox: 0.6055  mixup_unsup_d4.loss_iou: 0.5437  mosaic_unsup_loss_cls: 0.1531  mosaic_unsup_loss_bbox: 2.2844  mosaic_unsup_loss_iou: 2.6981  mosaic_unsup_d0.loss_cls: 0.2238  mosaic_unsup_d0.loss_bbox: 2.3406  mosaic_unsup_d0.loss_iou: 2.7702  mosaic_unsup_d1.loss_cls: 0.1722  mosaic_unsup_d1.loss_bbox: 2.3325  mosaic_unsup_d1.loss_iou: 2.7153  mosaic_unsup_d2.loss_cls: 0.1901  mosaic_unsup_d2.loss_bbox: 2.2909  mosaic_unsup_d2.loss_iou: 2.7293  mosaic_unsup_d3.loss_cls: 0.1532  mosaic_unsup_d3.loss_bbox: 2.2883  mosaic_unsup_d3.loss_iou: 2.6872  mosaic_unsup_d4.loss_cls: 0.1659  mosaic_unsup_d4.loss_bbox: 2.2839  mosaic_unsup_d4.loss_iou: 2.7048
2025/06/23 22:20:43 - mmengine - INFO - Iter(train) [   750/240000]  base_lr: 1.4991e-05 lr: 1.4991e-06  eta: 2 days, 12:26:44  time: 0.7792  data_time: 0.0234  memory: 9885  grad_norm: 2607.0299  loss: 48.8085  sup_loss_cls: 0.6020  sup_loss_bbox: 1.2142  sup_loss_iou: 1.9261  sup_d0.loss_cls: 0.6196  sup_d0.loss_bbox: 1.1825  sup_d0.loss_iou: 1.8071  sup_d1.loss_cls: 0.6129  sup_d1.loss_bbox: 1.2332  sup_d1.loss_iou: 1.8918  sup_d2.loss_cls: 0.5936  sup_d2.loss_bbox: 1.2291  sup_d2.loss_iou: 1.9004  sup_d3.loss_cls: 0.6069  sup_d3.loss_bbox: 1.2374  sup_d3.loss_iou: 1.9037  sup_d4.loss_cls: 0.6021  sup_d4.loss_bbox: 1.2064  sup_d4.loss_iou: 1.9014  mixup_unsup_loss_cls: 0.0332  mixup_unsup_loss_bbox: 0.5570  mixup_unsup_loss_iou: 0.5032  mixup_unsup_d0.loss_cls: 0.0416  mixup_unsup_d0.loss_bbox: 0.5056  mixup_unsup_d0.loss_iou: 0.4651  mixup_unsup_d1.loss_cls: 0.0294  mixup_unsup_d1.loss_bbox: 0.5106  mixup_unsup_d1.loss_iou: 0.4697  mixup_unsup_d2.loss_cls: 0.0310  mixup_unsup_d2.loss_bbox: 0.5305  mixup_unsup_d2.loss_iou: 0.4839  mixup_unsup_d3.loss_cls: 0.0321  mixup_unsup_d3.loss_bbox: 0.5304  mixup_unsup_d3.loss_iou: 0.4910  mixup_unsup_d4.loss_cls: 0.0293  mixup_unsup_d4.loss_bbox: 0.5474  mixup_unsup_d4.loss_iou: 0.4981  mosaic_unsup_loss_cls: 0.1294  mosaic_unsup_loss_bbox: 1.3783  mosaic_unsup_loss_iou: 1.8376  mosaic_unsup_d0.loss_cls: 0.1283  mosaic_unsup_d0.loss_bbox: 1.4478  mosaic_unsup_d0.loss_iou: 1.8706  mosaic_unsup_d1.loss_cls: 0.1186  mosaic_unsup_d1.loss_bbox: 1.4188  mosaic_unsup_d1.loss_iou: 1.8433  mosaic_unsup_d2.loss_cls: 0.1329  mosaic_unsup_d2.loss_bbox: 1.3959  mosaic_unsup_d2.loss_iou: 1.8470  mosaic_unsup_d3.loss_cls: 0.1249  mosaic_unsup_d3.loss_bbox: 1.4062  mosaic_unsup_d3.loss_iou: 1.8294  mosaic_unsup_d4.loss_cls: 0.1306  mosaic_unsup_d4.loss_bbox: 1.3850  mosaic_unsup_d4.loss_iou: 1.8242
2025/06/23 22:21:22 - mmengine - INFO - Iter(train) [   800/240000]  base_lr: 1.5992e-05 lr: 1.5992e-06  eta: 2 days, 11:55:41  time: 0.7879  data_time: 0.0236  memory: 9819  grad_norm: 3173.2922  loss: 49.2416  sup_loss_cls: 0.5663  sup_loss_bbox: 1.1969  sup_loss_iou: 1.7088  sup_d0.loss_cls: 0.5618  sup_d0.loss_bbox: 1.2188  sup_d0.loss_iou: 1.7020  sup_d1.loss_cls: 0.5748  sup_d1.loss_bbox: 1.2103  sup_d1.loss_iou: 1.7095  sup_d2.loss_cls: 0.5656  sup_d2.loss_bbox: 1.2113  sup_d2.loss_iou: 1.7152  sup_d3.loss_cls: 0.5679  sup_d3.loss_bbox: 1.2346  sup_d3.loss_iou: 1.7384  sup_d4.loss_cls: 0.5716  sup_d4.loss_bbox: 1.2224  sup_d4.loss_iou: 1.7281  mixup_unsup_loss_cls: 0.0319  mixup_unsup_loss_bbox: 0.5384  mixup_unsup_loss_iou: 0.5523  mixup_unsup_d0.loss_cls: 0.0567  mixup_unsup_d0.loss_bbox: 0.5152  mixup_unsup_d0.loss_iou: 0.5284  mixup_unsup_d1.loss_cls: 0.0313  mixup_unsup_d1.loss_bbox: 0.5306  mixup_unsup_d1.loss_iou: 0.5383  mixup_unsup_d2.loss_cls: 0.0361  mixup_unsup_d2.loss_bbox: 0.5294  mixup_unsup_d2.loss_iou: 0.5325  mixup_unsup_d3.loss_cls: 0.0403  mixup_unsup_d3.loss_bbox: 0.5186  mixup_unsup_d3.loss_iou: 0.5383  mixup_unsup_d4.loss_cls: 0.0342  mixup_unsup_d4.loss_bbox: 0.5321  mixup_unsup_d4.loss_iou: 0.5506  mosaic_unsup_loss_cls: 0.0679  mosaic_unsup_loss_bbox: 1.5538  mosaic_unsup_loss_iou: 1.9174  mosaic_unsup_d0.loss_cls: 0.0915  mosaic_unsup_d0.loss_bbox: 1.6076  mosaic_unsup_d0.loss_iou: 1.9885  mosaic_unsup_d1.loss_cls: 0.0784  mosaic_unsup_d1.loss_bbox: 1.5913  mosaic_unsup_d1.loss_iou: 1.9502  mosaic_unsup_d2.loss_cls: 0.0870  mosaic_unsup_d2.loss_bbox: 1.5786  mosaic_unsup_d2.loss_iou: 1.9656  mosaic_unsup_d3.loss_cls: 0.0776  mosaic_unsup_d3.loss_bbox: 1.5748  mosaic_unsup_d3.loss_iou: 1.9309  mosaic_unsup_d4.loss_cls: 0.0763  mosaic_unsup_d4.loss_bbox: 1.5599  mosaic_unsup_d4.loss_iou: 1.9052
2025/06/23 22:22:02 - mmengine - INFO - Iter(train) [   850/240000]  base_lr: 1.6992e-05 lr: 1.6992e-06  eta: 2 days, 11:32:18  time: 0.8054  data_time: 0.0241  memory: 9885  grad_norm: 3464.5174  loss: 56.9712  sup_loss_cls: 0.6954  sup_loss_bbox: 1.1447  sup_loss_iou: 1.8264  sup_d0.loss_cls: 0.6560  sup_d0.loss_bbox: 1.1152  sup_d0.loss_iou: 1.7791  sup_d1.loss_cls: 0.6976  sup_d1.loss_bbox: 1.1485  sup_d1.loss_iou: 1.8276  sup_d2.loss_cls: 0.7053  sup_d2.loss_bbox: 1.1421  sup_d2.loss_iou: 1.8361  sup_d3.loss_cls: 0.6938  sup_d3.loss_bbox: 1.1341  sup_d3.loss_iou: 1.8608  sup_d4.loss_cls: 0.6900  sup_d4.loss_bbox: 1.1778  sup_d4.loss_iou: 1.8938  mixup_unsup_loss_cls: 0.0395  mixup_unsup_loss_bbox: 0.4148  mixup_unsup_loss_iou: 0.4420  mixup_unsup_d0.loss_cls: 0.0523  mixup_unsup_d0.loss_bbox: 0.4082  mixup_unsup_d0.loss_iou: 0.4378  mixup_unsup_d1.loss_cls: 0.0328  mixup_unsup_d1.loss_bbox: 0.4115  mixup_unsup_d1.loss_iou: 0.4385  mixup_unsup_d2.loss_cls: 0.0358  mixup_unsup_d2.loss_bbox: 0.4185  mixup_unsup_d2.loss_iou: 0.4376  mixup_unsup_d3.loss_cls: 0.0406  mixup_unsup_d3.loss_bbox: 0.4080  mixup_unsup_d3.loss_iou: 0.4341  mixup_unsup_d4.loss_cls: 0.0414  mixup_unsup_d4.loss_bbox: 0.4178  mixup_unsup_d4.loss_iou: 0.4428  mosaic_unsup_loss_cls: 0.0838  mosaic_unsup_loss_bbox: 2.3454  mosaic_unsup_loss_iou: 2.5328  mosaic_unsup_d0.loss_cls: 0.1054  mosaic_unsup_d0.loss_bbox: 2.2778  mosaic_unsup_d0.loss_iou: 2.5347  mosaic_unsup_d1.loss_cls: 0.0743  mosaic_unsup_d1.loss_bbox: 2.3156  mosaic_unsup_d1.loss_iou: 2.5185  mosaic_unsup_d2.loss_cls: 0.0855  mosaic_unsup_d2.loss_bbox: 2.3086  mosaic_unsup_d2.loss_iou: 2.5410  mosaic_unsup_d3.loss_cls: 0.0817  mosaic_unsup_d3.loss_bbox: 2.3387  mosaic_unsup_d3.loss_iou: 2.5339  mosaic_unsup_d4.loss_cls: 0.0807  mosaic_unsup_d4.loss_bbox: 2.3253  mosaic_unsup_d4.loss_iou: 2.5092
2025/06/23 22:22:42 - mmengine - INFO - Iter(train) [   900/240000]  base_lr: 1.7992e-05 lr: 1.7992e-06  eta: 2 days, 11:08:20  time: 0.7914  data_time: 0.0244  memory: 9880  grad_norm: 2036.1018  loss: 49.6022  sup_loss_cls: 0.5874  sup_loss_bbox: 1.2138  sup_loss_iou: 1.8465  sup_d0.loss_cls: 0.5828  sup_d0.loss_bbox: 1.1883  sup_d0.loss_iou: 1.8315  sup_d1.loss_cls: 0.5966  sup_d1.loss_bbox: 1.2207  sup_d1.loss_iou: 1.8590  sup_d2.loss_cls: 0.5822  sup_d2.loss_bbox: 1.1987  sup_d2.loss_iou: 1.8425  sup_d3.loss_cls: 0.5856  sup_d3.loss_bbox: 1.2219  sup_d3.loss_iou: 1.8035  sup_d4.loss_cls: 0.5847  sup_d4.loss_bbox: 1.2188  sup_d4.loss_iou: 1.8337  mixup_unsup_loss_cls: 0.0044  mixup_unsup_loss_bbox: 0.3349  mixup_unsup_loss_iou: 0.3262  mixup_unsup_d0.loss_cls: 0.0071  mixup_unsup_d0.loss_bbox: 0.3083  mixup_unsup_d0.loss_iou: 0.3144  mixup_unsup_d1.loss_cls: 0.0046  mixup_unsup_d1.loss_bbox: 0.3242  mixup_unsup_d1.loss_iou: 0.3190  mixup_unsup_d2.loss_cls: 0.0050  mixup_unsup_d2.loss_bbox: 0.3204  mixup_unsup_d2.loss_iou: 0.3176  mixup_unsup_d3.loss_cls: 0.0051  mixup_unsup_d3.loss_bbox: 0.3255  mixup_unsup_d3.loss_iou: 0.3213  mixup_unsup_d4.loss_cls: 0.0050  mixup_unsup_d4.loss_bbox: 0.3303  mixup_unsup_d4.loss_iou: 0.3245  mosaic_unsup_loss_cls: 0.1106  mosaic_unsup_loss_bbox: 1.6679  mosaic_unsup_loss_iou: 2.1612  mosaic_unsup_d0.loss_cls: 0.1286  mosaic_unsup_d0.loss_bbox: 1.6734  mosaic_unsup_d0.loss_iou: 2.2299  mosaic_unsup_d1.loss_cls: 0.1115  mosaic_unsup_d1.loss_bbox: 1.6681  mosaic_unsup_d1.loss_iou: 2.2155  mosaic_unsup_d2.loss_cls: 0.1195  mosaic_unsup_d2.loss_bbox: 1.6675  mosaic_unsup_d2.loss_iou: 2.2161  mosaic_unsup_d3.loss_cls: 0.1141  mosaic_unsup_d3.loss_bbox: 1.6765  mosaic_unsup_d3.loss_iou: 2.1909  mosaic_unsup_d4.loss_cls: 0.1198  mosaic_unsup_d4.loss_bbox: 1.6651  mosaic_unsup_d4.loss_iou: 2.1701
2025/06/23 22:23:20 - mmengine - INFO - Iter(train) [   950/240000]  base_lr: 1.8992e-05 lr: 1.8992e-06  eta: 2 days, 10:42:45  time: 0.7719  data_time: 0.0238  memory: 9627  grad_norm: 1585.3715  loss: 53.1542  sup_loss_cls: 0.5827  sup_loss_bbox: 1.3397  sup_loss_iou: 1.9386  sup_d0.loss_cls: 0.5858  sup_d0.loss_bbox: 1.2760  sup_d0.loss_iou: 1.9105  sup_d1.loss_cls: 0.5870  sup_d1.loss_bbox: 1.3306  sup_d1.loss_iou: 1.9609  sup_d2.loss_cls: 0.5816  sup_d2.loss_bbox: 1.3316  sup_d2.loss_iou: 1.9539  sup_d3.loss_cls: 0.5885  sup_d3.loss_bbox: 1.3719  sup_d3.loss_iou: 1.9534  sup_d4.loss_cls: 0.5829  sup_d4.loss_bbox: 1.3603  sup_d4.loss_iou: 1.9501  mixup_unsup_loss_cls: 0.1176  mixup_unsup_loss_bbox: 0.3925  mixup_unsup_loss_iou: 0.4442  mixup_unsup_d0.loss_cls: 0.1115  mixup_unsup_d0.loss_bbox: 0.3612  mixup_unsup_d0.loss_iou: 0.4265  mixup_unsup_d1.loss_cls: 0.1024  mixup_unsup_d1.loss_bbox: 0.3549  mixup_unsup_d1.loss_iou: 0.4247  mixup_unsup_d2.loss_cls: 0.1118  mixup_unsup_d2.loss_bbox: 0.3699  mixup_unsup_d2.loss_iou: 0.4333  mixup_unsup_d3.loss_cls: 0.1250  mixup_unsup_d3.loss_bbox: 0.3822  mixup_unsup_d3.loss_iou: 0.4422  mixup_unsup_d4.loss_cls: 0.1306  mixup_unsup_d4.loss_bbox: 0.3900  mixup_unsup_d4.loss_iou: 0.4447  mosaic_unsup_loss_cls: 0.1428  mosaic_unsup_loss_bbox: 1.7513  mosaic_unsup_loss_iou: 2.1607  mosaic_unsup_d0.loss_cls: 0.1436  mosaic_unsup_d0.loss_bbox: 1.7572  mosaic_unsup_d0.loss_iou: 2.1606  mosaic_unsup_d1.loss_cls: 0.1367  mosaic_unsup_d1.loss_bbox: 1.7744  mosaic_unsup_d1.loss_iou: 2.1574  mosaic_unsup_d2.loss_cls: 0.1421  mosaic_unsup_d2.loss_bbox: 1.7780  mosaic_unsup_d2.loss_iou: 2.1549  mosaic_unsup_d3.loss_cls: 0.1396  mosaic_unsup_d3.loss_bbox: 1.7884  mosaic_unsup_d3.loss_iou: 2.1522  mosaic_unsup_d4.loss_cls: 0.1475  mosaic_unsup_d4.loss_bbox: 1.7754  mosaic_unsup_d4.loss_iou: 2.1399
2025/06/23 22:24:00 - mmengine - INFO - Exp name: Newdatamixpl05_detr_r50_100_sonar-s1-p10_20250623_220902
2025/06/23 22:24:00 - mmengine - INFO - Iter(train) [  1000/240000]  base_lr: 1.9992e-05 lr: 1.9992e-06  eta: 2 days, 10:23:08  time: 0.7894  data_time: 0.0243  memory: 9885  grad_norm: 1668.9139  loss: 54.1441  sup_loss_cls: 0.6062  sup_loss_bbox: 1.0908  sup_loss_iou: 1.6870  sup_d0.loss_cls: 0.6004  sup_d0.loss_bbox: 1.0755  sup_d0.loss_iou: 1.6728  sup_d1.loss_cls: 0.6187  sup_d1.loss_bbox: 1.1038  sup_d1.loss_iou: 1.7048  sup_d2.loss_cls: 0.6076  sup_d2.loss_bbox: 1.0679  sup_d2.loss_iou: 1.7085  sup_d3.loss_cls: 0.6041  sup_d3.loss_bbox: 1.0945  sup_d3.loss_iou: 1.7535  sup_d4.loss_cls: 0.6054  sup_d4.loss_bbox: 1.0870  sup_d4.loss_iou: 1.7420  mixup_unsup_loss_cls: 0.1372  mixup_unsup_loss_bbox: 0.4232  mixup_unsup_loss_iou: 0.4574  mixup_unsup_d0.loss_cls: 0.1113  mixup_unsup_d0.loss_bbox: 0.4010  mixup_unsup_d0.loss_iou: 0.4515  mixup_unsup_d1.loss_cls: 0.1140  mixup_unsup_d1.loss_bbox: 0.4078  mixup_unsup_d1.loss_iou: 0.4562  mixup_unsup_d2.loss_cls: 0.1270  mixup_unsup_d2.loss_bbox: 0.4219  mixup_unsup_d2.loss_iou: 0.4636  mixup_unsup_d3.loss_cls: 0.1430  mixup_unsup_d3.loss_bbox: 0.4336  mixup_unsup_d3.loss_iou: 0.4740  mixup_unsup_d4.loss_cls: 0.1531  mixup_unsup_d4.loss_bbox: 0.4386  mixup_unsup_d4.loss_iou: 0.4729  mosaic_unsup_loss_cls: 0.0514  mosaic_unsup_loss_bbox: 2.0656  mosaic_unsup_loss_iou: 2.5207  mosaic_unsup_d0.loss_cls: 0.0476  mosaic_unsup_d0.loss_bbox: 2.0785  mosaic_unsup_d0.loss_iou: 2.4823  mosaic_unsup_d1.loss_cls: 0.0449  mosaic_unsup_d1.loss_bbox: 2.0692  mosaic_unsup_d1.loss_iou: 2.4734  mosaic_unsup_d2.loss_cls: 0.0504  mosaic_unsup_d2.loss_bbox: 2.0557  mosaic_unsup_d2.loss_iou: 2.4778  mosaic_unsup_d3.loss_cls: 0.0538  mosaic_unsup_d3.loss_bbox: 2.0444  mosaic_unsup_d3.loss_iou: 2.4974  mosaic_unsup_d4.loss_cls: 0.0533  mosaic_unsup_d4.loss_bbox: 2.0603  mosaic_unsup_d4.loss_iou: 2.4996
2025/06/23 22:24:39 - mmengine - INFO - Iter(train) [  1050/240000]  base_lr: 2.0992e-05 lr: 2.0992e-06  eta: 2 days, 10:05:03  time: 0.7880  data_time: 0.0236  memory: 9886  grad_norm: 2359.7771  loss: 51.3151  sup_loss_cls: 0.6834  sup_loss_bbox: 1.2130  sup_loss_iou: 1.8357  sup_d0.loss_cls: 0.6828  sup_d0.loss_bbox: 1.1751  sup_d0.loss_iou: 1.7539  sup_d1.loss_cls: 0.6915  sup_d1.loss_bbox: 1.2232  sup_d1.loss_iou: 1.8100  sup_d2.loss_cls: 0.6811  sup_d2.loss_bbox: 1.2123  sup_d2.loss_iou: 1.8066  sup_d3.loss_cls: 0.6896  sup_d3.loss_bbox: 1.2325  sup_d3.loss_iou: 1.8417  sup_d4.loss_cls: 0.6920  sup_d4.loss_bbox: 1.2691  sup_d4.loss_iou: 1.8352  mixup_unsup_loss_cls: 0.0479  mixup_unsup_loss_bbox: 0.3520  mixup_unsup_loss_iou: 0.4479  mixup_unsup_d0.loss_cls: 0.0527  mixup_unsup_d0.loss_bbox: 0.2990  mixup_unsup_d0.loss_iou: 0.4091  mixup_unsup_d1.loss_cls: 0.0396  mixup_unsup_d1.loss_bbox: 0.3149  mixup_unsup_d1.loss_iou: 0.4246  mixup_unsup_d2.loss_cls: 0.0449  mixup_unsup_d2.loss_bbox: 0.3243  mixup_unsup_d2.loss_iou: 0.4298  mixup_unsup_d3.loss_cls: 0.0504  mixup_unsup_d3.loss_bbox: 0.3546  mixup_unsup_d3.loss_iou: 0.4568  mixup_unsup_d4.loss_cls: 0.0513  mixup_unsup_d4.loss_bbox: 0.3482  mixup_unsup_d4.loss_iou: 0.4541  mosaic_unsup_loss_cls: 0.0775  mosaic_unsup_loss_bbox: 1.6910  mosaic_unsup_loss_iou: 2.2420  mosaic_unsup_d0.loss_cls: 0.0962  mosaic_unsup_d0.loss_bbox: 1.7190  mosaic_unsup_d0.loss_iou: 2.2516  mosaic_unsup_d1.loss_cls: 0.0877  mosaic_unsup_d1.loss_bbox: 1.6971  mosaic_unsup_d1.loss_iou: 2.2149  mosaic_unsup_d2.loss_cls: 0.0860  mosaic_unsup_d2.loss_bbox: 1.7053  mosaic_unsup_d2.loss_iou: 2.2187  mosaic_unsup_d3.loss_cls: 0.0797  mosaic_unsup_d3.loss_bbox: 1.6951  mosaic_unsup_d3.loss_iou: 2.2276  mosaic_unsup_d4.loss_cls: 0.0716  mosaic_unsup_d4.loss_bbox: 1.7080  mosaic_unsup_d4.loss_iou: 2.2152
2025/06/23 22:25:18 - mmengine - INFO - Iter(train) [  1100/240000]  base_lr: 2.1992e-05 lr: 2.1992e-06  eta: 2 days, 9:46:26  time: 0.7763  data_time: 0.0261  memory: 9884  grad_norm: 2636.7765  loss: 49.7455  sup_loss_cls: 0.5651  sup_loss_bbox: 1.2950  sup_loss_iou: 1.9028  sup_d0.loss_cls: 0.5745  sup_d0.loss_bbox: 1.1116  sup_d0.loss_iou: 1.7248  sup_d1.loss_cls: 0.5723  sup_d1.loss_bbox: 1.1611  sup_d1.loss_iou: 1.7900  sup_d2.loss_cls: 0.5734  sup_d2.loss_bbox: 1.1595  sup_d2.loss_iou: 1.7922  sup_d3.loss_cls: 0.5732  sup_d3.loss_bbox: 1.1932  sup_d3.loss_iou: 1.8412  sup_d4.loss_cls: 0.5726  sup_d4.loss_bbox: 1.2275  sup_d4.loss_iou: 1.8974  mixup_unsup_loss_cls: 0.0666  mixup_unsup_loss_bbox: 0.2976  mixup_unsup_loss_iou: 0.4015  mixup_unsup_d0.loss_cls: 0.0734  mixup_unsup_d0.loss_bbox: 0.2605  mixup_unsup_d0.loss_iou: 0.3631  mixup_unsup_d1.loss_cls: 0.0544  mixup_unsup_d1.loss_bbox: 0.2686  mixup_unsup_d1.loss_iou: 0.3753  mixup_unsup_d2.loss_cls: 0.0570  mixup_unsup_d2.loss_bbox: 0.2765  mixup_unsup_d2.loss_iou: 0.3831  mixup_unsup_d3.loss_cls: 0.0697  mixup_unsup_d3.loss_bbox: 0.2762  mixup_unsup_d3.loss_iou: 0.3820  mixup_unsup_d4.loss_cls: 0.0706  mixup_unsup_d4.loss_bbox: 0.2875  mixup_unsup_d4.loss_iou: 0.3905  mosaic_unsup_loss_cls: 0.2554  mosaic_unsup_loss_bbox: 1.6280  mosaic_unsup_loss_iou: 2.1321  mosaic_unsup_d0.loss_cls: 0.2142  mosaic_unsup_d0.loss_bbox: 1.6072  mosaic_unsup_d0.loss_iou: 2.1430  mosaic_unsup_d1.loss_cls: 0.2167  mosaic_unsup_d1.loss_bbox: 1.6079  mosaic_unsup_d1.loss_iou: 2.1448  mosaic_unsup_d2.loss_cls: 0.2201  mosaic_unsup_d2.loss_bbox: 1.6242  mosaic_unsup_d2.loss_iou: 2.1378  mosaic_unsup_d3.loss_cls: 0.2286  mosaic_unsup_d3.loss_bbox: 1.6226  mosaic_unsup_d3.loss_iou: 2.1191  mosaic_unsup_d4.loss_cls: 0.2396  mosaic_unsup_d4.loss_bbox: 1.6160  mosaic_unsup_d4.loss_iou: 2.1066
2025/06/23 22:25:57 - mmengine - INFO - Iter(train) [  1150/240000]  base_lr: 2.2992e-05 lr: 2.2992e-06  eta: 2 days, 9:27:56  time: 0.7680  data_time: 0.0236  memory: 9886  grad_norm: 2747.2015  loss: 56.9658  sup_loss_cls: 0.6546  sup_loss_bbox: 1.1388  sup_loss_iou: 1.6571  sup_d0.loss_cls: 0.6066  sup_d0.loss_bbox: 1.1241  sup_d0.loss_iou: 1.6429  sup_d1.loss_cls: 0.6390  sup_d1.loss_bbox: 1.1752  sup_d1.loss_iou: 1.7236  sup_d2.loss_cls: 0.6429  sup_d2.loss_bbox: 1.1175  sup_d2.loss_iou: 1.6427  sup_d3.loss_cls: 0.6489  sup_d3.loss_bbox: 1.1337  sup_d3.loss_iou: 1.6966  sup_d4.loss_cls: 0.6433  sup_d4.loss_bbox: 1.1646  sup_d4.loss_iou: 1.7402  mixup_unsup_loss_cls: 0.0959  mixup_unsup_loss_bbox: 0.6281  mixup_unsup_loss_iou: 0.7572  mixup_unsup_d0.loss_cls: 0.1043  mixup_unsup_d0.loss_bbox: 0.5955  mixup_unsup_d0.loss_iou: 0.7357  mixup_unsup_d1.loss_cls: 0.0979  mixup_unsup_d1.loss_bbox: 0.6162  mixup_unsup_d1.loss_iou: 0.7478  mixup_unsup_d2.loss_cls: 0.0918  mixup_unsup_d2.loss_bbox: 0.6273  mixup_unsup_d2.loss_iou: 0.7515  mixup_unsup_d3.loss_cls: 0.0988  mixup_unsup_d3.loss_bbox: 0.6150  mixup_unsup_d3.loss_iou: 0.7420  mixup_unsup_d4.loss_cls: 0.1040  mixup_unsup_d4.loss_bbox: 0.6245  mixup_unsup_d4.loss_iou: 0.7525  mosaic_unsup_loss_cls: 0.2634  mosaic_unsup_loss_bbox: 1.9067  mosaic_unsup_loss_iou: 2.3859  mosaic_unsup_d0.loss_cls: 0.2609  mosaic_unsup_d0.loss_bbox: 1.9196  mosaic_unsup_d0.loss_iou: 2.3966  mosaic_unsup_d1.loss_cls: 0.2618  mosaic_unsup_d1.loss_bbox: 1.9137  mosaic_unsup_d1.loss_iou: 2.3956  mosaic_unsup_d2.loss_cls: 0.2444  mosaic_unsup_d2.loss_bbox: 1.9229  mosaic_unsup_d2.loss_iou: 2.3924  mosaic_unsup_d3.loss_cls: 0.2545  mosaic_unsup_d3.loss_bbox: 1.9142  mosaic_unsup_d3.loss_iou: 2.3927  mosaic_unsup_d4.loss_cls: 0.2673  mosaic_unsup_d4.loss_bbox: 1.9140  mosaic_unsup_d4.loss_iou: 2.3810
2025/06/23 22:26:36 - mmengine - INFO - Iter(train) [  1200/240000]  base_lr: 2.3992e-05 lr: 2.3992e-06  eta: 2 days, 9:13:10  time: 0.7814  data_time: 0.0238  memory: 9880  grad_norm: 3374.6871  loss: 53.6522  sup_loss_cls: 0.6493  sup_loss_bbox: 1.1001  sup_loss_iou: 1.6226  sup_d0.loss_cls: 0.6448  sup_d0.loss_bbox: 1.1044  sup_d0.loss_iou: 1.5172  sup_d1.loss_cls: 0.6391  sup_d1.loss_bbox: 1.1335  sup_d1.loss_iou: 1.5935  sup_d2.loss_cls: 0.6352  sup_d2.loss_bbox: 1.0854  sup_d2.loss_iou: 1.5957  sup_d3.loss_cls: 0.6374  sup_d3.loss_bbox: 1.1066  sup_d3.loss_iou: 1.6083  sup_d4.loss_cls: 0.6372  sup_d4.loss_bbox: 1.1646  sup_d4.loss_iou: 1.6037  mixup_unsup_loss_cls: 0.0060  mixup_unsup_loss_bbox: 0.3552  mixup_unsup_loss_iou: 0.4455  mixup_unsup_d0.loss_cls: 0.0072  mixup_unsup_d0.loss_bbox: 0.3303  mixup_unsup_d0.loss_iou: 0.4300  mixup_unsup_d1.loss_cls: 0.0054  mixup_unsup_d1.loss_bbox: 0.3522  mixup_unsup_d1.loss_iou: 0.4430  mixup_unsup_d2.loss_cls: 0.0068  mixup_unsup_d2.loss_bbox: 0.3430  mixup_unsup_d2.loss_iou: 0.4376  mixup_unsup_d3.loss_cls: 0.0061  mixup_unsup_d3.loss_bbox: 0.3508  mixup_unsup_d3.loss_iou: 0.4432  mixup_unsup_d4.loss_cls: 0.0056  mixup_unsup_d4.loss_bbox: 0.3410  mixup_unsup_d4.loss_iou: 0.4382  mosaic_unsup_loss_cls: 0.2451  mosaic_unsup_loss_bbox: 2.0949  mosaic_unsup_loss_iou: 2.4819  mosaic_unsup_d0.loss_cls: 0.2045  mosaic_unsup_d0.loss_bbox: 2.0995  mosaic_unsup_d0.loss_iou: 2.4698  mosaic_unsup_d1.loss_cls: 0.2221  mosaic_unsup_d1.loss_bbox: 2.0994  mosaic_unsup_d1.loss_iou: 2.4708  mosaic_unsup_d2.loss_cls: 0.2291  mosaic_unsup_d2.loss_bbox: 2.0906  mosaic_unsup_d2.loss_iou: 2.4697  mosaic_unsup_d3.loss_cls: 0.2382  mosaic_unsup_d3.loss_bbox: 2.1128  mosaic_unsup_d3.loss_iou: 2.4689  mosaic_unsup_d4.loss_cls: 0.2458  mosaic_unsup_d4.loss_bbox: 2.1167  mosaic_unsup_d4.loss_iou: 2.4672
2025/06/23 22:27:14 - mmengine - INFO - Iter(train) [  1250/240000]  base_lr: 2.4992e-05 lr: 2.4992e-06  eta: 2 days, 8:57:21  time: 0.7677  data_time: 0.0237  memory: 9886  grad_norm: 1829.5795  loss: 45.2694  sup_loss_cls: 0.5632  sup_loss_bbox: 1.0196  sup_loss_iou: 1.6673  sup_d0.loss_cls: 0.5536  sup_d0.loss_bbox: 0.9643  sup_d0.loss_iou: 1.6282  sup_d1.loss_cls: 0.5796  sup_d1.loss_bbox: 1.0249  sup_d1.loss_iou: 1.6690  sup_d2.loss_cls: 0.5728  sup_d2.loss_bbox: 0.9822  sup_d2.loss_iou: 1.6516  sup_d3.loss_cls: 0.5683  sup_d3.loss_bbox: 1.0423  sup_d3.loss_iou: 1.6427  sup_d4.loss_cls: 0.5651  sup_d4.loss_bbox: 1.0400  sup_d4.loss_iou: 1.6759  mixup_unsup_loss_cls: 0.0111  mixup_unsup_loss_bbox: 0.1944  mixup_unsup_loss_iou: 0.2682  mixup_unsup_d0.loss_cls: 0.0139  mixup_unsup_d0.loss_bbox: 0.1942  mixup_unsup_d0.loss_iou: 0.2666  mixup_unsup_d1.loss_cls: 0.0097  mixup_unsup_d1.loss_bbox: 0.1940  mixup_unsup_d1.loss_iou: 0.2673  mixup_unsup_d2.loss_cls: 0.0124  mixup_unsup_d2.loss_bbox: 0.1963  mixup_unsup_d2.loss_iou: 0.2694  mixup_unsup_d3.loss_cls: 0.0123  mixup_unsup_d3.loss_bbox: 0.1912  mixup_unsup_d3.loss_iou: 0.2693  mixup_unsup_d4.loss_cls: 0.0126  mixup_unsup_d4.loss_bbox: 0.1952  mixup_unsup_d4.loss_iou: 0.2702  mosaic_unsup_loss_cls: 0.0133  mosaic_unsup_loss_bbox: 1.6884  mosaic_unsup_loss_iou: 2.1357  mosaic_unsup_d0.loss_cls: 0.0203  mosaic_unsup_d0.loss_bbox: 1.6805  mosaic_unsup_d0.loss_iou: 2.1127  mosaic_unsup_d1.loss_cls: 0.0172  mosaic_unsup_d1.loss_bbox: 1.6838  mosaic_unsup_d1.loss_iou: 2.1126  mosaic_unsup_d2.loss_cls: 0.0176  mosaic_unsup_d2.loss_bbox: 1.6861  mosaic_unsup_d2.loss_iou: 2.1309  mosaic_unsup_d3.loss_cls: 0.0144  mosaic_unsup_d3.loss_bbox: 1.7082  mosaic_unsup_d3.loss_iou: 2.1463  mosaic_unsup_d4.loss_cls: 0.0129  mosaic_unsup_d4.loss_bbox: 1.6983  mosaic_unsup_d4.loss_iou: 2.1311
2025/06/23 22:27:53 - mmengine - INFO - Iter(train) [  1300/240000]  base_lr: 2.5993e-05 lr: 2.5993e-06  eta: 2 days, 8:43:02  time: 0.7700  data_time: 0.0237  memory: 9884  grad_norm: 2464.8350  loss: 46.6531  sup_loss_cls: 0.5948  sup_loss_bbox: 1.0366  sup_loss_iou: 1.6417  sup_d0.loss_cls: 0.5822  sup_d0.loss_bbox: 0.9125  sup_d0.loss_iou: 1.4460  sup_d1.loss_cls: 0.6008  sup_d1.loss_bbox: 0.9681  sup_d1.loss_iou: 1.5246  sup_d2.loss_cls: 0.6004  sup_d2.loss_bbox: 0.9310  sup_d2.loss_iou: 1.4577  sup_d3.loss_cls: 0.5955  sup_d3.loss_bbox: 1.0067  sup_d3.loss_iou: 1.5475  sup_d4.loss_cls: 0.6052  sup_d4.loss_bbox: 1.0703  sup_d4.loss_iou: 1.6820  mixup_unsup_loss_cls: 0.0121  mixup_unsup_loss_bbox: 0.2352  mixup_unsup_loss_iou: 0.2864  mixup_unsup_d0.loss_cls: 0.0140  mixup_unsup_d0.loss_bbox: 0.2242  mixup_unsup_d0.loss_iou: 0.2678  mixup_unsup_d1.loss_cls: 0.0100  mixup_unsup_d1.loss_bbox: 0.2261  mixup_unsup_d1.loss_iou: 0.2699  mixup_unsup_d2.loss_cls: 0.0113  mixup_unsup_d2.loss_bbox: 0.2383  mixup_unsup_d2.loss_iou: 0.2854  mixup_unsup_d3.loss_cls: 0.0111  mixup_unsup_d3.loss_bbox: 0.2214  mixup_unsup_d3.loss_iou: 0.2759  mixup_unsup_d4.loss_cls: 0.0111  mixup_unsup_d4.loss_bbox: 0.2386  mixup_unsup_d4.loss_iou: 0.2827  mosaic_unsup_loss_cls: 0.2130  mosaic_unsup_loss_bbox: 1.6677  mosaic_unsup_loss_iou: 2.2338  mosaic_unsup_d0.loss_cls: 0.2307  mosaic_unsup_d0.loss_bbox: 1.6763  mosaic_unsup_d0.loss_iou: 2.2325  mosaic_unsup_d1.loss_cls: 0.2368  mosaic_unsup_d1.loss_bbox: 1.6654  mosaic_unsup_d1.loss_iou: 2.2198  mosaic_unsup_d2.loss_cls: 0.2090  mosaic_unsup_d2.loss_bbox: 1.6786  mosaic_unsup_d2.loss_iou: 2.2057  mosaic_unsup_d3.loss_cls: 0.2075  mosaic_unsup_d3.loss_bbox: 1.7039  mosaic_unsup_d3.loss_iou: 2.2257  mosaic_unsup_d4.loss_cls: 0.2094  mosaic_unsup_d4.loss_bbox: 1.6693  mosaic_unsup_d4.loss_iou: 2.2426
2025/06/23 22:28:31 - mmengine - INFO - Iter(train) [  1350/240000]  base_lr: 2.6993e-05 lr: 2.6993e-06  eta: 2 days, 8:29:37  time: 0.7691  data_time: 0.0223  memory: 9885  grad_norm: 2685.4735  loss: 48.5562  sup_loss_cls: 0.7055  sup_loss_bbox: 1.1735  sup_loss_iou: 1.8256  sup_d0.loss_cls: 0.6852  sup_d0.loss_bbox: 1.0051  sup_d0.loss_iou: 1.6355  sup_d1.loss_cls: 0.7279  sup_d1.loss_bbox: 1.0959  sup_d1.loss_iou: 1.7453  sup_d2.loss_cls: 0.6865  sup_d2.loss_bbox: 0.9967  sup_d2.loss_iou: 1.6046  sup_d3.loss_cls: 0.6903  sup_d3.loss_bbox: 1.1117  sup_d3.loss_iou: 1.7370  sup_d4.loss_cls: 0.6766  sup_d4.loss_bbox: 1.2321  sup_d4.loss_iou: 1.8072  mixup_unsup_loss_cls: 0.1150  mixup_unsup_loss_bbox: 0.4146  mixup_unsup_loss_iou: 0.5625  mixup_unsup_d0.loss_cls: 0.1139  mixup_unsup_d0.loss_bbox: 0.4225  mixup_unsup_d0.loss_iou: 0.5612  mixup_unsup_d1.loss_cls: 0.1061  mixup_unsup_d1.loss_bbox: 0.4152  mixup_unsup_d1.loss_iou: 0.5629  mixup_unsup_d2.loss_cls: 0.1105  mixup_unsup_d2.loss_bbox: 0.4026  mixup_unsup_d2.loss_iou: 0.5415  mixup_unsup_d3.loss_cls: 0.1077  mixup_unsup_d3.loss_bbox: 0.4136  mixup_unsup_d3.loss_iou: 0.5446  mixup_unsup_d4.loss_cls: 0.1272  mixup_unsup_d4.loss_bbox: 0.4151  mixup_unsup_d4.loss_iou: 0.5597  mosaic_unsup_loss_cls: 0.0262  mosaic_unsup_loss_bbox: 1.5249  mosaic_unsup_loss_iou: 1.9361  mosaic_unsup_d0.loss_cls: 0.0318  mosaic_unsup_d0.loss_bbox: 1.5191  mosaic_unsup_d0.loss_iou: 1.9249  mosaic_unsup_d1.loss_cls: 0.0230  mosaic_unsup_d1.loss_bbox: 1.5258  mosaic_unsup_d1.loss_iou: 1.9166  mosaic_unsup_d2.loss_cls: 0.0282  mosaic_unsup_d2.loss_bbox: 1.5267  mosaic_unsup_d2.loss_iou: 1.9589  mosaic_unsup_d3.loss_cls: 0.0272  mosaic_unsup_d3.loss_bbox: 1.5194  mosaic_unsup_d3.loss_iou: 1.9587  mosaic_unsup_d4.loss_cls: 0.0320  mosaic_unsup_d4.loss_bbox: 1.5196  mosaic_unsup_d4.loss_iou: 1.9187
2025/06/23 22:29:11 - mmengine - INFO - Iter(train) [  1400/240000]  base_lr: 2.7993e-05 lr: 2.7993e-06  eta: 2 days, 8:22:34  time: 0.8075  data_time: 0.0248  memory: 9885  grad_norm: 1815.0313  loss: 55.2298  sup_loss_cls: 0.5223  sup_loss_bbox: 0.9729  sup_loss_iou: 1.6003  sup_d0.loss_cls: 0.5033  sup_d0.loss_bbox: 0.8530  sup_d0.loss_iou: 1.4745  sup_d1.loss_cls: 0.5125  sup_d1.loss_bbox: 0.9471  sup_d1.loss_iou: 1.6127  sup_d2.loss_cls: 0.5091  sup_d2.loss_bbox: 0.8744  sup_d2.loss_iou: 1.5150  sup_d3.loss_cls: 0.5236  sup_d3.loss_bbox: 1.0279  sup_d3.loss_iou: 1.6433  sup_d4.loss_cls: 0.5343  sup_d4.loss_bbox: 1.0728  sup_d4.loss_iou: 1.6904  mixup_unsup_loss_cls: 0.0632  mixup_unsup_loss_bbox: 0.4725  mixup_unsup_loss_iou: 0.6229  mixup_unsup_d0.loss_cls: 0.0628  mixup_unsup_d0.loss_bbox: 0.4504  mixup_unsup_d0.loss_iou: 0.5999  mixup_unsup_d1.loss_cls: 0.0627  mixup_unsup_d1.loss_bbox: 0.4635  mixup_unsup_d1.loss_iou: 0.6120  mixup_unsup_d2.loss_cls: 0.0610  mixup_unsup_d2.loss_bbox: 0.4639  mixup_unsup_d2.loss_iou: 0.6085  mixup_unsup_d3.loss_cls: 0.0584  mixup_unsup_d3.loss_bbox: 0.4590  mixup_unsup_d3.loss_iou: 0.6038  mixup_unsup_d4.loss_cls: 0.0610  mixup_unsup_d4.loss_bbox: 0.4837  mixup_unsup_d4.loss_iou: 0.6313  mosaic_unsup_loss_cls: 0.1560  mosaic_unsup_loss_bbox: 2.1020  mosaic_unsup_loss_iou: 2.7611  mosaic_unsup_d0.loss_cls: 0.1455  mosaic_unsup_d0.loss_bbox: 2.0613  mosaic_unsup_d0.loss_iou: 2.7383  mosaic_unsup_d1.loss_cls: 0.1464  mosaic_unsup_d1.loss_bbox: 2.0807  mosaic_unsup_d1.loss_iou: 2.7305  mosaic_unsup_d2.loss_cls: 0.1486  mosaic_unsup_d2.loss_bbox: 2.1179  mosaic_unsup_d2.loss_iou: 2.7719  mosaic_unsup_d3.loss_cls: 0.1370  mosaic_unsup_d3.loss_bbox: 2.1263  mosaic_unsup_d3.loss_iou: 2.7682  mosaic_unsup_d4.loss_cls: 0.1482  mosaic_unsup_d4.loss_bbox: 2.1048  mosaic_unsup_d4.loss_iou: 2.7551
2025/06/23 22:29:50 - mmengine - INFO - Iter(train) [  1450/240000]  base_lr: 2.8993e-05 lr: 2.8993e-06  eta: 2 days, 8:11:38  time: 0.7760  data_time: 0.0229  memory: 9885  grad_norm: 2198.1098  loss: 41.3178  sup_loss_cls: 0.6064  sup_loss_bbox: 0.8220  sup_loss_iou: 1.5145  sup_d0.loss_cls: 0.5680  sup_d0.loss_bbox: 0.8454  sup_d0.loss_iou: 1.5413  sup_d1.loss_cls: 0.5822  sup_d1.loss_bbox: 0.9190  sup_d1.loss_iou: 1.6280  sup_d2.loss_cls: 0.5814  sup_d2.loss_bbox: 0.7772  sup_d2.loss_iou: 1.4355  sup_d3.loss_cls: 0.5929  sup_d3.loss_bbox: 0.8360  sup_d3.loss_iou: 1.5280  sup_d4.loss_cls: 0.5958  sup_d4.loss_bbox: 0.8922  sup_d4.loss_iou: 1.6391  mixup_unsup_loss_cls: 0.0005  mixup_unsup_loss_bbox: 0.0866  mixup_unsup_loss_iou: 0.0880  mixup_unsup_d0.loss_cls: 0.0009  mixup_unsup_d0.loss_bbox: 0.0764  mixup_unsup_d0.loss_iou: 0.0787  mixup_unsup_d1.loss_cls: 0.0005  mixup_unsup_d1.loss_bbox: 0.0765  mixup_unsup_d1.loss_iou: 0.0804  mixup_unsup_d2.loss_cls: 0.0004  mixup_unsup_d2.loss_bbox: 0.0787  mixup_unsup_d2.loss_iou: 0.0818  mixup_unsup_d3.loss_cls: 0.0007  mixup_unsup_d3.loss_bbox: 0.0784  mixup_unsup_d3.loss_iou: 0.0823  mixup_unsup_d4.loss_cls: 0.0005  mixup_unsup_d4.loss_bbox: 0.0845  mixup_unsup_d4.loss_iou: 0.0878  mosaic_unsup_loss_cls: 0.0173  mosaic_unsup_loss_bbox: 1.5818  mosaic_unsup_loss_iou: 2.1483  mosaic_unsup_d0.loss_cls: 0.0258  mosaic_unsup_d0.loss_bbox: 1.5660  mosaic_unsup_d0.loss_iou: 2.1361  mosaic_unsup_d1.loss_cls: 0.0210  mosaic_unsup_d1.loss_bbox: 1.5693  mosaic_unsup_d1.loss_iou: 2.1267  mosaic_unsup_d2.loss_cls: 0.0223  mosaic_unsup_d2.loss_bbox: 1.5849  mosaic_unsup_d2.loss_iou: 2.1415  mosaic_unsup_d3.loss_cls: 0.0203  mosaic_unsup_d3.loss_bbox: 1.5844  mosaic_unsup_d3.loss_iou: 2.1488  mosaic_unsup_d4.loss_cls: 0.0198  mosaic_unsup_d4.loss_bbox: 1.5830  mosaic_unsup_d4.loss_iou: 2.1322
2025/06/23 22:30:29 - mmengine - INFO - Iter(train) [  1500/240000]  base_lr: 2.9993e-05 lr: 2.9993e-06  eta: 2 days, 8:01:18  time: 0.7755  data_time: 0.0238  memory: 9702  grad_norm: 1731.1697  loss: 46.5175  sup_loss_cls: 0.6034  sup_loss_bbox: 0.8084  sup_loss_iou: 1.3956  sup_d0.loss_cls: 0.5653  sup_d0.loss_bbox: 0.7840  sup_d0.loss_iou: 1.3636  sup_d1.loss_cls: 0.5785  sup_d1.loss_bbox: 0.8087  sup_d1.loss_iou: 1.3316  sup_d2.loss_cls: 0.5922  sup_d2.loss_bbox: 0.7530  sup_d2.loss_iou: 1.2148  sup_d3.loss_cls: 0.5907  sup_d3.loss_bbox: 0.7931  sup_d3.loss_iou: 1.2694  sup_d4.loss_cls: 0.6075  sup_d4.loss_bbox: 0.8207  sup_d4.loss_iou: 1.3401  mixup_unsup_loss_cls: 0.0262  mixup_unsup_loss_bbox: 0.1519  mixup_unsup_loss_iou: 0.2162  mixup_unsup_d0.loss_cls: 0.0310  mixup_unsup_d0.loss_bbox: 0.1522  mixup_unsup_d0.loss_iou: 0.2133  mixup_unsup_d1.loss_cls: 0.0320  mixup_unsup_d1.loss_bbox: 0.1457  mixup_unsup_d1.loss_iou: 0.2115  mixup_unsup_d2.loss_cls: 0.0349  mixup_unsup_d2.loss_bbox: 0.1443  mixup_unsup_d2.loss_iou: 0.2096  mixup_unsup_d3.loss_cls: 0.0341  mixup_unsup_d3.loss_bbox: 0.1438  mixup_unsup_d3.loss_iou: 0.2077  mixup_unsup_d4.loss_cls: 0.0330  mixup_unsup_d4.loss_bbox: 0.1423  mixup_unsup_d4.loss_iou: 0.2088  mosaic_unsup_loss_cls: 0.2170  mosaic_unsup_loss_bbox: 2.0830  mosaic_unsup_loss_iou: 2.3553  mosaic_unsup_d0.loss_cls: 0.2756  mosaic_unsup_d0.loss_bbox: 1.9957  mosaic_unsup_d0.loss_iou: 2.4037  mosaic_unsup_d1.loss_cls: 0.2648  mosaic_unsup_d1.loss_bbox: 2.0188  mosaic_unsup_d1.loss_iou: 2.3844  mosaic_unsup_d2.loss_cls: 0.2451  mosaic_unsup_d2.loss_bbox: 2.0370  mosaic_unsup_d2.loss_iou: 2.3722  mosaic_unsup_d3.loss_cls: 0.2285  mosaic_unsup_d3.loss_bbox: 2.0387  mosaic_unsup_d3.loss_iou: 2.3832  mosaic_unsup_d4.loss_cls: 0.2366  mosaic_unsup_d4.loss_bbox: 2.0532  mosaic_unsup_d4.loss_iou: 2.3657
2025/06/23 22:31:06 - mmengine - INFO - Iter(train) [  1550/240000]  base_lr: 3.0993e-05 lr: 3.0993e-06  eta: 2 days, 7:46:27  time: 0.7352  data_time: 0.0229  memory: 9884  grad_norm: 1567.7195  loss: 40.4532  sup_loss_cls: 0.5701  sup_loss_bbox: 0.7500  sup_loss_iou: 1.3159  sup_d0.loss_cls: 0.5574  sup_d0.loss_bbox: 0.7035  sup_d0.loss_iou: 1.3081  sup_d1.loss_cls: 0.5661  sup_d1.loss_bbox: 0.7570  sup_d1.loss_iou: 1.3086  sup_d2.loss_cls: 0.5714  sup_d2.loss_bbox: 0.7353  sup_d2.loss_iou: 1.3025  sup_d3.loss_cls: 0.5757  sup_d3.loss_bbox: 0.7298  sup_d3.loss_iou: 1.3541  sup_d4.loss_cls: 0.5690  sup_d4.loss_bbox: 0.7625  sup_d4.loss_iou: 1.3021  mixup_unsup_loss_cls: 0.0319  mixup_unsup_loss_bbox: 0.0793  mixup_unsup_loss_iou: 0.0965  mixup_unsup_d0.loss_cls: 0.0312  mixup_unsup_d0.loss_bbox: 0.0787  mixup_unsup_d0.loss_iou: 0.0954  mixup_unsup_d1.loss_cls: 0.0288  mixup_unsup_d1.loss_bbox: 0.0796  mixup_unsup_d1.loss_iou: 0.0960  mixup_unsup_d2.loss_cls: 0.0295  mixup_unsup_d2.loss_bbox: 0.0797  mixup_unsup_d2.loss_iou: 0.0979  mixup_unsup_d3.loss_cls: 0.0285  mixup_unsup_d3.loss_bbox: 0.0762  mixup_unsup_d3.loss_iou: 0.0952  mixup_unsup_d4.loss_cls: 0.0298  mixup_unsup_d4.loss_bbox: 0.0801  mixup_unsup_d4.loss_iou: 0.0980  mosaic_unsup_loss_cls: 0.0164  mosaic_unsup_loss_bbox: 1.6435  mosaic_unsup_loss_iou: 2.2422  mosaic_unsup_d0.loss_cls: 0.0311  mosaic_unsup_d0.loss_bbox: 1.6720  mosaic_unsup_d0.loss_iou: 2.2480  mosaic_unsup_d1.loss_cls: 0.0205  mosaic_unsup_d1.loss_bbox: 1.6678  mosaic_unsup_d1.loss_iou: 2.2341  mosaic_unsup_d2.loss_cls: 0.0182  mosaic_unsup_d2.loss_bbox: 1.6575  mosaic_unsup_d2.loss_iou: 2.2282  mosaic_unsup_d3.loss_cls: 0.0202  mosaic_unsup_d3.loss_bbox: 1.6591  mosaic_unsup_d3.loss_iou: 2.2338  mosaic_unsup_d4.loss_cls: 0.0192  mosaic_unsup_d4.loss_bbox: 1.6461  mosaic_unsup_d4.loss_iou: 2.2239
2025/06/23 22:31:44 - mmengine - INFO - Iter(train) [  1600/240000]  base_lr: 3.1993e-05 lr: 3.1993e-06  eta: 2 days, 7:36:28  time: 0.7673  data_time: 0.0229  memory: 9625  grad_norm: 1601.6501  loss: 45.8227  sup_loss_cls: 0.5600  sup_loss_bbox: 0.8628  sup_loss_iou: 1.5648  sup_d0.loss_cls: 0.5372  sup_d0.loss_bbox: 0.6793  sup_d0.loss_iou: 1.2940  sup_d1.loss_cls: 0.5496  sup_d1.loss_bbox: 0.7574  sup_d1.loss_iou: 1.3241  sup_d2.loss_cls: 0.5686  sup_d2.loss_bbox: 0.7288  sup_d2.loss_iou: 1.3335  sup_d3.loss_cls: 0.5576  sup_d3.loss_bbox: 0.7372  sup_d3.loss_iou: 1.3569  sup_d4.loss_cls: 0.5626  sup_d4.loss_bbox: 0.7952  sup_d4.loss_iou: 1.4066  mixup_unsup_loss_cls: 0.0493  mixup_unsup_loss_bbox: 0.3336  mixup_unsup_loss_iou: 0.3554  mixup_unsup_d0.loss_cls: 0.0534  mixup_unsup_d0.loss_bbox: 0.3018  mixup_unsup_d0.loss_iou: 0.3356  mixup_unsup_d1.loss_cls: 0.0453  mixup_unsup_d1.loss_bbox: 0.3059  mixup_unsup_d1.loss_iou: 0.3417  mixup_unsup_d2.loss_cls: 0.0490  mixup_unsup_d2.loss_bbox: 0.3232  mixup_unsup_d2.loss_iou: 0.3478  mixup_unsup_d3.loss_cls: 0.0485  mixup_unsup_d3.loss_bbox: 0.3311  mixup_unsup_d3.loss_iou: 0.3540  mixup_unsup_d4.loss_cls: 0.0485  mixup_unsup_d4.loss_bbox: 0.3328  mixup_unsup_d4.loss_iou: 0.3559  mosaic_unsup_loss_cls: 0.1155  mosaic_unsup_loss_bbox: 1.9092  mosaic_unsup_loss_iou: 2.2146  mosaic_unsup_d0.loss_cls: 0.1097  mosaic_unsup_d0.loss_bbox: 1.9003  mosaic_unsup_d0.loss_iou: 2.2148  mosaic_unsup_d1.loss_cls: 0.1023  mosaic_unsup_d1.loss_bbox: 1.8908  mosaic_unsup_d1.loss_iou: 2.2117  mosaic_unsup_d2.loss_cls: 0.1003  mosaic_unsup_d2.loss_bbox: 1.8846  mosaic_unsup_d2.loss_iou: 2.2157  mosaic_unsup_d3.loss_cls: 0.1117  mosaic_unsup_d3.loss_bbox: 1.8997  mosaic_unsup_d3.loss_iou: 2.2106  mosaic_unsup_d4.loss_cls: 0.1177  mosaic_unsup_d4.loss_bbox: 1.9139  mosaic_unsup_d4.loss_iou: 2.2107
2025/06/23 22:32:21 - mmengine - INFO - Iter(train) [  1650/240000]  base_lr: 3.2993e-05 lr: 3.2993e-06  eta: 2 days, 7:23:59  time: 0.7418  data_time: 0.0227  memory: 9885  grad_norm: 1206.5062  loss: 41.5473  sup_loss_cls: 0.5270  sup_loss_bbox: 0.7280  sup_loss_iou: 1.2887  sup_d0.loss_cls: 0.5198  sup_d0.loss_bbox: 0.6744  sup_d0.loss_iou: 1.1887  sup_d1.loss_cls: 0.5157  sup_d1.loss_bbox: 0.7242  sup_d1.loss_iou: 1.2102  sup_d2.loss_cls: 0.5205  sup_d2.loss_bbox: 0.6965  sup_d2.loss_iou: 1.1991  sup_d3.loss_cls: 0.5188  sup_d3.loss_bbox: 0.6983  sup_d3.loss_iou: 1.2207  sup_d4.loss_cls: 0.5309  sup_d4.loss_bbox: 0.7231  sup_d4.loss_iou: 1.2663  mixup_unsup_loss_cls: 0.0761  mixup_unsup_loss_bbox: 0.3331  mixup_unsup_loss_iou: 0.4346  mixup_unsup_d0.loss_cls: 0.0871  mixup_unsup_d0.loss_bbox: 0.3404  mixup_unsup_d0.loss_iou: 0.4388  mixup_unsup_d1.loss_cls: 0.0777  mixup_unsup_d1.loss_bbox: 0.3162  mixup_unsup_d1.loss_iou: 0.4206  mixup_unsup_d2.loss_cls: 0.0840  mixup_unsup_d2.loss_bbox: 0.3042  mixup_unsup_d2.loss_iou: 0.4129  mixup_unsup_d3.loss_cls: 0.0824  mixup_unsup_d3.loss_bbox: 0.3272  mixup_unsup_d3.loss_iou: 0.4269  mixup_unsup_d4.loss_cls: 0.0776  mixup_unsup_d4.loss_bbox: 0.3263  mixup_unsup_d4.loss_iou: 0.4276  mosaic_unsup_loss_cls: 0.0110  mosaic_unsup_loss_bbox: 1.4809  mosaic_unsup_loss_iou: 2.1293  mosaic_unsup_d0.loss_cls: 0.0194  mosaic_unsup_d0.loss_bbox: 1.4923  mosaic_unsup_d0.loss_iou: 2.1158  mosaic_unsup_d1.loss_cls: 0.0130  mosaic_unsup_d1.loss_bbox: 1.4954  mosaic_unsup_d1.loss_iou: 2.1459  mosaic_unsup_d2.loss_cls: 0.0120  mosaic_unsup_d2.loss_bbox: 1.5005  mosaic_unsup_d2.loss_iou: 2.1492  mosaic_unsup_d3.loss_cls: 0.0114  mosaic_unsup_d3.loss_bbox: 1.4769  mosaic_unsup_d3.loss_iou: 2.1240  mosaic_unsup_d4.loss_cls: 0.0115  mosaic_unsup_d4.loss_bbox: 1.4932  mosaic_unsup_d4.loss_iou: 2.1213
2025/06/23 22:32:59 - mmengine - INFO - Iter(train) [  1700/240000]  base_lr: 3.3993e-05 lr: 3.3993e-06  eta: 2 days, 7:13:58  time: 0.7569  data_time: 0.0228  memory: 9627  grad_norm: 1515.1447  loss: 44.8505  sup_loss_cls: 0.5927  sup_loss_bbox: 0.7336  sup_loss_iou: 1.2854  sup_d0.loss_cls: 0.5360  sup_d0.loss_bbox: 0.7101  sup_d0.loss_iou: 1.2196  sup_d1.loss_cls: 0.5805  sup_d1.loss_bbox: 0.6714  sup_d1.loss_iou: 1.1790  sup_d2.loss_cls: 0.5914  sup_d2.loss_bbox: 0.6721  sup_d2.loss_iou: 1.1075  sup_d3.loss_cls: 0.6026  sup_d3.loss_bbox: 0.6871  sup_d3.loss_iou: 1.1998  sup_d4.loss_cls: 0.6018  sup_d4.loss_bbox: 0.6708  sup_d4.loss_iou: 1.2013  mixup_unsup_loss_cls: 0.1552  mixup_unsup_loss_bbox: 0.2546  mixup_unsup_loss_iou: 0.3868  mixup_unsup_d0.loss_cls: 0.1717  mixup_unsup_d0.loss_bbox: 0.2427  mixup_unsup_d0.loss_iou: 0.3771  mixup_unsup_d1.loss_cls: 0.1298  mixup_unsup_d1.loss_bbox: 0.2663  mixup_unsup_d1.loss_iou: 0.3838  mixup_unsup_d2.loss_cls: 0.1242  mixup_unsup_d2.loss_bbox: 0.2986  mixup_unsup_d2.loss_iou: 0.3835  mixup_unsup_d3.loss_cls: 0.1537  mixup_unsup_d3.loss_bbox: 0.3016  mixup_unsup_d3.loss_iou: 0.3796  mixup_unsup_d4.loss_cls: 0.1419  mixup_unsup_d4.loss_bbox: 0.2728  mixup_unsup_d4.loss_iou: 0.3854  mosaic_unsup_loss_cls: 0.0068  mosaic_unsup_loss_bbox: 1.6977  mosaic_unsup_loss_iou: 2.5011  mosaic_unsup_d0.loss_cls: 0.0138  mosaic_unsup_d0.loss_bbox: 1.6906  mosaic_unsup_d0.loss_iou: 2.4926  mosaic_unsup_d1.loss_cls: 0.0081  mosaic_unsup_d1.loss_bbox: 1.6726  mosaic_unsup_d1.loss_iou: 2.4951  mosaic_unsup_d2.loss_cls: 0.0078  mosaic_unsup_d2.loss_bbox: 1.6991  mosaic_unsup_d2.loss_iou: 2.5153  mosaic_unsup_d3.loss_cls: 0.0081  mosaic_unsup_d3.loss_bbox: 1.6792  mosaic_unsup_d3.loss_iou: 2.5079  mosaic_unsup_d4.loss_cls: 0.0069  mosaic_unsup_d4.loss_bbox: 1.7016  mosaic_unsup_d4.loss_iou: 2.4939
2025/06/23 22:33:39 - mmengine - INFO - Iter(train) [  1750/240000]  base_lr: 3.4993e-05 lr: 3.4993e-06  eta: 2 days, 7:09:59  time: 0.8055  data_time: 0.0242  memory: 9885  grad_norm: 1254.0396  loss: 54.9750  sup_loss_cls: 0.5481  sup_loss_bbox: 0.7315  sup_loss_iou: 1.3700  sup_d0.loss_cls: 0.5243  sup_d0.loss_bbox: 0.6330  sup_d0.loss_iou: 1.3105  sup_d1.loss_cls: 0.5513  sup_d1.loss_bbox: 0.6501  sup_d1.loss_iou: 1.2541  sup_d2.loss_cls: 0.5725  sup_d2.loss_bbox: 0.6723  sup_d2.loss_iou: 1.3300  sup_d3.loss_cls: 0.5552  sup_d3.loss_bbox: 0.6653  sup_d3.loss_iou: 1.3711  sup_d4.loss_cls: 0.5515  sup_d4.loss_bbox: 0.6708  sup_d4.loss_iou: 1.4026  mixup_unsup_loss_cls: 0.2154  mixup_unsup_loss_bbox: 0.4904  mixup_unsup_loss_iou: 0.6931  mixup_unsup_d0.loss_cls: 0.2193  mixup_unsup_d0.loss_bbox: 0.4960  mixup_unsup_d0.loss_iou: 0.6992  mixup_unsup_d1.loss_cls: 0.2149  mixup_unsup_d1.loss_bbox: 0.5047  mixup_unsup_d1.loss_iou: 0.7058  mixup_unsup_d2.loss_cls: 0.2113  mixup_unsup_d2.loss_bbox: 0.4946  mixup_unsup_d2.loss_iou: 0.6997  mixup_unsup_d3.loss_cls: 0.2231  mixup_unsup_d3.loss_bbox: 0.4989  mixup_unsup_d3.loss_iou: 0.7067  mixup_unsup_d4.loss_cls: 0.2121  mixup_unsup_d4.loss_bbox: 0.5009  mixup_unsup_d4.loss_iou: 0.7061  mosaic_unsup_loss_cls: 0.0066  mosaic_unsup_loss_bbox: 2.3466  mosaic_unsup_loss_iou: 2.8336  mosaic_unsup_d0.loss_cls: 0.0127  mosaic_unsup_d0.loss_bbox: 2.3519  mosaic_unsup_d0.loss_iou: 2.8310  mosaic_unsup_d1.loss_cls: 0.0079  mosaic_unsup_d1.loss_bbox: 2.3457  mosaic_unsup_d1.loss_iou: 2.8335  mosaic_unsup_d2.loss_cls: 0.0072  mosaic_unsup_d2.loss_bbox: 2.3439  mosaic_unsup_d2.loss_iou: 2.8525  mosaic_unsup_d3.loss_cls: 0.0074  mosaic_unsup_d3.loss_bbox: 2.3329  mosaic_unsup_d3.loss_iou: 2.8298  mosaic_unsup_d4.loss_cls: 0.0069  mosaic_unsup_d4.loss_bbox: 2.3514  mosaic_unsup_d4.loss_iou: 2.8170
2025/06/23 22:34:19 - mmengine - INFO - Iter(train) [  1800/240000]  base_lr: 3.5994e-05 lr: 3.5994e-06  eta: 2 days, 7:04:20  time: 0.7887  data_time: 0.0246  memory: 9886  grad_norm: 1773.9977  loss: 41.0908  sup_loss_cls: 0.5824  sup_loss_bbox: 0.7687  sup_loss_iou: 1.3269  sup_d0.loss_cls: 0.5975  sup_d0.loss_bbox: 0.6657  sup_d0.loss_iou: 1.1644  sup_d1.loss_cls: 0.5936  sup_d1.loss_bbox: 0.6926  sup_d1.loss_iou: 1.2059  sup_d2.loss_cls: 0.5890  sup_d2.loss_bbox: 0.6802  sup_d2.loss_iou: 1.1544  sup_d3.loss_cls: 0.5997  sup_d3.loss_bbox: 0.6758  sup_d3.loss_iou: 1.1683  sup_d4.loss_cls: 0.5990  sup_d4.loss_bbox: 0.7038  sup_d4.loss_iou: 1.2438  mixup_unsup_loss_cls: 0.0744  mixup_unsup_loss_bbox: 0.2389  mixup_unsup_loss_iou: 0.2892  mixup_unsup_d0.loss_cls: 0.0546  mixup_unsup_d0.loss_bbox: 0.2354  mixup_unsup_d0.loss_iou: 0.3040  mixup_unsup_d1.loss_cls: 0.0521  mixup_unsup_d1.loss_bbox: 0.2283  mixup_unsup_d1.loss_iou: 0.2959  mixup_unsup_d2.loss_cls: 0.0620  mixup_unsup_d2.loss_bbox: 0.2273  mixup_unsup_d2.loss_iou: 0.2913  mixup_unsup_d3.loss_cls: 0.0654  mixup_unsup_d3.loss_bbox: 0.2294  mixup_unsup_d3.loss_iou: 0.2921  mixup_unsup_d4.loss_cls: 0.0581  mixup_unsup_d4.loss_bbox: 0.2276  mixup_unsup_d4.loss_iou: 0.2881  mosaic_unsup_loss_cls: 0.0794  mosaic_unsup_loss_bbox: 1.5384  mosaic_unsup_loss_iou: 2.1444  mosaic_unsup_d0.loss_cls: 0.0928  mosaic_unsup_d0.loss_bbox: 1.5474  mosaic_unsup_d0.loss_iou: 2.1093  mosaic_unsup_d1.loss_cls: 0.0660  mosaic_unsup_d1.loss_bbox: 1.5443  mosaic_unsup_d1.loss_iou: 2.1333  mosaic_unsup_d2.loss_cls: 0.0634  mosaic_unsup_d2.loss_bbox: 1.5477  mosaic_unsup_d2.loss_iou: 2.1398  mosaic_unsup_d3.loss_cls: 0.0677  mosaic_unsup_d3.loss_bbox: 1.5562  mosaic_unsup_d3.loss_iou: 2.1460  mosaic_unsup_d4.loss_cls: 0.0762  mosaic_unsup_d4.loss_bbox: 1.5661  mosaic_unsup_d4.loss_iou: 2.1467
2025/06/23 22:34:59 - mmengine - INFO - Iter(train) [  1850/240000]  base_lr: 3.6994e-05 lr: 3.6994e-06  eta: 2 days, 7:00:23  time: 0.8020  data_time: 0.0249  memory: 9886  grad_norm: 2206.9696  loss: 50.2469  sup_loss_cls: 0.5780  sup_loss_bbox: 0.7775  sup_loss_iou: 1.4511  sup_d0.loss_cls: 0.5513  sup_d0.loss_bbox: 0.7391  sup_d0.loss_iou: 1.3364  sup_d1.loss_cls: 0.6201  sup_d1.loss_bbox: 0.6954  sup_d1.loss_iou: 1.3187  sup_d2.loss_cls: 0.6039  sup_d2.loss_bbox: 0.7071  sup_d2.loss_iou: 1.2666  sup_d3.loss_cls: 0.5977  sup_d3.loss_bbox: 0.7855  sup_d3.loss_iou: 1.3461  sup_d4.loss_cls: 0.6082  sup_d4.loss_bbox: 0.7424  sup_d4.loss_iou: 1.3986  mixup_unsup_loss_cls: 0.0371  mixup_unsup_loss_bbox: 0.4347  mixup_unsup_loss_iou: 0.4847  mixup_unsup_d0.loss_cls: 0.0483  mixup_unsup_d0.loss_bbox: 0.4098  mixup_unsup_d0.loss_iou: 0.4743  mixup_unsup_d1.loss_cls: 0.0370  mixup_unsup_d1.loss_bbox: 0.4100  mixup_unsup_d1.loss_iou: 0.4747  mixup_unsup_d2.loss_cls: 0.0318  mixup_unsup_d2.loss_bbox: 0.4194  mixup_unsup_d2.loss_iou: 0.4761  mixup_unsup_d3.loss_cls: 0.0333  mixup_unsup_d3.loss_bbox: 0.4259  mixup_unsup_d3.loss_iou: 0.4784  mixup_unsup_d4.loss_cls: 0.0340  mixup_unsup_d4.loss_bbox: 0.4262  mixup_unsup_d4.loss_iou: 0.4825  mosaic_unsup_loss_cls: 0.1010  mosaic_unsup_loss_bbox: 1.9764  mosaic_unsup_loss_iou: 2.6436  mosaic_unsup_d0.loss_cls: 0.1352  mosaic_unsup_d0.loss_bbox: 2.0031  mosaic_unsup_d0.loss_iou: 2.6582  mosaic_unsup_d1.loss_cls: 0.1181  mosaic_unsup_d1.loss_bbox: 2.0080  mosaic_unsup_d1.loss_iou: 2.6440  mosaic_unsup_d2.loss_cls: 0.1156  mosaic_unsup_d2.loss_bbox: 1.9927  mosaic_unsup_d2.loss_iou: 2.6480  mosaic_unsup_d3.loss_cls: 0.1097  mosaic_unsup_d3.loss_bbox: 1.9926  mosaic_unsup_d3.loss_iou: 2.6359  mosaic_unsup_d4.loss_cls: 0.0947  mosaic_unsup_d4.loss_bbox: 1.9947  mosaic_unsup_d4.loss_iou: 2.6337
2025/06/23 22:35:38 - mmengine - INFO - Iter(train) [  1900/240000]  base_lr: 3.7994e-05 lr: 3.7994e-06  eta: 2 days, 6:53:57  time: 0.7765  data_time: 0.0247  memory: 9702  grad_norm: 1288.7225  loss: 42.0977  sup_loss_cls: 0.5545  sup_loss_bbox: 0.6639  sup_loss_iou: 1.0906  sup_d0.loss_cls: 0.5221  sup_d0.loss_bbox: 0.7018  sup_d0.loss_iou: 1.2639  sup_d1.loss_cls: 0.5566  sup_d1.loss_bbox: 0.7091  sup_d1.loss_iou: 1.2687  sup_d2.loss_cls: 0.5539  sup_d2.loss_bbox: 0.6343  sup_d2.loss_iou: 1.1338  sup_d3.loss_cls: 0.5574  sup_d3.loss_bbox: 0.6637  sup_d3.loss_iou: 1.0971  sup_d4.loss_cls: 0.5827  sup_d4.loss_bbox: 0.6659  sup_d4.loss_iou: 1.0595  mixup_unsup_loss_cls: 0.0524  mixup_unsup_loss_bbox: 0.4085  mixup_unsup_loss_iou: 0.4596  mixup_unsup_d0.loss_cls: 0.0600  mixup_unsup_d0.loss_bbox: 0.3717  mixup_unsup_d0.loss_iou: 0.4473  mixup_unsup_d1.loss_cls: 0.0502  mixup_unsup_d1.loss_bbox: 0.4097  mixup_unsup_d1.loss_iou: 0.4590  mixup_unsup_d2.loss_cls: 0.0513  mixup_unsup_d2.loss_bbox: 0.4012  mixup_unsup_d2.loss_iou: 0.4556  mixup_unsup_d3.loss_cls: 0.0450  mixup_unsup_d3.loss_bbox: 0.4030  mixup_unsup_d3.loss_iou: 0.4601  mixup_unsup_d4.loss_cls: 0.0485  mixup_unsup_d4.loss_bbox: 0.4073  mixup_unsup_d4.loss_iou: 0.4630  mosaic_unsup_loss_cls: 0.0616  mosaic_unsup_loss_bbox: 1.5734  mosaic_unsup_loss_iou: 2.0800  mosaic_unsup_d0.loss_cls: 0.0807  mosaic_unsup_d0.loss_bbox: 1.5895  mosaic_unsup_d0.loss_iou: 2.0813  mosaic_unsup_d1.loss_cls: 0.0706  mosaic_unsup_d1.loss_bbox: 1.5992  mosaic_unsup_d1.loss_iou: 2.0836  mosaic_unsup_d2.loss_cls: 0.0707  mosaic_unsup_d2.loss_bbox: 1.5804  mosaic_unsup_d2.loss_iou: 2.0827  mosaic_unsup_d3.loss_cls: 0.0649  mosaic_unsup_d3.loss_bbox: 1.5768  mosaic_unsup_d3.loss_iou: 2.0790  mosaic_unsup_d4.loss_cls: 0.0568  mosaic_unsup_d4.loss_bbox: 1.5628  mosaic_unsup_d4.loss_iou: 2.0709
2025/06/23 22:36:17 - mmengine - INFO - Iter(train) [  1950/240000]  base_lr: 3.8994e-05 lr: 3.8994e-06  eta: 2 days, 6:48:02  time: 0.7787  data_time: 0.0247  memory: 9618  grad_norm: 1656.9955  loss: 47.2881  sup_loss_cls: 0.6333  sup_loss_bbox: 0.7955  sup_loss_iou: 1.4079  sup_d0.loss_cls: 0.6188  sup_d0.loss_bbox: 0.6992  sup_d0.loss_iou: 1.2319  sup_d1.loss_cls: 0.6594  sup_d1.loss_bbox: 0.6872  sup_d1.loss_iou: 1.2875  sup_d2.loss_cls: 0.6389  sup_d2.loss_bbox: 0.6997  sup_d2.loss_iou: 1.2579  sup_d3.loss_cls: 0.6222  sup_d3.loss_bbox: 0.7758  sup_d3.loss_iou: 1.3931  sup_d4.loss_cls: 0.6218  sup_d4.loss_bbox: 0.6598  sup_d4.loss_iou: 1.2405  mixup_unsup_loss_cls: 0.1324  mixup_unsup_loss_bbox: 0.4956  mixup_unsup_loss_iou: 0.7223  mixup_unsup_d0.loss_cls: 0.1285  mixup_unsup_d0.loss_bbox: 0.4789  mixup_unsup_d0.loss_iou: 0.6875  mixup_unsup_d1.loss_cls: 0.1072  mixup_unsup_d1.loss_bbox: 0.4882  mixup_unsup_d1.loss_iou: 0.6972  mixup_unsup_d2.loss_cls: 0.1265  mixup_unsup_d2.loss_bbox: 0.4997  mixup_unsup_d2.loss_iou: 0.7065  mixup_unsup_d3.loss_cls: 0.1467  mixup_unsup_d3.loss_bbox: 0.4877  mixup_unsup_d3.loss_iou: 0.6922  mixup_unsup_d4.loss_cls: 0.1363  mixup_unsup_d4.loss_bbox: 0.4806  mixup_unsup_d4.loss_iou: 0.7074  mosaic_unsup_loss_cls: 0.0871  mosaic_unsup_loss_bbox: 1.6285  mosaic_unsup_loss_iou: 2.1972  mosaic_unsup_d0.loss_cls: 0.0990  mosaic_unsup_d0.loss_bbox: 1.6417  mosaic_unsup_d0.loss_iou: 2.1831  mosaic_unsup_d1.loss_cls: 0.0665  mosaic_unsup_d1.loss_bbox: 1.6384  mosaic_unsup_d1.loss_iou: 2.1871  mosaic_unsup_d2.loss_cls: 0.0851  mosaic_unsup_d2.loss_bbox: 1.6265  mosaic_unsup_d2.loss_iou: 2.1885  mosaic_unsup_d3.loss_cls: 0.0970  mosaic_unsup_d3.loss_bbox: 1.6234  mosaic_unsup_d3.loss_iou: 2.1822  mosaic_unsup_d4.loss_cls: 0.0931  mosaic_unsup_d4.loss_bbox: 1.6118  mosaic_unsup_d4.loss_iou: 2.2004
2025/06/23 22:36:56 - mmengine - INFO - Exp name: Newdatamixpl05_detr_r50_100_sonar-s1-p10_20250623_220902
2025/06/23 22:36:56 - mmengine - INFO - Iter(train) [  2000/240000]  base_lr: 3.9994e-05 lr: 3.9994e-06  eta: 2 days, 6:43:04  time: 0.7856  data_time: 0.0254  memory: 9886  grad_norm: 2172.1579  loss: 47.2699  sup_loss_cls: 0.8515  sup_loss_bbox: 0.6550  sup_loss_iou: 1.2317  sup_d0.loss_cls: 0.8103  sup_d0.loss_bbox: 0.6097  sup_d0.loss_iou: 1.1372  sup_d1.loss_cls: 0.9201  sup_d1.loss_bbox: 0.6260  sup_d1.loss_iou: 1.1837  sup_d2.loss_cls: 0.8656  sup_d2.loss_bbox: 0.6321  sup_d2.loss_iou: 1.1463  sup_d3.loss_cls: 0.8303  sup_d3.loss_bbox: 0.6960  sup_d3.loss_iou: 1.2728  sup_d4.loss_cls: 0.8452  sup_d4.loss_bbox: 0.6890  sup_d4.loss_iou: 1.2610  mixup_unsup_loss_cls: 0.1308  mixup_unsup_loss_bbox: 0.3704  mixup_unsup_loss_iou: 0.5244  mixup_unsup_d0.loss_cls: 0.1448  mixup_unsup_d0.loss_bbox: 0.3518  mixup_unsup_d0.loss_iou: 0.5174  mixup_unsup_d1.loss_cls: 0.1144  mixup_unsup_d1.loss_bbox: 0.3660  mixup_unsup_d1.loss_iou: 0.5203  mixup_unsup_d2.loss_cls: 0.1194  mixup_unsup_d2.loss_bbox: 0.3687  mixup_unsup_d2.loss_iou: 0.5306  mixup_unsup_d3.loss_cls: 0.1292  mixup_unsup_d3.loss_bbox: 0.3615  mixup_unsup_d3.loss_iou: 0.5149  mixup_unsup_d4.loss_cls: 0.1235  mixup_unsup_d4.loss_bbox: 0.3557  mixup_unsup_d4.loss_iou: 0.5240  mosaic_unsup_loss_cls: 0.1047  mosaic_unsup_loss_bbox: 1.7450  mosaic_unsup_loss_iou: 2.3296  mosaic_unsup_d0.loss_cls: 0.1301  mosaic_unsup_d0.loss_bbox: 1.7201  mosaic_unsup_d0.loss_iou: 2.3203  mosaic_unsup_d1.loss_cls: 0.1052  mosaic_unsup_d1.loss_bbox: 1.7053  mosaic_unsup_d1.loss_iou: 2.3306  mosaic_unsup_d2.loss_cls: 0.1027  mosaic_unsup_d2.loss_bbox: 1.7093  mosaic_unsup_d2.loss_iou: 2.3211  mosaic_unsup_d3.loss_cls: 0.1060  mosaic_unsup_d3.loss_bbox: 1.7334  mosaic_unsup_d3.loss_iou: 2.3198  mosaic_unsup_d4.loss_cls: 0.1127  mosaic_unsup_d4.loss_bbox: 1.7243  mosaic_unsup_d4.loss_iou: 2.3183
2025/06/23 22:37:35 - mmengine - INFO - Iter(train) [  2050/240000]  base_lr: 4.0994e-05 lr: 4.0994e-06  eta: 2 days, 6:37:54  time: 0.7814  data_time: 0.0235  memory: 9886  grad_norm: 1176.6925  loss: 47.4287  sup_loss_cls: 0.5809  sup_loss_bbox: 0.7757  sup_loss_iou: 1.2625  sup_d0.loss_cls: 0.5852  sup_d0.loss_bbox: 0.6423  sup_d0.loss_iou: 1.2091  sup_d1.loss_cls: 0.5611  sup_d1.loss_bbox: 0.6473  sup_d1.loss_iou: 1.2038  sup_d2.loss_cls: 0.5706  sup_d2.loss_bbox: 0.6655  sup_d2.loss_iou: 1.1491  sup_d3.loss_cls: 0.5732  sup_d3.loss_bbox: 0.6600  sup_d3.loss_iou: 1.1837  sup_d4.loss_cls: 0.5761  sup_d4.loss_bbox: 0.6905  sup_d4.loss_iou: 1.2077  mixup_unsup_loss_cls: 0.0080  mixup_unsup_loss_bbox: 0.3048  mixup_unsup_loss_iou: 0.4229  mixup_unsup_d0.loss_cls: 0.0115  mixup_unsup_d0.loss_bbox: 0.2994  mixup_unsup_d0.loss_iou: 0.4216  mixup_unsup_d1.loss_cls: 0.0065  mixup_unsup_d1.loss_bbox: 0.2997  mixup_unsup_d1.loss_iou: 0.4129  mixup_unsup_d2.loss_cls: 0.0064  mixup_unsup_d2.loss_bbox: 0.3007  mixup_unsup_d2.loss_iou: 0.4164  mixup_unsup_d3.loss_cls: 0.0101  mixup_unsup_d3.loss_bbox: 0.2997  mixup_unsup_d3.loss_iou: 0.4144  mixup_unsup_d4.loss_cls: 0.0076  mixup_unsup_d4.loss_bbox: 0.2989  mixup_unsup_d4.loss_iou: 0.4179  mosaic_unsup_loss_cls: 0.1053  mosaic_unsup_loss_bbox: 1.9433  mosaic_unsup_loss_iou: 2.6577  mosaic_unsup_d0.loss_cls: 0.1138  mosaic_unsup_d0.loss_bbox: 1.9262  mosaic_unsup_d0.loss_iou: 2.6650  mosaic_unsup_d1.loss_cls: 0.1064  mosaic_unsup_d1.loss_bbox: 1.9623  mosaic_unsup_d1.loss_iou: 2.6679  mosaic_unsup_d2.loss_cls: 0.1067  mosaic_unsup_d2.loss_bbox: 1.9649  mosaic_unsup_d2.loss_iou: 2.6559  mosaic_unsup_d3.loss_cls: 0.1091  mosaic_unsup_d3.loss_bbox: 1.9546  mosaic_unsup_d3.loss_iou: 2.6596  mosaic_unsup_d4.loss_cls: 0.1052  mosaic_unsup_d4.loss_bbox: 1.9629  mosaic_unsup_d4.loss_iou: 2.6581
2025/06/23 22:38:13 - mmengine - INFO - Iter(train) [  2100/240000]  base_lr: 4.1994e-05 lr: 4.1994e-06  eta: 2 days, 6:31:37  time: 0.7673  data_time: 0.0242  memory: 9704  grad_norm: 894.7485  loss: 44.6753  sup_loss_cls: 0.6088  sup_loss_bbox: 0.7810  sup_loss_iou: 1.3154  sup_d0.loss_cls: 0.5871  sup_d0.loss_bbox: 0.7222  sup_d0.loss_iou: 1.3310  sup_d1.loss_cls: 0.6072  sup_d1.loss_bbox: 0.7240  sup_d1.loss_iou: 1.3013  sup_d2.loss_cls: 0.6179  sup_d2.loss_bbox: 0.7593  sup_d2.loss_iou: 1.2569  sup_d3.loss_cls: 0.6075  sup_d3.loss_bbox: 0.8442  sup_d3.loss_iou: 1.3567  sup_d4.loss_cls: 0.6075  sup_d4.loss_bbox: 0.8639  sup_d4.loss_iou: 1.4327  mixup_unsup_loss_cls: 0.0975  mixup_unsup_loss_bbox: 0.3667  mixup_unsup_loss_iou: 0.5447  mixup_unsup_d0.loss_cls: 0.0865  mixup_unsup_d0.loss_bbox: 0.4179  mixup_unsup_d0.loss_iou: 0.5740  mixup_unsup_d1.loss_cls: 0.0930  mixup_unsup_d1.loss_bbox: 0.4094  mixup_unsup_d1.loss_iou: 0.5747  mixup_unsup_d2.loss_cls: 0.0998  mixup_unsup_d2.loss_bbox: 0.4187  mixup_unsup_d2.loss_iou: 0.5823  mixup_unsup_d3.loss_cls: 0.1045  mixup_unsup_d3.loss_bbox: 0.4290  mixup_unsup_d3.loss_iou: 0.5860  mixup_unsup_d4.loss_cls: 0.0898  mixup_unsup_d4.loss_bbox: 0.4298  mixup_unsup_d4.loss_iou: 0.5875  mosaic_unsup_loss_cls: 0.0776  mosaic_unsup_loss_bbox: 1.5144  mosaic_unsup_loss_iou: 2.0408  mosaic_unsup_d0.loss_cls: 0.0910  mosaic_unsup_d0.loss_bbox: 1.5275  mosaic_unsup_d0.loss_iou: 2.0298  mosaic_unsup_d1.loss_cls: 0.0872  mosaic_unsup_d1.loss_bbox: 1.5278  mosaic_unsup_d1.loss_iou: 2.0406  mosaic_unsup_d2.loss_cls: 0.0900  mosaic_unsup_d2.loss_bbox: 1.5228  mosaic_unsup_d2.loss_iou: 2.0353  mosaic_unsup_d3.loss_cls: 0.0880  mosaic_unsup_d3.loss_bbox: 1.5150  mosaic_unsup_d3.loss_iou: 2.0321  mosaic_unsup_d4.loss_cls: 0.0781  mosaic_unsup_d4.loss_bbox: 1.5313  mosaic_unsup_d4.loss_iou: 2.0297
2025/06/23 22:38:54 - mmengine - INFO - Iter(train) [  2150/240000]  base_lr: 4.2994e-05 lr: 4.2994e-06  eta: 2 days, 6:29:01  time: 0.8045  data_time: 0.0268  memory: 9885  grad_norm: 1753.3564  loss: 43.3440  sup_loss_cls: 0.5764  sup_loss_bbox: 0.6530  sup_loss_iou: 1.2507  sup_d0.loss_cls: 0.5893  sup_d0.loss_bbox: 0.5174  sup_d0.loss_iou: 1.0981  sup_d1.loss_cls: 0.6027  sup_d1.loss_bbox: 0.5786  sup_d1.loss_iou: 1.1500  sup_d2.loss_cls: 0.5905  sup_d2.loss_bbox: 0.5800  sup_d2.loss_iou: 1.1479  sup_d3.loss_cls: 0.5748  sup_d3.loss_bbox: 0.6399  sup_d3.loss_iou: 1.2149  sup_d4.loss_cls: 0.5780  sup_d4.loss_bbox: 0.6272  sup_d4.loss_iou: 1.1785  mixup_unsup_loss_cls: 0.1402  mixup_unsup_loss_bbox: 0.2390  mixup_unsup_loss_iou: 0.3202  mixup_unsup_d0.loss_cls: 0.1110  mixup_unsup_d0.loss_bbox: 0.2134  mixup_unsup_d0.loss_iou: 0.3250  mixup_unsup_d1.loss_cls: 0.1213  mixup_unsup_d1.loss_bbox: 0.2283  mixup_unsup_d1.loss_iou: 0.3234  mixup_unsup_d2.loss_cls: 0.1275  mixup_unsup_d2.loss_bbox: 0.2243  mixup_unsup_d2.loss_iou: 0.3160  mixup_unsup_d3.loss_cls: 0.1310  mixup_unsup_d3.loss_bbox: 0.2210  mixup_unsup_d3.loss_iou: 0.3235  mixup_unsup_d4.loss_cls: 0.1243  mixup_unsup_d4.loss_bbox: 0.2171  mixup_unsup_d4.loss_iou: 0.3287  mosaic_unsup_loss_cls: 0.1066  mosaic_unsup_loss_bbox: 1.7873  mosaic_unsup_loss_iou: 2.3688  mosaic_unsup_d0.loss_cls: 0.0642  mosaic_unsup_d0.loss_bbox: 1.7421  mosaic_unsup_d0.loss_iou: 2.3282  mosaic_unsup_d1.loss_cls: 0.0642  mosaic_unsup_d1.loss_bbox: 1.7654  mosaic_unsup_d1.loss_iou: 2.3283  mosaic_unsup_d2.loss_cls: 0.0832  mosaic_unsup_d2.loss_bbox: 1.7774  mosaic_unsup_d2.loss_iou: 2.3502  mosaic_unsup_d3.loss_cls: 0.0877  mosaic_unsup_d3.loss_bbox: 1.7615  mosaic_unsup_d3.loss_iou: 2.3431  mosaic_unsup_d4.loss_cls: 0.0897  mosaic_unsup_d4.loss_bbox: 1.7611  mosaic_unsup_d4.loss_iou: 2.3519
2025/06/23 22:39:32 - mmengine - INFO - Iter(train) [  2200/240000]  base_lr: 4.3994e-05 lr: 4.3994e-06  eta: 2 days, 6:22:39  time: 0.7615  data_time: 0.0232  memory: 9816  grad_norm: 1437.5736  loss: 40.0772  sup_loss_cls: 0.5738  sup_loss_bbox: 0.6539  sup_loss_iou: 1.1388  sup_d0.loss_cls: 0.5570  sup_d0.loss_bbox: 0.5818  sup_d0.loss_iou: 1.1317  sup_d1.loss_cls: 0.5978  sup_d1.loss_bbox: 0.5809  sup_d1.loss_iou: 1.0660  sup_d2.loss_cls: 0.5916  sup_d2.loss_bbox: 0.5935  sup_d2.loss_iou: 1.1179  sup_d3.loss_cls: 0.5814  sup_d3.loss_bbox: 0.6065  sup_d3.loss_iou: 1.1053  sup_d4.loss_cls: 0.5974  sup_d4.loss_bbox: 0.6506  sup_d4.loss_iou: 1.1212  mixup_unsup_loss_cls: 0.0563  mixup_unsup_loss_bbox: 0.3180  mixup_unsup_loss_iou: 0.4084  mixup_unsup_d0.loss_cls: 0.0461  mixup_unsup_d0.loss_bbox: 0.3291  mixup_unsup_d0.loss_iou: 0.4323  mixup_unsup_d1.loss_cls: 0.0449  mixup_unsup_d1.loss_bbox: 0.3172  mixup_unsup_d1.loss_iou: 0.4144  mixup_unsup_d2.loss_cls: 0.0523  mixup_unsup_d2.loss_bbox: 0.3176  mixup_unsup_d2.loss_iou: 0.4192  mixup_unsup_d3.loss_cls: 0.0611  mixup_unsup_d3.loss_bbox: 0.3159  mixup_unsup_d3.loss_iou: 0.4092  mixup_unsup_d4.loss_cls: 0.0578  mixup_unsup_d4.loss_bbox: 0.3253  mixup_unsup_d4.loss_iou: 0.4250  mosaic_unsup_loss_cls: 0.2322  mosaic_unsup_loss_bbox: 1.4134  mosaic_unsup_loss_iou: 2.0473  mosaic_unsup_d0.loss_cls: 0.1826  mosaic_unsup_d0.loss_bbox: 1.2681  mosaic_unsup_d0.loss_iou: 2.0708  mosaic_unsup_d1.loss_cls: 0.1503  mosaic_unsup_d1.loss_bbox: 1.3191  mosaic_unsup_d1.loss_iou: 2.0587  mosaic_unsup_d2.loss_cls: 0.1926  mosaic_unsup_d2.loss_bbox: 1.2514  mosaic_unsup_d2.loss_iou: 2.0543  mosaic_unsup_d3.loss_cls: 0.2126  mosaic_unsup_d3.loss_bbox: 1.3491  mosaic_unsup_d3.loss_iou: 2.0529  mosaic_unsup_d4.loss_cls: 0.2331  mosaic_unsup_d4.loss_bbox: 1.3525  mosaic_unsup_d4.loss_iou: 2.0392
2025/06/23 22:40:09 - mmengine - INFO - Iter(train) [  2250/240000]  base_lr: 4.4994e-05 lr: 4.4994e-06  eta: 2 days, 6:15:33  time: 0.7504  data_time: 0.0236  memory: 9702  grad_norm: 1489.5747  loss: 41.6192  sup_loss_cls: 0.5830  sup_loss_bbox: 0.6293  sup_loss_iou: 1.2059  sup_d0.loss_cls: 0.5751  sup_d0.loss_bbox: 0.6835  sup_d0.loss_iou: 1.1794  sup_d1.loss_cls: 0.6069  sup_d1.loss_bbox: 0.6929  sup_d1.loss_iou: 1.2606  sup_d2.loss_cls: 0.6123  sup_d2.loss_bbox: 0.6934  sup_d2.loss_iou: 1.2317  sup_d3.loss_cls: 0.6124  sup_d3.loss_bbox: 0.6986  sup_d3.loss_iou: 1.2166  sup_d4.loss_cls: 0.6173  sup_d4.loss_bbox: 0.7298  sup_d4.loss_iou: 1.1999  mixup_unsup_loss_cls: 0.0129  mixup_unsup_loss_bbox: 0.1825  mixup_unsup_loss_iou: 0.2270  mixup_unsup_d0.loss_cls: 0.0162  mixup_unsup_d0.loss_bbox: 0.1852  mixup_unsup_d0.loss_iou: 0.2305  mixup_unsup_d1.loss_cls: 0.0155  mixup_unsup_d1.loss_bbox: 0.1832  mixup_unsup_d1.loss_iou: 0.2284  mixup_unsup_d2.loss_cls: 0.0164  mixup_unsup_d2.loss_bbox: 0.1907  mixup_unsup_d2.loss_iou: 0.2338  mixup_unsup_d3.loss_cls: 0.0144  mixup_unsup_d3.loss_bbox: 0.1915  mixup_unsup_d3.loss_iou: 0.2334  mixup_unsup_d4.loss_cls: 0.0122  mixup_unsup_d4.loss_bbox: 0.1849  mixup_unsup_d4.loss_iou: 0.2305  mosaic_unsup_loss_cls: 0.0820  mosaic_unsup_loss_bbox: 1.5819  mosaic_unsup_loss_iou: 2.3357  mosaic_unsup_d0.loss_cls: 0.0993  mosaic_unsup_d0.loss_bbox: 1.5902  mosaic_unsup_d0.loss_iou: 2.3108  mosaic_unsup_d1.loss_cls: 0.0962  mosaic_unsup_d1.loss_bbox: 1.5847  mosaic_unsup_d1.loss_iou: 2.3247  mosaic_unsup_d2.loss_cls: 0.0910  mosaic_unsup_d2.loss_bbox: 1.5866  mosaic_unsup_d2.loss_iou: 2.3116  mosaic_unsup_d3.loss_cls: 0.0882  mosaic_unsup_d3.loss_bbox: 1.5811  mosaic_unsup_d3.loss_iou: 2.3203  mosaic_unsup_d4.loss_cls: 0.0828  mosaic_unsup_d4.loss_bbox: 1.6059  mosaic_unsup_d4.loss_iou: 2.3286
2025/06/23 22:40:48 - mmengine - INFO - Iter(train) [  2300/240000]  base_lr: 4.5995e-05 lr: 4.5995e-06  eta: 2 days, 6:10:29  time: 0.7707  data_time: 0.0252  memory: 9878  grad_norm: 1413.3378  loss: 43.8363  sup_loss_cls: 0.7319  sup_loss_bbox: 0.8356  sup_loss_iou: 1.2201  sup_d0.loss_cls: 0.6898  sup_d0.loss_bbox: 0.8255  sup_d0.loss_iou: 1.2792  sup_d1.loss_cls: 0.7023  sup_d1.loss_bbox: 0.7746  sup_d1.loss_iou: 1.2438  sup_d2.loss_cls: 0.7203  sup_d2.loss_bbox: 0.8033  sup_d2.loss_iou: 1.2177  sup_d3.loss_cls: 0.7208  sup_d3.loss_bbox: 0.8632  sup_d3.loss_iou: 1.2714  sup_d4.loss_cls: 0.7169  sup_d4.loss_bbox: 0.8958  sup_d4.loss_iou: 1.3174  mixup_unsup_loss_cls: 0.1058  mixup_unsup_loss_bbox: 0.1773  mixup_unsup_loss_iou: 0.3100  mixup_unsup_d0.loss_cls: 0.1126  mixup_unsup_d0.loss_bbox: 0.1658  mixup_unsup_d0.loss_iou: 0.3085  mixup_unsup_d1.loss_cls: 0.1274  mixup_unsup_d1.loss_bbox: 0.1660  mixup_unsup_d1.loss_iou: 0.3113  mixup_unsup_d2.loss_cls: 0.1322  mixup_unsup_d2.loss_bbox: 0.1778  mixup_unsup_d2.loss_iou: 0.3256  mixup_unsup_d3.loss_cls: 0.1300  mixup_unsup_d3.loss_bbox: 0.1905  mixup_unsup_d3.loss_iou: 0.3234  mixup_unsup_d4.loss_cls: 0.1159  mixup_unsup_d4.loss_bbox: 0.1920  mixup_unsup_d4.loss_iou: 0.3245  mosaic_unsup_loss_cls: 0.1399  mosaic_unsup_loss_bbox: 1.5696  mosaic_unsup_loss_iou: 2.1835  mosaic_unsup_d0.loss_cls: 0.1661  mosaic_unsup_d0.loss_bbox: 1.5652  mosaic_unsup_d0.loss_iou: 2.1781  mosaic_unsup_d1.loss_cls: 0.1432  mosaic_unsup_d1.loss_bbox: 1.5653  mosaic_unsup_d1.loss_iou: 2.1767  mosaic_unsup_d2.loss_cls: 0.1433  mosaic_unsup_d2.loss_bbox: 1.5608  mosaic_unsup_d2.loss_iou: 2.1629  mosaic_unsup_d3.loss_cls: 0.1324  mosaic_unsup_d3.loss_bbox: 1.5694  mosaic_unsup_d3.loss_iou: 2.1645  mosaic_unsup_d4.loss_cls: 0.1461  mosaic_unsup_d4.loss_bbox: 1.5669  mosaic_unsup_d4.loss_iou: 2.1762
2025/06/23 22:41:26 - mmengine - INFO - Iter(train) [  2350/240000]  base_lr: 4.6995e-05 lr: 4.6995e-06  eta: 2 days, 6:05:33  time: 0.7701  data_time: 0.0248  memory: 9700  grad_norm: 1813.5363  loss: 45.2267  sup_loss_cls: 0.5960  sup_loss_bbox: 0.6821  sup_loss_iou: 1.2032  sup_d0.loss_cls: 0.5667  sup_d0.loss_bbox: 0.6158  sup_d0.loss_iou: 1.2008  sup_d1.loss_cls: 0.6172  sup_d1.loss_bbox: 0.6304  sup_d1.loss_iou: 1.2697  sup_d2.loss_cls: 0.6257  sup_d2.loss_bbox: 0.6611  sup_d2.loss_iou: 1.1749  sup_d3.loss_cls: 0.6332  sup_d3.loss_bbox: 0.6712  sup_d3.loss_iou: 1.1837  sup_d4.loss_cls: 0.6021  sup_d4.loss_bbox: 0.7548  sup_d4.loss_iou: 1.2682  mixup_unsup_loss_cls: 0.0417  mixup_unsup_loss_bbox: 0.4476  mixup_unsup_loss_iou: 0.6486  mixup_unsup_d0.loss_cls: 0.0341  mixup_unsup_d0.loss_bbox: 0.4104  mixup_unsup_d0.loss_iou: 0.6189  mixup_unsup_d1.loss_cls: 0.0271  mixup_unsup_d1.loss_bbox: 0.4533  mixup_unsup_d1.loss_iou: 0.6311  mixup_unsup_d2.loss_cls: 0.0362  mixup_unsup_d2.loss_bbox: 0.4601  mixup_unsup_d2.loss_iou: 0.6282  mixup_unsup_d3.loss_cls: 0.0510  mixup_unsup_d3.loss_bbox: 0.4642  mixup_unsup_d3.loss_iou: 0.6501  mixup_unsup_d4.loss_cls: 0.0447  mixup_unsup_d4.loss_bbox: 0.4222  mixup_unsup_d4.loss_iou: 0.6231  mosaic_unsup_loss_cls: 0.0773  mosaic_unsup_loss_bbox: 1.5602  mosaic_unsup_loss_iou: 2.2901  mosaic_unsup_d0.loss_cls: 0.1007  mosaic_unsup_d0.loss_bbox: 1.5753  mosaic_unsup_d0.loss_iou: 2.3239  mosaic_unsup_d1.loss_cls: 0.0850  mosaic_unsup_d1.loss_bbox: 1.5490  mosaic_unsup_d1.loss_iou: 2.2679  mosaic_unsup_d2.loss_cls: 0.0818  mosaic_unsup_d2.loss_bbox: 1.5734  mosaic_unsup_d2.loss_iou: 2.2850  mosaic_unsup_d3.loss_cls: 0.0693  mosaic_unsup_d3.loss_bbox: 1.5588  mosaic_unsup_d3.loss_iou: 2.2526  mosaic_unsup_d4.loss_cls: 0.0699  mosaic_unsup_d4.loss_bbox: 1.5657  mosaic_unsup_d4.loss_iou: 2.2916
2025/06/23 22:42:06 - mmengine - INFO - Iter(train) [  2400/240000]  base_lr: 4.7995e-05 lr: 4.7995e-06  eta: 2 days, 6:02:44  time: 0.7936  data_time: 0.0248  memory: 9847  grad_norm: 910.9704  loss: 44.9650  sup_loss_cls: 0.5388  sup_loss_bbox: 0.6587  sup_loss_iou: 1.2582  sup_d0.loss_cls: 0.5211  sup_d0.loss_bbox: 0.6305  sup_d0.loss_iou: 1.2207  sup_d1.loss_cls: 0.5379  sup_d1.loss_bbox: 0.6993  sup_d1.loss_iou: 1.2774  sup_d2.loss_cls: 0.5588  sup_d2.loss_bbox: 0.7533  sup_d2.loss_iou: 1.3022  sup_d3.loss_cls: 0.5453  sup_d3.loss_bbox: 0.6320  sup_d3.loss_iou: 1.1403  sup_d4.loss_cls: 0.5417  sup_d4.loss_bbox: 0.6302  sup_d4.loss_iou: 1.1351  mixup_unsup_loss_cls: 0.0816  mixup_unsup_loss_bbox: 0.2737  mixup_unsup_loss_iou: 0.3302  mixup_unsup_d0.loss_cls: 0.0842  mixup_unsup_d0.loss_bbox: 0.2204  mixup_unsup_d0.loss_iou: 0.3283  mixup_unsup_d1.loss_cls: 0.0838  mixup_unsup_d1.loss_bbox: 0.2347  mixup_unsup_d1.loss_iou: 0.3360  mixup_unsup_d2.loss_cls: 0.0802  mixup_unsup_d2.loss_bbox: 0.2283  mixup_unsup_d2.loss_iou: 0.3255  mixup_unsup_d3.loss_cls: 0.0780  mixup_unsup_d3.loss_bbox: 0.2538  mixup_unsup_d3.loss_iou: 0.3377  mixup_unsup_d4.loss_cls: 0.0742  mixup_unsup_d4.loss_bbox: 0.2360  mixup_unsup_d4.loss_iou: 0.3337  mosaic_unsup_loss_cls: 0.1197  mosaic_unsup_loss_bbox: 1.8983  mosaic_unsup_loss_iou: 2.4127  mosaic_unsup_d0.loss_cls: 0.1137  mosaic_unsup_d0.loss_bbox: 1.8753  mosaic_unsup_d0.loss_iou: 2.4280  mosaic_unsup_d1.loss_cls: 0.0979  mosaic_unsup_d1.loss_bbox: 1.8677  mosaic_unsup_d1.loss_iou: 2.4200  mosaic_unsup_d2.loss_cls: 0.1045  mosaic_unsup_d2.loss_bbox: 1.8599  mosaic_unsup_d2.loss_iou: 2.4131  mosaic_unsup_d3.loss_cls: 0.1077  mosaic_unsup_d3.loss_bbox: 1.8940  mosaic_unsup_d3.loss_iou: 2.4273  mosaic_unsup_d4.loss_cls: 0.1023  mosaic_unsup_d4.loss_bbox: 1.8905  mosaic_unsup_d4.loss_iou: 2.4308
2025/06/23 22:42:43 - mmengine - INFO - Iter(train) [  2450/240000]  base_lr: 4.8995e-05 lr: 4.8995e-06  eta: 2 days, 5:56:21  time: 0.7483  data_time: 0.0249  memory: 9702  grad_norm: 901.8280  loss: 36.6156  sup_loss_cls: 0.5896  sup_loss_bbox: 0.6871  sup_loss_iou: 1.2228  sup_d0.loss_cls: 0.5575  sup_d0.loss_bbox: 0.6832  sup_d0.loss_iou: 1.3527  sup_d1.loss_cls: 0.5854  sup_d1.loss_bbox: 0.6301  sup_d1.loss_iou: 1.1519  sup_d2.loss_cls: 0.5896  sup_d2.loss_bbox: 0.6376  sup_d2.loss_iou: 1.1309  sup_d3.loss_cls: 0.6019  sup_d3.loss_bbox: 0.6851  sup_d3.loss_iou: 1.2042  sup_d4.loss_cls: 0.6178  sup_d4.loss_bbox: 0.7010  sup_d4.loss_iou: 1.2209  mixup_unsup_loss_cls: 0.0009  mixup_unsup_loss_bbox: 0.0723  mixup_unsup_loss_iou: 0.1246  mixup_unsup_d0.loss_cls: 0.0010  mixup_unsup_d0.loss_bbox: 0.0705  mixup_unsup_d0.loss_iou: 0.1232  mixup_unsup_d1.loss_cls: 0.0008  mixup_unsup_d1.loss_bbox: 0.0709  mixup_unsup_d1.loss_iou: 0.1241  mixup_unsup_d2.loss_cls: 0.0007  mixup_unsup_d2.loss_bbox: 0.0697  mixup_unsup_d2.loss_iou: 0.1224  mixup_unsup_d3.loss_cls: 0.0007  mixup_unsup_d3.loss_bbox: 0.0690  mixup_unsup_d3.loss_iou: 0.1229  mixup_unsup_d4.loss_cls: 0.0007  mixup_unsup_d4.loss_bbox: 0.0695  mixup_unsup_d4.loss_iou: 0.1231  mosaic_unsup_loss_cls: 0.0578  mosaic_unsup_loss_bbox: 1.3694  mosaic_unsup_loss_iou: 1.9836  mosaic_unsup_d0.loss_cls: 0.0651  mosaic_unsup_d0.loss_bbox: 1.4052  mosaic_unsup_d0.loss_iou: 1.9985  mosaic_unsup_d1.loss_cls: 0.0523  mosaic_unsup_d1.loss_bbox: 1.4123  mosaic_unsup_d1.loss_iou: 1.9896  mosaic_unsup_d2.loss_cls: 0.0552  mosaic_unsup_d2.loss_bbox: 1.3850  mosaic_unsup_d2.loss_iou: 1.9981  mosaic_unsup_d3.loss_cls: 0.0497  mosaic_unsup_d3.loss_bbox: 1.3763  mosaic_unsup_d3.loss_iou: 1.9918  mosaic_unsup_d4.loss_cls: 0.0521  mosaic_unsup_d4.loss_bbox: 1.3652  mosaic_unsup_d4.loss_iou: 1.9921
2025/06/23 22:43:21 - mmengine - INFO - Iter(train) [  2500/240000]  base_lr: 4.9995e-05 lr: 4.9995e-06  eta: 2 days, 5:50:36  time: 0.7533  data_time: 0.0244  memory: 9885  grad_norm: 664.1548  loss: 44.9454  sup_loss_cls: 0.5450  sup_loss_bbox: 0.7024  sup_loss_iou: 1.3124  sup_d0.loss_cls: 0.5100  sup_d0.loss_bbox: 0.5594  sup_d0.loss_iou: 1.2872  sup_d1.loss_cls: 0.5167  sup_d1.loss_bbox: 0.5725  sup_d1.loss_iou: 1.1735  sup_d2.loss_cls: 0.5381  sup_d2.loss_bbox: 0.5430  sup_d2.loss_iou: 1.0657  sup_d3.loss_cls: 0.5331  sup_d3.loss_bbox: 0.5620  sup_d3.loss_iou: 1.0521  sup_d4.loss_cls: 0.5512  sup_d4.loss_bbox: 0.6173  sup_d4.loss_iou: 1.2172  mixup_unsup_loss_cls: 0.0545  mixup_unsup_loss_bbox: 0.5687  mixup_unsup_loss_iou: 0.7812  mixup_unsup_d0.loss_cls: 0.0551  mixup_unsup_d0.loss_bbox: 0.5540  mixup_unsup_d0.loss_iou: 0.7595  mixup_unsup_d1.loss_cls: 0.0556  mixup_unsup_d1.loss_bbox: 0.5594  mixup_unsup_d1.loss_iou: 0.7674  mixup_unsup_d2.loss_cls: 0.0580  mixup_unsup_d2.loss_bbox: 0.5786  mixup_unsup_d2.loss_iou: 0.7736  mixup_unsup_d3.loss_cls: 0.0615  mixup_unsup_d3.loss_bbox: 0.5685  mixup_unsup_d3.loss_iou: 0.7730  mixup_unsup_d4.loss_cls: 0.0550  mixup_unsup_d4.loss_bbox: 0.5736  mixup_unsup_d4.loss_iou: 0.7638  mosaic_unsup_loss_cls: 0.0681  mosaic_unsup_loss_bbox: 1.5799  mosaic_unsup_loss_iou: 2.1334  mosaic_unsup_d0.loss_cls: 0.0838  mosaic_unsup_d0.loss_bbox: 1.5682  mosaic_unsup_d0.loss_iou: 2.1380  mosaic_unsup_d1.loss_cls: 0.0822  mosaic_unsup_d1.loss_bbox: 1.5577  mosaic_unsup_d1.loss_iou: 2.1479  mosaic_unsup_d2.loss_cls: 0.0804  mosaic_unsup_d2.loss_bbox: 1.5915  mosaic_unsup_d2.loss_iou: 2.1329  mosaic_unsup_d3.loss_cls: 0.0736  mosaic_unsup_d3.loss_bbox: 1.5650  mosaic_unsup_d3.loss_iou: 2.1404  mosaic_unsup_d4.loss_cls: 0.0671  mosaic_unsup_d4.loss_bbox: 1.5810  mosaic_unsup_d4.loss_iou: 2.1345
2025/06/23 22:43:59 - mmengine - INFO - Iter(train) [  2550/240000]  base_lr: 5.0995e-05 lr: 5.0995e-06  eta: 2 days, 5:46:24  time: 0.7709  data_time: 0.0240  memory: 9886  grad_norm: 741.4961  loss: 40.0106  sup_loss_cls: 0.5050  sup_loss_bbox: 0.6791  sup_loss_iou: 1.1539  sup_d0.loss_cls: 0.4873  sup_d0.loss_bbox: 0.5681  sup_d0.loss_iou: 1.1577  sup_d1.loss_cls: 0.5298  sup_d1.loss_bbox: 0.6066  sup_d1.loss_iou: 1.0953  sup_d2.loss_cls: 0.5037  sup_d2.loss_bbox: 0.6560  sup_d2.loss_iou: 1.1834  sup_d3.loss_cls: 0.5115  sup_d3.loss_bbox: 0.6456  sup_d3.loss_iou: 1.1368  sup_d4.loss_cls: 0.5199  sup_d4.loss_bbox: 0.7036  sup_d4.loss_iou: 1.1397  mixup_unsup_loss_cls: 0.0013  mixup_unsup_loss_bbox: 0.2605  mixup_unsup_loss_iou: 0.3417  mixup_unsup_d0.loss_cls: 0.0019  mixup_unsup_d0.loss_bbox: 0.2518  mixup_unsup_d0.loss_iou: 0.3410  mixup_unsup_d1.loss_cls: 0.0014  mixup_unsup_d1.loss_bbox: 0.2551  mixup_unsup_d1.loss_iou: 0.3436  mixup_unsup_d2.loss_cls: 0.0012  mixup_unsup_d2.loss_bbox: 0.2573  mixup_unsup_d2.loss_iou: 0.3410  mixup_unsup_d3.loss_cls: 0.0012  mixup_unsup_d3.loss_bbox: 0.2539  mixup_unsup_d3.loss_iou: 0.3400  mixup_unsup_d4.loss_cls: 0.0011  mixup_unsup_d4.loss_bbox: 0.2596  mixup_unsup_d4.loss_iou: 0.3418  mosaic_unsup_loss_cls: 0.0129  mosaic_unsup_loss_bbox: 1.5221  mosaic_unsup_loss_iou: 2.2648  mosaic_unsup_d0.loss_cls: 0.0205  mosaic_unsup_d0.loss_bbox: 1.5384  mosaic_unsup_d0.loss_iou: 2.2565  mosaic_unsup_d1.loss_cls: 0.0118  mosaic_unsup_d1.loss_bbox: 1.5109  mosaic_unsup_d1.loss_iou: 2.2237  mosaic_unsup_d2.loss_cls: 0.0116  mosaic_unsup_d2.loss_bbox: 1.5049  mosaic_unsup_d2.loss_iou: 2.2384  mosaic_unsup_d3.loss_cls: 0.0111  mosaic_unsup_d3.loss_bbox: 1.5111  mosaic_unsup_d3.loss_iou: 2.2295  mosaic_unsup_d4.loss_cls: 0.0120  mosaic_unsup_d4.loss_bbox: 1.5072  mosaic_unsup_d4.loss_iou: 2.2450
2025/06/23 22:44:37 - mmengine - INFO - Iter(train) [  2600/240000]  base_lr: 5.1995e-05 lr: 5.1995e-06  eta: 2 days, 5:41:25  time: 0.7585  data_time: 0.0233  memory: 9886  grad_norm: 1279.4630  loss: 39.4813  sup_loss_cls: 0.5835  sup_loss_bbox: 0.6699  sup_loss_iou: 1.2595  sup_d0.loss_cls: 0.5450  sup_d0.loss_bbox: 0.5156  sup_d0.loss_iou: 1.0569  sup_d1.loss_cls: 0.5761  sup_d1.loss_bbox: 0.5776  sup_d1.loss_iou: 1.1301  sup_d2.loss_cls: 0.5961  sup_d2.loss_bbox: 0.5406  sup_d2.loss_iou: 1.0287  sup_d3.loss_cls: 0.6241  sup_d3.loss_bbox: 0.6566  sup_d3.loss_iou: 1.1489  sup_d4.loss_cls: 0.6245  sup_d4.loss_bbox: 0.6408  sup_d4.loss_iou: 1.1615  mixup_unsup_loss_cls: 0.0151  mixup_unsup_loss_bbox: 0.2044  mixup_unsup_loss_iou: 0.3141  mixup_unsup_d0.loss_cls: 0.0199  mixup_unsup_d0.loss_bbox: 0.2065  mixup_unsup_d0.loss_iou: 0.3137  mixup_unsup_d1.loss_cls: 0.0255  mixup_unsup_d1.loss_bbox: 0.2064  mixup_unsup_d1.loss_iou: 0.3169  mixup_unsup_d2.loss_cls: 0.0280  mixup_unsup_d2.loss_bbox: 0.2003  mixup_unsup_d2.loss_iou: 0.3088  mixup_unsup_d3.loss_cls: 0.0221  mixup_unsup_d3.loss_bbox: 0.1976  mixup_unsup_d3.loss_iou: 0.3068  mixup_unsup_d4.loss_cls: 0.0148  mixup_unsup_d4.loss_bbox: 0.1997  mixup_unsup_d4.loss_iou: 0.3119  mosaic_unsup_loss_cls: 0.0069  mosaic_unsup_loss_bbox: 1.5404  mosaic_unsup_loss_iou: 2.1745  mosaic_unsup_d0.loss_cls: 0.0123  mosaic_unsup_d0.loss_bbox: 1.5405  mosaic_unsup_d0.loss_iou: 2.1739  mosaic_unsup_d1.loss_cls: 0.0081  mosaic_unsup_d1.loss_bbox: 1.5430  mosaic_unsup_d1.loss_iou: 2.1720  mosaic_unsup_d2.loss_cls: 0.0070  mosaic_unsup_d2.loss_bbox: 1.5386  mosaic_unsup_d2.loss_iou: 2.1705  mosaic_unsup_d3.loss_cls: 0.0065  mosaic_unsup_d3.loss_bbox: 1.5465  mosaic_unsup_d3.loss_iou: 2.1689  mosaic_unsup_d4.loss_cls: 0.0060  mosaic_unsup_d4.loss_bbox: 1.5416  mosaic_unsup_d4.loss_iou: 2.1753
2025/06/23 22:45:17 - mmengine - INFO - Iter(train) [  2650/240000]  base_lr: 5.2995e-05 lr: 5.2995e-06  eta: 2 days, 5:38:34  time: 0.7853  data_time: 0.0250  memory: 9887  grad_norm: 970.0784  loss: 53.4763  sup_loss_cls: 0.6232  sup_loss_bbox: 0.6897  sup_loss_iou: 1.2292  sup_d0.loss_cls: 0.6340  sup_d0.loss_bbox: 0.6323  sup_d0.loss_iou: 1.2388  sup_d1.loss_cls: 0.6149  sup_d1.loss_bbox: 0.7116  sup_d1.loss_iou: 1.2620  sup_d2.loss_cls: 0.6316  sup_d2.loss_bbox: 0.5893  sup_d2.loss_iou: 1.0547  sup_d3.loss_cls: 0.6351  sup_d3.loss_bbox: 0.6512  sup_d3.loss_iou: 1.1393  sup_d4.loss_cls: 0.6570  sup_d4.loss_bbox: 0.6927  sup_d4.loss_iou: 1.1800  mixup_unsup_loss_cls: 0.2088  mixup_unsup_loss_bbox: 0.8351  mixup_unsup_loss_iou: 1.0815  mixup_unsup_d0.loss_cls: 0.2383  mixup_unsup_d0.loss_bbox: 0.8424  mixup_unsup_d0.loss_iou: 1.0986  mixup_unsup_d1.loss_cls: 0.2714  mixup_unsup_d1.loss_bbox: 0.8323  mixup_unsup_d1.loss_iou: 1.0887  mixup_unsup_d2.loss_cls: 0.2640  mixup_unsup_d2.loss_bbox: 0.8402  mixup_unsup_d2.loss_iou: 1.1063  mixup_unsup_d3.loss_cls: 0.2457  mixup_unsup_d3.loss_bbox: 0.8471  mixup_unsup_d3.loss_iou: 1.1033  mixup_unsup_d4.loss_cls: 0.2087  mixup_unsup_d4.loss_bbox: 0.8571  mixup_unsup_d4.loss_iou: 1.0963  mosaic_unsup_loss_cls: 0.0066  mosaic_unsup_loss_bbox: 1.6159  mosaic_unsup_loss_iou: 2.6711  mosaic_unsup_d0.loss_cls: 0.0091  mosaic_unsup_d0.loss_bbox: 1.6230  mosaic_unsup_d0.loss_iou: 2.6124  mosaic_unsup_d1.loss_cls: 0.0076  mosaic_unsup_d1.loss_bbox: 1.6144  mosaic_unsup_d1.loss_iou: 2.6340  mosaic_unsup_d2.loss_cls: 0.0072  mosaic_unsup_d2.loss_bbox: 1.6169  mosaic_unsup_d2.loss_iou: 2.6305  mosaic_unsup_d3.loss_cls: 0.0073  mosaic_unsup_d3.loss_bbox: 1.6186  mosaic_unsup_d3.loss_iou: 2.6240  mosaic_unsup_d4.loss_cls: 0.0068  mosaic_unsup_d4.loss_bbox: 1.6061  mosaic_unsup_d4.loss_iou: 2.6322
2025/06/23 22:45:54 - mmengine - INFO - Iter(train) [  2700/240000]  base_lr: 5.3995e-05 lr: 5.3995e-06  eta: 2 days, 5:33:24  time: 0.7522  data_time: 0.0235  memory: 9885  grad_norm: 1492.5850  loss: 41.0483  sup_loss_cls: 0.6013  sup_loss_bbox: 0.7929  sup_loss_iou: 1.3348  sup_d0.loss_cls: 0.5627  sup_d0.loss_bbox: 0.7537  sup_d0.loss_iou: 1.3096  sup_d1.loss_cls: 0.5674  sup_d1.loss_bbox: 0.7535  sup_d1.loss_iou: 1.2931  sup_d2.loss_cls: 0.5779  sup_d2.loss_bbox: 0.7380  sup_d2.loss_iou: 1.2100  sup_d3.loss_cls: 0.5763  sup_d3.loss_bbox: 0.7687  sup_d3.loss_iou: 1.1736  sup_d4.loss_cls: 0.6224  sup_d4.loss_bbox: 0.7713  sup_d4.loss_iou: 1.2259  mixup_unsup_loss_cls: 0.0318  mixup_unsup_loss_bbox: 0.0633  mixup_unsup_loss_iou: 0.0904  mixup_unsup_d0.loss_cls: 0.0365  mixup_unsup_d0.loss_bbox: 0.0473  mixup_unsup_d0.loss_iou: 0.0894  mixup_unsup_d1.loss_cls: 0.0378  mixup_unsup_d1.loss_bbox: 0.0453  mixup_unsup_d1.loss_iou: 0.0847  mixup_unsup_d2.loss_cls: 0.0364  mixup_unsup_d2.loss_bbox: 0.0556  mixup_unsup_d2.loss_iou: 0.0925  mixup_unsup_d3.loss_cls: 0.0344  mixup_unsup_d3.loss_bbox: 0.0531  mixup_unsup_d3.loss_iou: 0.0880  mixup_unsup_d4.loss_cls: 0.0316  mixup_unsup_d4.loss_bbox: 0.0579  mixup_unsup_d4.loss_iou: 0.0909  mosaic_unsup_loss_cls: 0.0070  mosaic_unsup_loss_bbox: 1.7124  mosaic_unsup_loss_iou: 2.3434  mosaic_unsup_d0.loss_cls: 0.0088  mosaic_unsup_d0.loss_bbox: 1.7196  mosaic_unsup_d0.loss_iou: 2.3341  mosaic_unsup_d1.loss_cls: 0.0076  mosaic_unsup_d1.loss_bbox: 1.7108  mosaic_unsup_d1.loss_iou: 2.3426  mosaic_unsup_d2.loss_cls: 0.0074  mosaic_unsup_d2.loss_bbox: 1.7090  mosaic_unsup_d2.loss_iou: 2.3403  mosaic_unsup_d3.loss_cls: 0.0077  mosaic_unsup_d3.loss_bbox: 1.7084  mosaic_unsup_d3.loss_iou: 2.3373  mosaic_unsup_d4.loss_cls: 0.0074  mosaic_unsup_d4.loss_bbox: 1.7061  mosaic_unsup_d4.loss_iou: 2.3384
2025/06/23 22:46:31 - mmengine - INFO - Iter(train) [  2750/240000]  base_lr: 5.4995e-05 lr: 5.4995e-06  eta: 2 days, 5:27:33  time: 0.7406  data_time: 0.0237  memory: 9627  grad_norm: 844.8021  loss: 42.9410  sup_loss_cls: 0.5331  sup_loss_bbox: 0.6536  sup_loss_iou: 1.1563  sup_d0.loss_cls: 0.5191  sup_d0.loss_bbox: 0.4892  sup_d0.loss_iou: 1.0789  sup_d1.loss_cls: 0.5431  sup_d1.loss_bbox: 0.5283  sup_d1.loss_iou: 1.1841  sup_d2.loss_cls: 0.5542  sup_d2.loss_bbox: 0.5521  sup_d2.loss_iou: 1.1697  sup_d3.loss_cls: 0.5583  sup_d3.loss_bbox: 0.6722  sup_d3.loss_iou: 1.2285  sup_d4.loss_cls: 0.5647  sup_d4.loss_bbox: 0.6039  sup_d4.loss_iou: 1.1846  mixup_unsup_loss_cls: 0.0510  mixup_unsup_loss_bbox: 0.3583  mixup_unsup_loss_iou: 0.4710  mixup_unsup_d0.loss_cls: 0.0547  mixup_unsup_d0.loss_bbox: 0.3472  mixup_unsup_d0.loss_iou: 0.4654  mixup_unsup_d1.loss_cls: 0.0520  mixup_unsup_d1.loss_bbox: 0.3495  mixup_unsup_d1.loss_iou: 0.4658  mixup_unsup_d2.loss_cls: 0.0555  mixup_unsup_d2.loss_bbox: 0.3570  mixup_unsup_d2.loss_iou: 0.4705  mixup_unsup_d3.loss_cls: 0.0612  mixup_unsup_d3.loss_bbox: 0.3468  mixup_unsup_d3.loss_iou: 0.4640  mixup_unsup_d4.loss_cls: 0.0585  mixup_unsup_d4.loss_bbox: 0.3409  mixup_unsup_d4.loss_iou: 0.4614  mosaic_unsup_loss_cls: 0.0053  mosaic_unsup_loss_bbox: 1.6446  mosaic_unsup_loss_iou: 2.3314  mosaic_unsup_d0.loss_cls: 0.0079  mosaic_unsup_d0.loss_bbox: 1.6466  mosaic_unsup_d0.loss_iou: 2.3357  mosaic_unsup_d1.loss_cls: 0.0061  mosaic_unsup_d1.loss_bbox: 1.6418  mosaic_unsup_d1.loss_iou: 2.3426  mosaic_unsup_d2.loss_cls: 0.0054  mosaic_unsup_d2.loss_bbox: 1.6461  mosaic_unsup_d2.loss_iou: 2.3429  mosaic_unsup_d3.loss_cls: 0.0054  mosaic_unsup_d3.loss_bbox: 1.6460  mosaic_unsup_d3.loss_iou: 2.3381  mosaic_unsup_d4.loss_cls: 0.0049  mosaic_unsup_d4.loss_bbox: 1.6470  mosaic_unsup_d4.loss_iou: 2.3385
2025/06/23 22:47:11 - mmengine - INFO - Iter(train) [  2800/240000]  base_lr: 5.5996e-05 lr: 5.5996e-06  eta: 2 days, 5:26:19  time: 0.8033  data_time: 0.0254  memory: 9885  grad_norm: 1540.4044  loss: 47.9992  sup_loss_cls: 0.5621  sup_loss_bbox: 0.5132  sup_loss_iou: 1.1130  sup_d0.loss_cls: 0.5221  sup_d0.loss_bbox: 0.4601  sup_d0.loss_iou: 1.0099  sup_d1.loss_cls: 0.5550  sup_d1.loss_bbox: 0.5215  sup_d1.loss_iou: 1.1867  sup_d2.loss_cls: 0.5687  sup_d2.loss_bbox: 0.4630  sup_d2.loss_iou: 0.9977  sup_d3.loss_cls: 0.5824  sup_d3.loss_bbox: 0.4959  sup_d3.loss_iou: 1.0799  sup_d4.loss_cls: 0.6107  sup_d4.loss_bbox: 0.5130  sup_d4.loss_iou: 1.0775  mixup_unsup_loss_cls: 0.0614  mixup_unsup_loss_bbox: 0.5988  mixup_unsup_loss_iou: 0.8404  mixup_unsup_d0.loss_cls: 0.0639  mixup_unsup_d0.loss_bbox: 0.5732  mixup_unsup_d0.loss_iou: 0.8318  mixup_unsup_d1.loss_cls: 0.0547  mixup_unsup_d1.loss_bbox: 0.5746  mixup_unsup_d1.loss_iou: 0.8349  mixup_unsup_d2.loss_cls: 0.0566  mixup_unsup_d2.loss_bbox: 0.5739  mixup_unsup_d2.loss_iou: 0.8382  mixup_unsup_d3.loss_cls: 0.0563  mixup_unsup_d3.loss_bbox: 0.5700  mixup_unsup_d3.loss_iou: 0.8322  mixup_unsup_d4.loss_cls: 0.0570  mixup_unsup_d4.loss_bbox: 0.5836  mixup_unsup_d4.loss_iou: 0.8332  mosaic_unsup_loss_cls: 0.0286  mosaic_unsup_loss_bbox: 1.5855  mosaic_unsup_loss_iou: 2.7710  mosaic_unsup_d0.loss_cls: 0.0385  mosaic_unsup_d0.loss_bbox: 1.5830  mosaic_unsup_d0.loss_iou: 2.7790  mosaic_unsup_d1.loss_cls: 0.0262  mosaic_unsup_d1.loss_bbox: 1.5883  mosaic_unsup_d1.loss_iou: 2.7793  mosaic_unsup_d2.loss_cls: 0.0234  mosaic_unsup_d2.loss_bbox: 1.5820  mosaic_unsup_d2.loss_iou: 2.7751  mosaic_unsup_d3.loss_cls: 0.0192  mosaic_unsup_d3.loss_bbox: 1.5835  mosaic_unsup_d3.loss_iou: 2.7811  mosaic_unsup_d4.loss_cls: 0.0190  mosaic_unsup_d4.loss_bbox: 1.5875  mosaic_unsup_d4.loss_iou: 2.7818
2025/06/23 22:47:51 - mmengine - INFO - Iter(train) [  2850/240000]  base_lr: 5.6996e-05 lr: 5.6996e-06  eta: 2 days, 5:23:58  time: 0.7869  data_time: 0.0254  memory: 9627  grad_norm: 2218.7012  loss: 47.3231  sup_loss_cls: 0.7901  sup_loss_bbox: 0.7213  sup_loss_iou: 1.3858  sup_d0.loss_cls: 0.7981  sup_d0.loss_bbox: 0.5974  sup_d0.loss_iou: 1.3596  sup_d1.loss_cls: 0.7717  sup_d1.loss_bbox: 0.6048  sup_d1.loss_iou: 1.2317  sup_d2.loss_cls: 0.7772  sup_d2.loss_bbox: 0.6527  sup_d2.loss_iou: 1.2579  sup_d3.loss_cls: 0.8051  sup_d3.loss_bbox: 0.7166  sup_d3.loss_iou: 1.2975  sup_d4.loss_cls: 0.8049  sup_d4.loss_bbox: 0.7991  sup_d4.loss_iou: 1.3653  mixup_unsup_loss_cls: 0.1906  mixup_unsup_loss_bbox: 0.3186  mixup_unsup_loss_iou: 0.4677  mixup_unsup_d0.loss_cls: 0.1824  mixup_unsup_d0.loss_bbox: 0.2891  mixup_unsup_d0.loss_iou: 0.4669  mixup_unsup_d1.loss_cls: 0.1903  mixup_unsup_d1.loss_bbox: 0.3186  mixup_unsup_d1.loss_iou: 0.4708  mixup_unsup_d2.loss_cls: 0.1854  mixup_unsup_d2.loss_bbox: 0.3092  mixup_unsup_d2.loss_iou: 0.4711  mixup_unsup_d3.loss_cls: 0.1757  mixup_unsup_d3.loss_bbox: 0.3069  mixup_unsup_d3.loss_iou: 0.4581  mixup_unsup_d4.loss_cls: 0.1772  mixup_unsup_d4.loss_bbox: 0.3061  mixup_unsup_d4.loss_iou: 0.4485  mosaic_unsup_loss_cls: 0.1196  mosaic_unsup_loss_bbox: 1.5775  mosaic_unsup_loss_iou: 2.4373  mosaic_unsup_d0.loss_cls: 0.1018  mosaic_unsup_d0.loss_bbox: 1.5576  mosaic_unsup_d0.loss_iou: 2.4142  mosaic_unsup_d1.loss_cls: 0.1117  mosaic_unsup_d1.loss_bbox: 1.6032  mosaic_unsup_d1.loss_iou: 2.4349  mosaic_unsup_d2.loss_cls: 0.1269  mosaic_unsup_d2.loss_bbox: 1.5918  mosaic_unsup_d2.loss_iou: 2.4397  mosaic_unsup_d3.loss_cls: 0.1202  mosaic_unsup_d3.loss_bbox: 1.6297  mosaic_unsup_d3.loss_iou: 2.4099  mosaic_unsup_d4.loss_cls: 0.1139  mosaic_unsup_d4.loss_bbox: 1.6423  mosaic_unsup_d4.loss_iou: 2.4208
2025/06/23 22:48:30 - mmengine - INFO - Iter(train) [  2900/240000]  base_lr: 5.7996e-05 lr: 5.7996e-06  eta: 2 days, 5:21:17  time: 0.7812  data_time: 0.0241  memory: 9697  grad_norm: 1124.8010  loss: 50.8367  sup_loss_cls: 0.6181  sup_loss_bbox: 0.7229  sup_loss_iou: 1.2987  sup_d0.loss_cls: 0.6212  sup_d0.loss_bbox: 0.5270  sup_d0.loss_iou: 1.1459  sup_d1.loss_cls: 0.6381  sup_d1.loss_bbox: 0.6652  sup_d1.loss_iou: 1.3235  sup_d2.loss_cls: 0.6556  sup_d2.loss_bbox: 0.7146  sup_d2.loss_iou: 1.3332  sup_d3.loss_cls: 0.6188  sup_d3.loss_bbox: 0.7773  sup_d3.loss_iou: 1.3418  sup_d4.loss_cls: 0.6386  sup_d4.loss_bbox: 0.7442  sup_d4.loss_iou: 1.2749  mixup_unsup_loss_cls: 0.1680  mixup_unsup_loss_bbox: 0.7495  mixup_unsup_loss_iou: 1.0492  mixup_unsup_d0.loss_cls: 0.1563  mixup_unsup_d0.loss_bbox: 0.7180  mixup_unsup_d0.loss_iou: 1.0537  mixup_unsup_d1.loss_cls: 0.1335  mixup_unsup_d1.loss_bbox: 0.7740  mixup_unsup_d1.loss_iou: 1.0585  mixup_unsup_d2.loss_cls: 0.1350  mixup_unsup_d2.loss_bbox: 0.7511  mixup_unsup_d2.loss_iou: 1.0673  mixup_unsup_d3.loss_cls: 0.1516  mixup_unsup_d3.loss_bbox: 0.7411  mixup_unsup_d3.loss_iou: 1.0562  mixup_unsup_d4.loss_cls: 0.1669  mixup_unsup_d4.loss_bbox: 0.7518  mixup_unsup_d4.loss_iou: 1.0578  mosaic_unsup_loss_cls: 0.0244  mosaic_unsup_loss_bbox: 1.6673  mosaic_unsup_loss_iou: 2.2247  mosaic_unsup_d0.loss_cls: 0.0244  mosaic_unsup_d0.loss_bbox: 1.6506  mosaic_unsup_d0.loss_iou: 2.2276  mosaic_unsup_d1.loss_cls: 0.0209  mosaic_unsup_d1.loss_bbox: 1.6572  mosaic_unsup_d1.loss_iou: 2.2264  mosaic_unsup_d2.loss_cls: 0.0220  mosaic_unsup_d2.loss_bbox: 1.6576  mosaic_unsup_d2.loss_iou: 2.2187  mosaic_unsup_d3.loss_cls: 0.0239  mosaic_unsup_d3.loss_bbox: 1.6610  mosaic_unsup_d3.loss_iou: 2.2186  mosaic_unsup_d4.loss_cls: 0.0248  mosaic_unsup_d4.loss_bbox: 1.6647  mosaic_unsup_d4.loss_iou: 2.2223
2025/06/23 22:49:07 - mmengine - INFO - Iter(train) [  2950/240000]  base_lr: 5.8996e-05 lr: 5.8996e-06  eta: 2 days, 5:16:03  time: 0.7420  data_time: 0.0236  memory: 9879  grad_norm: 606.8767  loss: 36.1994  sup_loss_cls: 0.5518  sup_loss_bbox: 0.5618  sup_loss_iou: 1.0837  sup_d0.loss_cls: 0.5543  sup_d0.loss_bbox: 0.5782  sup_d0.loss_iou: 1.2834  sup_d1.loss_cls: 0.5712  sup_d1.loss_bbox: 0.5445  sup_d1.loss_iou: 1.2519  sup_d2.loss_cls: 0.5649  sup_d2.loss_bbox: 0.6479  sup_d2.loss_iou: 1.1914  sup_d3.loss_cls: 0.5498  sup_d3.loss_bbox: 0.5869  sup_d3.loss_iou: 1.0838  sup_d4.loss_cls: 0.5774  sup_d4.loss_bbox: 0.6041  sup_d4.loss_iou: 1.1072  mixup_unsup_loss_cls: 0.0012  mixup_unsup_loss_bbox: 0.0394  mixup_unsup_loss_iou: 0.0924  mixup_unsup_d0.loss_cls: 0.0012  mixup_unsup_d0.loss_bbox: 0.0449  mixup_unsup_d0.loss_iou: 0.1005  mixup_unsup_d1.loss_cls: 0.0008  mixup_unsup_d1.loss_bbox: 0.0413  mixup_unsup_d1.loss_iou: 0.0976  mixup_unsup_d2.loss_cls: 0.0010  mixup_unsup_d2.loss_bbox: 0.0464  mixup_unsup_d2.loss_iou: 0.1044  mixup_unsup_d3.loss_cls: 0.0016  mixup_unsup_d3.loss_bbox: 0.0458  mixup_unsup_d3.loss_iou: 0.1038  mixup_unsup_d4.loss_cls: 0.0012  mixup_unsup_d4.loss_bbox: 0.0377  mixup_unsup_d4.loss_iou: 0.0925  mosaic_unsup_loss_cls: 0.0558  mosaic_unsup_loss_bbox: 1.4568  mosaic_unsup_loss_iou: 2.0645  mosaic_unsup_d0.loss_cls: 0.0441  mosaic_unsup_d0.loss_bbox: 1.4497  mosaic_unsup_d0.loss_iou: 2.0696  mosaic_unsup_d1.loss_cls: 0.0395  mosaic_unsup_d1.loss_bbox: 1.4727  mosaic_unsup_d1.loss_iou: 2.0584  mosaic_unsup_d2.loss_cls: 0.0585  mosaic_unsup_d2.loss_bbox: 1.4556  mosaic_unsup_d2.loss_iou: 2.0675  mosaic_unsup_d3.loss_cls: 0.0520  mosaic_unsup_d3.loss_bbox: 1.4545  mosaic_unsup_d3.loss_iou: 2.0692  mosaic_unsup_d4.loss_cls: 0.0496  mosaic_unsup_d4.loss_bbox: 1.4695  mosaic_unsup_d4.loss_iou: 2.0637
2025/06/23 22:49:45 - mmengine - INFO - Exp name: Newdatamixpl05_detr_r50_100_sonar-s1-p10_20250623_220902
2025/06/23 22:49:45 - mmengine - INFO - Iter(train) [  3000/240000]  base_lr: 5.9996e-05 lr: 5.9996e-06  eta: 2 days, 5:11:53  time: 0.7557  data_time: 0.0233  memory: 9885  grad_norm: 1335.5316  loss: 41.0058  sup_loss_cls: 0.5751  sup_loss_bbox: 0.5915  sup_loss_iou: 1.0936  sup_d0.loss_cls: 0.5739  sup_d0.loss_bbox: 0.5676  sup_d0.loss_iou: 1.1154  sup_d1.loss_cls: 0.5908  sup_d1.loss_bbox: 0.5628  sup_d1.loss_iou: 1.1548  sup_d2.loss_cls: 0.5547  sup_d2.loss_bbox: 0.6309  sup_d2.loss_iou: 1.0970  sup_d3.loss_cls: 0.5758  sup_d3.loss_bbox: 0.6453  sup_d3.loss_iou: 1.1081  sup_d4.loss_cls: 0.5953  sup_d4.loss_bbox: 0.5368  sup_d4.loss_iou: 0.9707  mixup_unsup_loss_cls: 0.0693  mixup_unsup_loss_bbox: 0.1363  mixup_unsup_loss_iou: 0.2197  mixup_unsup_d0.loss_cls: 0.0759  mixup_unsup_d0.loss_bbox: 0.1232  mixup_unsup_d0.loss_iou: 0.2131  mixup_unsup_d1.loss_cls: 0.0662  mixup_unsup_d1.loss_bbox: 0.1304  mixup_unsup_d1.loss_iou: 0.2153  mixup_unsup_d2.loss_cls: 0.0736  mixup_unsup_d2.loss_bbox: 0.1229  mixup_unsup_d2.loss_iou: 0.2121  mixup_unsup_d3.loss_cls: 0.0655  mixup_unsup_d3.loss_bbox: 0.1127  mixup_unsup_d3.loss_iou: 0.2011  mixup_unsup_d4.loss_cls: 0.0621  mixup_unsup_d4.loss_bbox: 0.1347  mixup_unsup_d4.loss_iou: 0.2097  mosaic_unsup_loss_cls: 0.0973  mosaic_unsup_loss_bbox: 1.7762  mosaic_unsup_loss_iou: 2.3047  mosaic_unsup_d0.loss_cls: 0.1024  mosaic_unsup_d0.loss_bbox: 1.7620  mosaic_unsup_d0.loss_iou: 2.3071  mosaic_unsup_d1.loss_cls: 0.0904  mosaic_unsup_d1.loss_bbox: 1.7593  mosaic_unsup_d1.loss_iou: 2.3100  mosaic_unsup_d2.loss_cls: 0.1014  mosaic_unsup_d2.loss_bbox: 1.7666  mosaic_unsup_d2.loss_iou: 2.3102  mosaic_unsup_d3.loss_cls: 0.0929  mosaic_unsup_d3.loss_bbox: 1.7680  mosaic_unsup_d3.loss_iou: 2.3088  mosaic_unsup_d4.loss_cls: 0.0852  mosaic_unsup_d4.loss_bbox: 1.7704  mosaic_unsup_d4.loss_iou: 2.3092
2025/06/23 22:50:23 - mmengine - INFO - Iter(train) [  3050/240000]  base_lr: 6.0996e-05 lr: 6.0996e-06  eta: 2 days, 5:07:53  time: 0.7568  data_time: 0.0238  memory: 9821  grad_norm: 718.9561  loss: 41.7912  sup_loss_cls: 0.6277  sup_loss_bbox: 0.8409  sup_loss_iou: 1.3999  sup_d0.loss_cls: 0.5958  sup_d0.loss_bbox: 0.5395  sup_d0.loss_iou: 1.1163  sup_d1.loss_cls: 0.6197  sup_d1.loss_bbox: 0.6292  sup_d1.loss_iou: 1.2006  sup_d2.loss_cls: 0.6247  sup_d2.loss_bbox: 0.5844  sup_d2.loss_iou: 1.1752  sup_d3.loss_cls: 0.6572  sup_d3.loss_bbox: 0.6835  sup_d3.loss_iou: 1.1845  sup_d4.loss_cls: 0.6406  sup_d4.loss_bbox: 0.6769  sup_d4.loss_iou: 1.1504  mixup_unsup_loss_cls: 0.0491  mixup_unsup_loss_bbox: 0.1257  mixup_unsup_loss_iou: 0.1892  mixup_unsup_d0.loss_cls: 0.0384  mixup_unsup_d0.loss_bbox: 0.1231  mixup_unsup_d0.loss_iou: 0.1929  mixup_unsup_d1.loss_cls: 0.0431  mixup_unsup_d1.loss_bbox: 0.1313  mixup_unsup_d1.loss_iou: 0.1947  mixup_unsup_d2.loss_cls: 0.0485  mixup_unsup_d2.loss_bbox: 0.1265  mixup_unsup_d2.loss_iou: 0.1955  mixup_unsup_d3.loss_cls: 0.0419  mixup_unsup_d3.loss_bbox: 0.1298  mixup_unsup_d3.loss_iou: 0.1881  mixup_unsup_d4.loss_cls: 0.0465  mixup_unsup_d4.loss_bbox: 0.1234  mixup_unsup_d4.loss_iou: 0.1893  mosaic_unsup_loss_cls: 0.0316  mosaic_unsup_loss_bbox: 1.6725  mosaic_unsup_loss_iou: 2.3959  mosaic_unsup_d0.loss_cls: 0.0243  mosaic_unsup_d0.loss_bbox: 1.6785  mosaic_unsup_d0.loss_iou: 2.4029  mosaic_unsup_d1.loss_cls: 0.0208  mosaic_unsup_d1.loss_bbox: 1.6908  mosaic_unsup_d1.loss_iou: 2.4038  mosaic_unsup_d2.loss_cls: 0.0295  mosaic_unsup_d2.loss_bbox: 1.6724  mosaic_unsup_d2.loss_iou: 2.4055  mosaic_unsup_d3.loss_cls: 0.0218  mosaic_unsup_d3.loss_bbox: 1.6844  mosaic_unsup_d3.loss_iou: 2.4042  mosaic_unsup_d4.loss_cls: 0.0302  mosaic_unsup_d4.loss_bbox: 1.6935  mosaic_unsup_d4.loss_iou: 2.4046
2025/06/23 22:51:01 - mmengine - INFO - Iter(train) [  3100/240000]  base_lr: 6.1996e-05 lr: 6.1996e-06  eta: 2 days, 5:04:24  time: 0.7632  data_time: 0.0247  memory: 9819  grad_norm: 562.4860  loss: 49.1326  sup_loss_cls: 0.4999  sup_loss_bbox: 0.7140  sup_loss_iou: 1.3095  sup_d0.loss_cls: 0.4756  sup_d0.loss_bbox: 0.5302  sup_d0.loss_iou: 1.2480  sup_d1.loss_cls: 0.4900  sup_d1.loss_bbox: 0.6016  sup_d1.loss_iou: 1.2232  sup_d2.loss_cls: 0.5044  sup_d2.loss_bbox: 0.6293  sup_d2.loss_iou: 1.2410  sup_d3.loss_cls: 0.5276  sup_d3.loss_bbox: 0.6537  sup_d3.loss_iou: 1.1939  sup_d4.loss_cls: 0.5311  sup_d4.loss_bbox: 0.6768  sup_d4.loss_iou: 1.2141  mixup_unsup_loss_cls: 0.0042  mixup_unsup_loss_bbox: 0.3074  mixup_unsup_loss_iou: 0.5016  mixup_unsup_d0.loss_cls: 0.0045  mixup_unsup_d0.loss_bbox: 0.2982  mixup_unsup_d0.loss_iou: 0.4956  mixup_unsup_d1.loss_cls: 0.0039  mixup_unsup_d1.loss_bbox: 0.3077  mixup_unsup_d1.loss_iou: 0.4998  mixup_unsup_d2.loss_cls: 0.0037  mixup_unsup_d2.loss_bbox: 0.3074  mixup_unsup_d2.loss_iou: 0.4999  mixup_unsup_d3.loss_cls: 0.0042  mixup_unsup_d3.loss_bbox: 0.3043  mixup_unsup_d3.loss_iou: 0.4992  mixup_unsup_d4.loss_cls: 0.0043  mixup_unsup_d4.loss_bbox: 0.3068  mixup_unsup_d4.loss_iou: 0.5012  mosaic_unsup_loss_cls: 0.1290  mosaic_unsup_loss_bbox: 2.0663  mosaic_unsup_loss_iou: 2.8111  mosaic_unsup_d0.loss_cls: 0.1164  mosaic_unsup_d0.loss_bbox: 2.0470  mosaic_unsup_d0.loss_iou: 2.8380  mosaic_unsup_d1.loss_cls: 0.1162  mosaic_unsup_d1.loss_bbox: 2.0458  mosaic_unsup_d1.loss_iou: 2.8176  mosaic_unsup_d2.loss_cls: 0.1238  mosaic_unsup_d2.loss_bbox: 2.0606  mosaic_unsup_d2.loss_iou: 2.8184  mosaic_unsup_d3.loss_cls: 0.1137  mosaic_unsup_d3.loss_bbox: 2.0778  mosaic_unsup_d3.loss_iou: 2.8152  mosaic_unsup_d4.loss_cls: 0.1201  mosaic_unsup_d4.loss_bbox: 2.0851  mosaic_unsup_d4.loss_iou: 2.8126
2025/06/23 22:51:39 - mmengine - INFO - Iter(train) [  3150/240000]  base_lr: 6.2996e-05 lr: 6.2996e-06  eta: 2 days, 5:01:22  time: 0.7688  data_time: 0.0226  memory: 9885  grad_norm: 1396.3031  loss: 49.7110  sup_loss_cls: 0.5798  sup_loss_bbox: 0.6589  sup_loss_iou: 1.3052  sup_d0.loss_cls: 0.5597  sup_d0.loss_bbox: 0.4766  sup_d0.loss_iou: 1.0683  sup_d1.loss_cls: 0.5910  sup_d1.loss_bbox: 0.5791  sup_d1.loss_iou: 1.2068  sup_d2.loss_cls: 0.5924  sup_d2.loss_bbox: 0.5745  sup_d2.loss_iou: 1.0805  sup_d3.loss_cls: 0.6024  sup_d3.loss_bbox: 0.5793  sup_d3.loss_iou: 1.1195  sup_d4.loss_cls: 0.5914  sup_d4.loss_bbox: 0.6131  sup_d4.loss_iou: 1.1190  mixup_unsup_loss_cls: 0.0378  mixup_unsup_loss_bbox: 0.5404  mixup_unsup_loss_iou: 0.9367  mixup_unsup_d0.loss_cls: 0.0402  mixup_unsup_d0.loss_bbox: 0.5082  mixup_unsup_d0.loss_iou: 0.9094  mixup_unsup_d1.loss_cls: 0.0396  mixup_unsup_d1.loss_bbox: 0.5213  mixup_unsup_d1.loss_iou: 0.9164  mixup_unsup_d2.loss_cls: 0.0441  mixup_unsup_d2.loss_bbox: 0.5220  mixup_unsup_d2.loss_iou: 0.9064  mixup_unsup_d3.loss_cls: 0.0413  mixup_unsup_d3.loss_bbox: 0.5402  mixup_unsup_d3.loss_iou: 0.9122  mixup_unsup_d4.loss_cls: 0.0377  mixup_unsup_d4.loss_bbox: 0.5540  mixup_unsup_d4.loss_iou: 0.9127  mosaic_unsup_loss_cls: 0.0117  mosaic_unsup_loss_bbox: 1.7423  mosaic_unsup_loss_iou: 2.7092  mosaic_unsup_d0.loss_cls: 0.0146  mosaic_unsup_d0.loss_bbox: 1.7645  mosaic_unsup_d0.loss_iou: 2.7268  mosaic_unsup_d1.loss_cls: 0.0097  mosaic_unsup_d1.loss_bbox: 1.7648  mosaic_unsup_d1.loss_iou: 2.7278  mosaic_unsup_d2.loss_cls: 0.0133  mosaic_unsup_d2.loss_bbox: 1.7671  mosaic_unsup_d2.loss_iou: 2.7081  mosaic_unsup_d3.loss_cls: 0.0132  mosaic_unsup_d3.loss_bbox: 1.7577  mosaic_unsup_d3.loss_iou: 2.7043  mosaic_unsup_d4.loss_cls: 0.0125  mosaic_unsup_d4.loss_bbox: 1.7444  mosaic_unsup_d4.loss_iou: 2.7008
2025/06/23 22:52:16 - mmengine - INFO - Iter(train) [  3200/240000]  base_lr: 6.3996e-05 lr: 6.3996e-06  eta: 2 days, 4:56:51  time: 0.7434  data_time: 0.0236  memory: 9886  grad_norm: 890.4559  loss: 41.3710  sup_loss_cls: 0.7189  sup_loss_bbox: 0.7597  sup_loss_iou: 1.3063  sup_d0.loss_cls: 0.6907  sup_d0.loss_bbox: 0.5331  sup_d0.loss_iou: 1.2090  sup_d1.loss_cls: 0.7261  sup_d1.loss_bbox: 0.5653  sup_d1.loss_iou: 1.2018  sup_d2.loss_cls: 0.7093  sup_d2.loss_bbox: 0.5809  sup_d2.loss_iou: 1.1729  sup_d3.loss_cls: 0.7202  sup_d3.loss_bbox: 0.6451  sup_d3.loss_iou: 1.1965  sup_d4.loss_cls: 0.7294  sup_d4.loss_bbox: 0.7516  sup_d4.loss_iou: 1.3024  mixup_unsup_loss_cls: 0.1042  mixup_unsup_loss_bbox: 0.1760  mixup_unsup_loss_iou: 0.3287  mixup_unsup_d0.loss_cls: 0.1010  mixup_unsup_d0.loss_bbox: 0.1774  mixup_unsup_d0.loss_iou: 0.3205  mixup_unsup_d1.loss_cls: 0.1041  mixup_unsup_d1.loss_bbox: 0.1726  mixup_unsup_d1.loss_iou: 0.3219  mixup_unsup_d2.loss_cls: 0.1037  mixup_unsup_d2.loss_bbox: 0.1653  mixup_unsup_d2.loss_iou: 0.3123  mixup_unsup_d3.loss_cls: 0.0998  mixup_unsup_d3.loss_bbox: 0.1672  mixup_unsup_d3.loss_iou: 0.3197  mixup_unsup_d4.loss_cls: 0.1032  mixup_unsup_d4.loss_bbox: 0.1738  mixup_unsup_d4.loss_iou: 0.3246  mosaic_unsup_loss_cls: 0.0182  mosaic_unsup_loss_bbox: 1.5163  mosaic_unsup_loss_iou: 2.1682  mosaic_unsup_d0.loss_cls: 0.0208  mosaic_unsup_d0.loss_bbox: 1.5218  mosaic_unsup_d0.loss_iou: 2.1742  mosaic_unsup_d1.loss_cls: 0.0209  mosaic_unsup_d1.loss_bbox: 1.5203  mosaic_unsup_d1.loss_iou: 2.1795  mosaic_unsup_d2.loss_cls: 0.0212  mosaic_unsup_d2.loss_bbox: 1.5138  mosaic_unsup_d2.loss_iou: 2.1771  mosaic_unsup_d3.loss_cls: 0.0198  mosaic_unsup_d3.loss_bbox: 1.5221  mosaic_unsup_d3.loss_iou: 2.1737  mosaic_unsup_d4.loss_cls: 0.0177  mosaic_unsup_d4.loss_bbox: 1.5145  mosaic_unsup_d4.loss_iou: 2.1759
2025/06/23 22:52:54 - mmengine - INFO - Iter(train) [  3250/240000]  base_lr: 6.4996e-05 lr: 6.4996e-06  eta: 2 days, 4:53:12  time: 0.7559  data_time: 0.0237  memory: 9885  grad_norm: 1661.8800  loss: 41.1548  sup_loss_cls: 0.6558  sup_loss_bbox: 0.7554  sup_loss_iou: 1.2575  sup_d0.loss_cls: 0.6075  sup_d0.loss_bbox: 0.5554  sup_d0.loss_iou: 1.1510  sup_d1.loss_cls: 0.6694  sup_d1.loss_bbox: 0.7145  sup_d1.loss_iou: 1.3334  sup_d2.loss_cls: 0.6516  sup_d2.loss_bbox: 0.6942  sup_d2.loss_iou: 1.1229  sup_d3.loss_cls: 0.6609  sup_d3.loss_bbox: 0.7513  sup_d3.loss_iou: 1.2055  sup_d4.loss_cls: 0.6703  sup_d4.loss_bbox: 0.8742  sup_d4.loss_iou: 1.4134  mixup_unsup_loss_cls: 0.0545  mixup_unsup_loss_bbox: 0.2112  mixup_unsup_loss_iou: 0.3497  mixup_unsup_d0.loss_cls: 0.0495  mixup_unsup_d0.loss_bbox: 0.1978  mixup_unsup_d0.loss_iou: 0.3574  mixup_unsup_d1.loss_cls: 0.0488  mixup_unsup_d1.loss_bbox: 0.1982  mixup_unsup_d1.loss_iou: 0.3545  mixup_unsup_d2.loss_cls: 0.0547  mixup_unsup_d2.loss_bbox: 0.1969  mixup_unsup_d2.loss_iou: 0.3505  mixup_unsup_d3.loss_cls: 0.0533  mixup_unsup_d3.loss_bbox: 0.2083  mixup_unsup_d3.loss_iou: 0.3552  mixup_unsup_d4.loss_cls: 0.0539  mixup_unsup_d4.loss_bbox: 0.2151  mixup_unsup_d4.loss_iou: 0.3485  mosaic_unsup_loss_cls: 0.0484  mosaic_unsup_loss_bbox: 1.4457  mosaic_unsup_loss_iou: 2.1507  mosaic_unsup_d0.loss_cls: 0.0388  mosaic_unsup_d0.loss_bbox: 1.4258  mosaic_unsup_d0.loss_iou: 2.1510  mosaic_unsup_d1.loss_cls: 0.0342  mosaic_unsup_d1.loss_bbox: 1.4337  mosaic_unsup_d1.loss_iou: 2.1570  mosaic_unsup_d2.loss_cls: 0.0431  mosaic_unsup_d2.loss_bbox: 1.4360  mosaic_unsup_d2.loss_iou: 2.1506  mosaic_unsup_d3.loss_cls: 0.0398  mosaic_unsup_d3.loss_bbox: 1.4251  mosaic_unsup_d3.loss_iou: 2.1436  mosaic_unsup_d4.loss_cls: 0.0450  mosaic_unsup_d4.loss_bbox: 1.4340  mosaic_unsup_d4.loss_iou: 2.1499
2025/06/23 22:53:32 - mmengine - INFO - Iter(train) [  3300/240000]  base_lr: 6.5997e-05 lr: 6.5997e-06  eta: 2 days, 4:50:12  time: 0.7652  data_time: 0.0235  memory: 9886  grad_norm: 1296.9725  loss: 49.5588  sup_loss_cls: 0.8063  sup_loss_bbox: 0.7703  sup_loss_iou: 1.3264  sup_d0.loss_cls: 0.7536  sup_d0.loss_bbox: 0.6712  sup_d0.loss_iou: 1.2846  sup_d1.loss_cls: 0.7737  sup_d1.loss_bbox: 0.7210  sup_d1.loss_iou: 1.4073  sup_d2.loss_cls: 0.8058  sup_d2.loss_bbox: 0.6867  sup_d2.loss_iou: 1.2307  sup_d3.loss_cls: 0.7926  sup_d3.loss_bbox: 0.7433  sup_d3.loss_iou: 1.2772  sup_d4.loss_cls: 0.8142  sup_d4.loss_bbox: 0.8194  sup_d4.loss_iou: 1.3689  mixup_unsup_loss_cls: 0.0028  mixup_unsup_loss_bbox: 0.3355  mixup_unsup_loss_iou: 0.4955  mixup_unsup_d0.loss_cls: 0.0038  mixup_unsup_d0.loss_bbox: 0.3334  mixup_unsup_d0.loss_iou: 0.4938  mixup_unsup_d1.loss_cls: 0.0031  mixup_unsup_d1.loss_bbox: 0.3325  mixup_unsup_d1.loss_iou: 0.4922  mixup_unsup_d2.loss_cls: 0.0023  mixup_unsup_d2.loss_bbox: 0.3288  mixup_unsup_d2.loss_iou: 0.4892  mixup_unsup_d3.loss_cls: 0.0026  mixup_unsup_d3.loss_bbox: 0.3321  mixup_unsup_d3.loss_iou: 0.4916  mixup_unsup_d4.loss_cls: 0.0026  mixup_unsup_d4.loss_bbox: 0.3326  mixup_unsup_d4.loss_iou: 0.4936  mosaic_unsup_loss_cls: 0.0375  mosaic_unsup_loss_bbox: 1.8032  mosaic_unsup_loss_iou: 2.7282  mosaic_unsup_d0.loss_cls: 0.0435  mosaic_unsup_d0.loss_bbox: 1.8154  mosaic_unsup_d0.loss_iou: 2.7180  mosaic_unsup_d1.loss_cls: 0.0480  mosaic_unsup_d1.loss_bbox: 1.8239  mosaic_unsup_d1.loss_iou: 2.7307  mosaic_unsup_d2.loss_cls: 0.0467  mosaic_unsup_d2.loss_bbox: 1.8440  mosaic_unsup_d2.loss_iou: 2.7243  mosaic_unsup_d3.loss_cls: 0.0417  mosaic_unsup_d3.loss_bbox: 1.8215  mosaic_unsup_d3.loss_iou: 2.7195  mosaic_unsup_d4.loss_cls: 0.0424  mosaic_unsup_d4.loss_bbox: 1.8105  mosaic_unsup_d4.loss_iou: 2.7384
2025/06/23 22:54:11 - mmengine - INFO - Iter(train) [  3350/240000]  base_lr: 6.6997e-05 lr: 6.6997e-06  eta: 2 days, 4:47:18  time: 0.7658  data_time: 0.0232  memory: 9885  grad_norm: 1547.7621  loss: 47.3410  sup_loss_cls: 0.7174  sup_loss_bbox: 0.7186  sup_loss_iou: 1.4022  sup_d0.loss_cls: 0.7201  sup_d0.loss_bbox: 0.5702  sup_d0.loss_iou: 1.2025  sup_d1.loss_cls: 0.7358  sup_d1.loss_bbox: 0.6021  sup_d1.loss_iou: 1.2045  sup_d2.loss_cls: 0.7152  sup_d2.loss_bbox: 0.6837  sup_d2.loss_iou: 1.2146  sup_d3.loss_cls: 0.7277  sup_d3.loss_bbox: 0.6592  sup_d3.loss_iou: 1.2295  sup_d4.loss_cls: 0.7368  sup_d4.loss_bbox: 0.7215  sup_d4.loss_iou: 1.3284  mixup_unsup_loss_cls: 0.1100  mixup_unsup_loss_bbox: 0.3881  mixup_unsup_loss_iou: 0.4927  mixup_unsup_d0.loss_cls: 0.1018  mixup_unsup_d0.loss_bbox: 0.3629  mixup_unsup_d0.loss_iou: 0.4902  mixup_unsup_d1.loss_cls: 0.0973  mixup_unsup_d1.loss_bbox: 0.3459  mixup_unsup_d1.loss_iou: 0.4858  mixup_unsup_d2.loss_cls: 0.1121  mixup_unsup_d2.loss_bbox: 0.3323  mixup_unsup_d2.loss_iou: 0.4816  mixup_unsup_d3.loss_cls: 0.1056  mixup_unsup_d3.loss_bbox: 0.3346  mixup_unsup_d3.loss_iou: 0.4857  mixup_unsup_d4.loss_cls: 0.1031  mixup_unsup_d4.loss_bbox: 0.3670  mixup_unsup_d4.loss_iou: 0.4830  mosaic_unsup_loss_cls: 0.3268  mosaic_unsup_loss_bbox: 1.5189  mosaic_unsup_loss_iou: 2.4946  mosaic_unsup_d0.loss_cls: 0.3412  mosaic_unsup_d0.loss_bbox: 1.4766  mosaic_unsup_d0.loss_iou: 2.5125  mosaic_unsup_d1.loss_cls: 0.3400  mosaic_unsup_d1.loss_bbox: 1.4532  mosaic_unsup_d1.loss_iou: 2.4918  mosaic_unsup_d2.loss_cls: 0.3406  mosaic_unsup_d2.loss_bbox: 1.4546  mosaic_unsup_d2.loss_iou: 2.4929  mosaic_unsup_d3.loss_cls: 0.3116  mosaic_unsup_d3.loss_bbox: 1.4446  mosaic_unsup_d3.loss_iou: 2.4810  mosaic_unsup_d4.loss_cls: 0.3039  mosaic_unsup_d4.loss_bbox: 1.4852  mosaic_unsup_d4.loss_iou: 2.5010
2025/06/23 22:54:48 - mmengine - INFO - Iter(train) [  3400/240000]  base_lr: 6.7997e-05 lr: 6.7997e-06  eta: 2 days, 4:43:12  time: 0.7438  data_time: 0.0233  memory: 9819  grad_norm: 625.4023  loss: 42.8045  sup_loss_cls: 0.5341  sup_loss_bbox: 0.7647  sup_loss_iou: 1.3087  sup_d0.loss_cls: 0.5130  sup_d0.loss_bbox: 0.5477  sup_d0.loss_iou: 1.2522  sup_d1.loss_cls: 0.5390  sup_d1.loss_bbox: 0.5775  sup_d1.loss_iou: 1.1744  sup_d2.loss_cls: 0.5249  sup_d2.loss_bbox: 0.7613  sup_d2.loss_iou: 1.3105  sup_d3.loss_cls: 0.5587  sup_d3.loss_bbox: 0.6310  sup_d3.loss_iou: 1.1514  sup_d4.loss_cls: 0.5275  sup_d4.loss_bbox: 0.7053  sup_d4.loss_iou: 1.2659  mixup_unsup_loss_cls: 0.1242  mixup_unsup_loss_bbox: 0.2808  mixup_unsup_loss_iou: 0.4548  mixup_unsup_d0.loss_cls: 0.1243  mixup_unsup_d0.loss_bbox: 0.2588  mixup_unsup_d0.loss_iou: 0.4556  mixup_unsup_d1.loss_cls: 0.1297  mixup_unsup_d1.loss_bbox: 0.2458  mixup_unsup_d1.loss_iou: 0.4551  mixup_unsup_d2.loss_cls: 0.1279  mixup_unsup_d2.loss_bbox: 0.2478  mixup_unsup_d2.loss_iou: 0.4502  mixup_unsup_d3.loss_cls: 0.1199  mixup_unsup_d3.loss_bbox: 0.2684  mixup_unsup_d3.loss_iou: 0.4500  mixup_unsup_d4.loss_cls: 0.1349  mixup_unsup_d4.loss_bbox: 0.2656  mixup_unsup_d4.loss_iou: 0.4477  mosaic_unsup_loss_cls: 0.0791  mosaic_unsup_loss_bbox: 1.5274  mosaic_unsup_loss_iou: 2.2453  mosaic_unsup_d0.loss_cls: 0.0787  mosaic_unsup_d0.loss_bbox: 1.5331  mosaic_unsup_d0.loss_iou: 2.2644  mosaic_unsup_d1.loss_cls: 0.0765  mosaic_unsup_d1.loss_bbox: 1.5110  mosaic_unsup_d1.loss_iou: 2.2504  mosaic_unsup_d2.loss_cls: 0.0729  mosaic_unsup_d2.loss_bbox: 1.5271  mosaic_unsup_d2.loss_iou: 2.2575  mosaic_unsup_d3.loss_cls: 0.0694  mosaic_unsup_d3.loss_bbox: 1.5318  mosaic_unsup_d3.loss_iou: 2.2531  mosaic_unsup_d4.loss_cls: 0.0845  mosaic_unsup_d4.loss_bbox: 1.5145  mosaic_unsup_d4.loss_iou: 2.2383
2025/06/23 22:55:26 - mmengine - INFO - Iter(train) [  3450/240000]  base_lr: 6.8997e-05 lr: 6.8997e-06  eta: 2 days, 4:39:48  time: 0.7544  data_time: 0.0236  memory: 9885  grad_norm: 1521.2020  loss: 47.8894  sup_loss_cls: 0.6909  sup_loss_bbox: 0.6820  sup_loss_iou: 1.2408  sup_d0.loss_cls: 0.7043  sup_d0.loss_bbox: 0.5013  sup_d0.loss_iou: 1.0794  sup_d1.loss_cls: 0.7637  sup_d1.loss_bbox: 0.5718  sup_d1.loss_iou: 1.1768  sup_d2.loss_cls: 0.6769  sup_d2.loss_bbox: 0.6098  sup_d2.loss_iou: 1.0562  sup_d3.loss_cls: 0.7348  sup_d3.loss_bbox: 0.5902  sup_d3.loss_iou: 1.1050  sup_d4.loss_cls: 0.7104  sup_d4.loss_bbox: 0.6345  sup_d4.loss_iou: 1.0976  mixup_unsup_loss_cls: 0.1420  mixup_unsup_loss_bbox: 0.3330  mixup_unsup_loss_iou: 0.3887  mixup_unsup_d0.loss_cls: 0.1242  mixup_unsup_d0.loss_bbox: 0.2810  mixup_unsup_d0.loss_iou: 0.3924  mixup_unsup_d1.loss_cls: 0.1241  mixup_unsup_d1.loss_bbox: 0.2996  mixup_unsup_d1.loss_iou: 0.3845  mixup_unsup_d2.loss_cls: 0.1592  mixup_unsup_d2.loss_bbox: 0.2975  mixup_unsup_d2.loss_iou: 0.3906  mixup_unsup_d3.loss_cls: 0.1409  mixup_unsup_d3.loss_bbox: 0.2943  mixup_unsup_d3.loss_iou: 0.3899  mixup_unsup_d4.loss_cls: 0.1441  mixup_unsup_d4.loss_bbox: 0.3054  mixup_unsup_d4.loss_iou: 0.3919  mosaic_unsup_loss_cls: 0.3245  mosaic_unsup_loss_bbox: 1.8930  mosaic_unsup_loss_iou: 2.5660  mosaic_unsup_d0.loss_cls: 0.2691  mosaic_unsup_d0.loss_bbox: 1.7818  mosaic_unsup_d0.loss_iou: 2.5807  mosaic_unsup_d1.loss_cls: 0.2643  mosaic_unsup_d1.loss_bbox: 1.8387  mosaic_unsup_d1.loss_iou: 2.5736  mosaic_unsup_d2.loss_cls: 0.3539  mosaic_unsup_d2.loss_bbox: 1.8043  mosaic_unsup_d2.loss_iou: 2.5895  mosaic_unsup_d3.loss_cls: 0.3251  mosaic_unsup_d3.loss_bbox: 1.7894  mosaic_unsup_d3.loss_iou: 2.5881  mosaic_unsup_d4.loss_cls: 0.3262  mosaic_unsup_d4.loss_bbox: 1.8296  mosaic_unsup_d4.loss_iou: 2.5824
2025/06/23 22:56:04 - mmengine - INFO - Iter(train) [  3500/240000]  base_lr: 6.9997e-05 lr: 6.9997e-06  eta: 2 days, 4:37:37  time: 0.7745  data_time: 0.0238  memory: 9703  grad_norm: 1085.1859  loss: 52.0628  sup_loss_cls: 0.7416  sup_loss_bbox: 0.7492  sup_loss_iou: 1.3662  sup_d0.loss_cls: 0.7183  sup_d0.loss_bbox: 0.5708  sup_d0.loss_iou: 1.1600  sup_d1.loss_cls: 0.7094  sup_d1.loss_bbox: 0.6616  sup_d1.loss_iou: 1.2565  sup_d2.loss_cls: 0.7437  sup_d2.loss_bbox: 0.6966  sup_d2.loss_iou: 1.3050  sup_d3.loss_cls: 0.7338  sup_d3.loss_bbox: 0.7467  sup_d3.loss_iou: 1.3155  sup_d4.loss_cls: 0.7468  sup_d4.loss_bbox: 0.7906  sup_d4.loss_iou: 1.3344  mixup_unsup_loss_cls: 0.0891  mixup_unsup_loss_bbox: 0.4189  mixup_unsup_loss_iou: 0.6959  mixup_unsup_d0.loss_cls: 0.1055  mixup_unsup_d0.loss_bbox: 0.3952  mixup_unsup_d0.loss_iou: 0.6918  mixup_unsup_d1.loss_cls: 0.1185  mixup_unsup_d1.loss_bbox: 0.3880  mixup_unsup_d1.loss_iou: 0.6991  mixup_unsup_d2.loss_cls: 0.1083  mixup_unsup_d2.loss_bbox: 0.3921  mixup_unsup_d2.loss_iou: 0.6943  mixup_unsup_d3.loss_cls: 0.0963  mixup_unsup_d3.loss_bbox: 0.4040  mixup_unsup_d3.loss_iou: 0.6869  mixup_unsup_d4.loss_cls: 0.0984  mixup_unsup_d4.loss_bbox: 0.3990  mixup_unsup_d4.loss_iou: 0.6971  mosaic_unsup_loss_cls: 0.1328  mosaic_unsup_loss_bbox: 1.8341  mosaic_unsup_loss_iou: 2.7547  mosaic_unsup_d0.loss_cls: 0.1673  mosaic_unsup_d0.loss_bbox: 1.8305  mosaic_unsup_d0.loss_iou: 2.7511  mosaic_unsup_d1.loss_cls: 0.1816  mosaic_unsup_d1.loss_bbox: 1.8431  mosaic_unsup_d1.loss_iou: 2.7618  mosaic_unsup_d2.loss_cls: 0.1610  mosaic_unsup_d2.loss_bbox: 1.8486  mosaic_unsup_d2.loss_iou: 2.7576  mosaic_unsup_d3.loss_cls: 0.1486  mosaic_unsup_d3.loss_bbox: 1.8482  mosaic_unsup_d3.loss_iou: 2.7587  mosaic_unsup_d4.loss_cls: 0.1509  mosaic_unsup_d4.loss_bbox: 1.8384  mosaic_unsup_d4.loss_iou: 2.7685
2025/06/23 22:56:45 - mmengine - INFO - Iter(train) [  3550/240000]  base_lr: 7.0997e-05 lr: 7.0997e-06  eta: 2 days, 4:37:16  time: 0.8070  data_time: 0.0265  memory: 9704  grad_norm: 617.0671  loss: 43.0975  sup_loss_cls: 0.5067  sup_loss_bbox: 0.6152  sup_loss_iou: 1.1821  sup_d0.loss_cls: 0.5014  sup_d0.loss_bbox: 0.5182  sup_d0.loss_iou: 1.1113  sup_d1.loss_cls: 0.5477  sup_d1.loss_bbox: 0.5118  sup_d1.loss_iou: 1.1341  sup_d2.loss_cls: 0.5495  sup_d2.loss_bbox: 0.5021  sup_d2.loss_iou: 0.9574  sup_d3.loss_cls: 0.5455  sup_d3.loss_bbox: 0.5890  sup_d3.loss_iou: 1.2072  sup_d4.loss_cls: 0.5342  sup_d4.loss_bbox: 0.5624  sup_d4.loss_iou: 1.0511  mixup_unsup_loss_cls: 0.0864  mixup_unsup_loss_bbox: 0.4596  mixup_unsup_loss_iou: 0.7296  mixup_unsup_d0.loss_cls: 0.1173  mixup_unsup_d0.loss_bbox: 0.4569  mixup_unsup_d0.loss_iou: 0.7167  mixup_unsup_d1.loss_cls: 0.0936  mixup_unsup_d1.loss_bbox: 0.4635  mixup_unsup_d1.loss_iou: 0.7280  mixup_unsup_d2.loss_cls: 0.0921  mixup_unsup_d2.loss_bbox: 0.4684  mixup_unsup_d2.loss_iou: 0.7234  mixup_unsup_d3.loss_cls: 0.0970  mixup_unsup_d3.loss_bbox: 0.4629  mixup_unsup_d3.loss_iou: 0.7227  mixup_unsup_d4.loss_cls: 0.0972  mixup_unsup_d4.loss_bbox: 0.4534  mixup_unsup_d4.loss_iou: 0.7224  mosaic_unsup_loss_cls: 0.0154  mosaic_unsup_loss_bbox: 1.2874  mosaic_unsup_loss_iou: 2.4061  mosaic_unsup_d0.loss_cls: 0.0196  mosaic_unsup_d0.loss_bbox: 1.2936  mosaic_unsup_d0.loss_iou: 2.4070  mosaic_unsup_d1.loss_cls: 0.0182  mosaic_unsup_d1.loss_bbox: 1.2920  mosaic_unsup_d1.loss_iou: 2.4013  mosaic_unsup_d2.loss_cls: 0.0150  mosaic_unsup_d2.loss_bbox: 1.2956  mosaic_unsup_d2.loss_iou: 2.4047  mosaic_unsup_d3.loss_cls: 0.0158  mosaic_unsup_d3.loss_bbox: 1.2897  mosaic_unsup_d3.loss_iou: 2.4069  mosaic_unsup_d4.loss_cls: 0.0160  mosaic_unsup_d4.loss_bbox: 1.2917  mosaic_unsup_d4.loss_iou: 2.4033
2025/06/23 22:57:24 - mmengine - INFO - Iter(train) [  3600/240000]  base_lr: 7.1997e-05 lr: 7.1997e-06  eta: 2 days, 4:35:37  time: 0.7830  data_time: 0.0235  memory: 9624  grad_norm: 924.2050  loss: 49.7546  sup_loss_cls: 0.6325  sup_loss_bbox: 0.5979  sup_loss_iou: 1.1840  sup_d0.loss_cls: 0.5779  sup_d0.loss_bbox: 0.5554  sup_d0.loss_iou: 1.1944  sup_d1.loss_cls: 0.6103  sup_d1.loss_bbox: 0.5528  sup_d1.loss_iou: 1.1193  sup_d2.loss_cls: 0.6031  sup_d2.loss_bbox: 0.5698  sup_d2.loss_iou: 1.1663  sup_d3.loss_cls: 0.6037  sup_d3.loss_bbox: 0.5655  sup_d3.loss_iou: 1.1103  sup_d4.loss_cls: 0.6233  sup_d4.loss_bbox: 0.6265  sup_d4.loss_iou: 1.1248  mixup_unsup_loss_cls: 0.0337  mixup_unsup_loss_bbox: 0.2400  mixup_unsup_loss_iou: 0.3811  mixup_unsup_d0.loss_cls: 0.0228  mixup_unsup_d0.loss_bbox: 0.2514  mixup_unsup_d0.loss_iou: 0.3738  mixup_unsup_d1.loss_cls: 0.0218  mixup_unsup_d1.loss_bbox: 0.2402  mixup_unsup_d1.loss_iou: 0.3754  mixup_unsup_d2.loss_cls: 0.0324  mixup_unsup_d2.loss_bbox: 0.2512  mixup_unsup_d2.loss_iou: 0.3766  mixup_unsup_d3.loss_cls: 0.0396  mixup_unsup_d3.loss_bbox: 0.2449  mixup_unsup_d3.loss_iou: 0.3759  mixup_unsup_d4.loss_cls: 0.0467  mixup_unsup_d4.loss_bbox: 0.2395  mixup_unsup_d4.loss_iou: 0.3816  mosaic_unsup_loss_cls: 0.1121  mosaic_unsup_loss_bbox: 2.0313  mosaic_unsup_loss_iou: 3.1153  mosaic_unsup_d0.loss_cls: 0.1578  mosaic_unsup_d0.loss_bbox: 2.0847  mosaic_unsup_d0.loss_iou: 3.1146  mosaic_unsup_d1.loss_cls: 0.1279  mosaic_unsup_d1.loss_bbox: 2.0659  mosaic_unsup_d1.loss_iou: 3.1027  mosaic_unsup_d2.loss_cls: 0.1239  mosaic_unsup_d2.loss_bbox: 2.0849  mosaic_unsup_d2.loss_iou: 3.1052  mosaic_unsup_d3.loss_cls: 0.1305  mosaic_unsup_d3.loss_bbox: 2.0566  mosaic_unsup_d3.loss_iou: 3.1064  mosaic_unsup_d4.loss_cls: 0.1358  mosaic_unsup_d4.loss_bbox: 2.0431  mosaic_unsup_d4.loss_iou: 3.1094
2025/06/23 22:58:02 - mmengine - INFO - Iter(train) [  3650/240000]  base_lr: 7.2997e-05 lr: 7.2997e-06  eta: 2 days, 4:33:19  time: 0.7708  data_time: 0.0238  memory: 9819  grad_norm: 965.7194  loss: 52.2403  sup_loss_cls: 0.7795  sup_loss_bbox: 0.7737  sup_loss_iou: 1.3257  sup_d0.loss_cls: 0.7620  sup_d0.loss_bbox: 0.6114  sup_d0.loss_iou: 1.2429  sup_d1.loss_cls: 0.7807  sup_d1.loss_bbox: 0.6047  sup_d1.loss_iou: 1.2771  sup_d2.loss_cls: 0.8123  sup_d2.loss_bbox: 0.6941  sup_d2.loss_iou: 1.2445  sup_d3.loss_cls: 0.8282  sup_d3.loss_bbox: 0.6849  sup_d3.loss_iou: 1.3243  sup_d4.loss_cls: 0.7901  sup_d4.loss_bbox: 0.7332  sup_d4.loss_iou: 1.3099  mixup_unsup_loss_cls: 0.0472  mixup_unsup_loss_bbox: 0.4308  mixup_unsup_loss_iou: 0.7184  mixup_unsup_d0.loss_cls: 0.0325  mixup_unsup_d0.loss_bbox: 0.4135  mixup_unsup_d0.loss_iou: 0.7126  mixup_unsup_d1.loss_cls: 0.0371  mixup_unsup_d1.loss_bbox: 0.4278  mixup_unsup_d1.loss_iou: 0.7241  mixup_unsup_d2.loss_cls: 0.0439  mixup_unsup_d2.loss_bbox: 0.4158  mixup_unsup_d2.loss_iou: 0.7168  mixup_unsup_d3.loss_cls: 0.0489  mixup_unsup_d3.loss_bbox: 0.4273  mixup_unsup_d3.loss_iou: 0.7179  mixup_unsup_d4.loss_cls: 0.0538  mixup_unsup_d4.loss_bbox: 0.4153  mixup_unsup_d4.loss_iou: 0.7141  mosaic_unsup_loss_cls: 0.0410  mosaic_unsup_loss_bbox: 1.9728  mosaic_unsup_loss_iou: 2.7542  mosaic_unsup_d0.loss_cls: 0.0348  mosaic_unsup_d0.loss_bbox: 1.9631  mosaic_unsup_d0.loss_iou: 2.7617  mosaic_unsup_d1.loss_cls: 0.0342  mosaic_unsup_d1.loss_bbox: 1.9583  mosaic_unsup_d1.loss_iou: 2.7636  mosaic_unsup_d2.loss_cls: 0.0397  mosaic_unsup_d2.loss_bbox: 1.9648  mosaic_unsup_d2.loss_iou: 2.7548  mosaic_unsup_d3.loss_cls: 0.0382  mosaic_unsup_d3.loss_bbox: 1.9735  mosaic_unsup_d3.loss_iou: 2.7518  mosaic_unsup_d4.loss_cls: 0.0454  mosaic_unsup_d4.loss_bbox: 1.9485  mosaic_unsup_d4.loss_iou: 2.7629
2025/06/23 22:58:41 - mmengine - INFO - Iter(train) [  3700/240000]  base_lr: 7.3997e-05 lr: 7.3997e-06  eta: 2 days, 4:31:35  time: 0.7805  data_time: 0.0240  memory: 9878  grad_norm: 807.3010  loss: 41.6813  sup_loss_cls: 0.7692  sup_loss_bbox: 0.5775  sup_loss_iou: 1.1106  sup_d0.loss_cls: 0.7593  sup_d0.loss_bbox: 0.5304  sup_d0.loss_iou: 1.1219  sup_d1.loss_cls: 0.7545  sup_d1.loss_bbox: 0.5369  sup_d1.loss_iou: 1.1716  sup_d2.loss_cls: 0.7785  sup_d2.loss_bbox: 0.5624  sup_d2.loss_iou: 1.1167  sup_d3.loss_cls: 0.7662  sup_d3.loss_bbox: 0.5035  sup_d3.loss_iou: 1.0494  sup_d4.loss_cls: 0.7770  sup_d4.loss_bbox: 0.6572  sup_d4.loss_iou: 1.1676  mixup_unsup_loss_cls: 0.1175  mixup_unsup_loss_bbox: 0.2531  mixup_unsup_loss_iou: 0.3735  mixup_unsup_d0.loss_cls: 0.1281  mixup_unsup_d0.loss_bbox: 0.2082  mixup_unsup_d0.loss_iou: 0.3679  mixup_unsup_d1.loss_cls: 0.1143  mixup_unsup_d1.loss_bbox: 0.2112  mixup_unsup_d1.loss_iou: 0.3672  mixup_unsup_d2.loss_cls: 0.1100  mixup_unsup_d2.loss_bbox: 0.2268  mixup_unsup_d2.loss_iou: 0.3661  mixup_unsup_d3.loss_cls: 0.1219  mixup_unsup_d3.loss_bbox: 0.2371  mixup_unsup_d3.loss_iou: 0.3701  mixup_unsup_d4.loss_cls: 0.1235  mixup_unsup_d4.loss_bbox: 0.2126  mixup_unsup_d4.loss_iou: 0.3673  mosaic_unsup_loss_cls: 0.0421  mosaic_unsup_loss_bbox: 1.4486  mosaic_unsup_loss_iou: 2.2942  mosaic_unsup_d0.loss_cls: 0.0402  mosaic_unsup_d0.loss_bbox: 1.4386  mosaic_unsup_d0.loss_iou: 2.2976  mosaic_unsup_d1.loss_cls: 0.0463  mosaic_unsup_d1.loss_bbox: 1.4387  mosaic_unsup_d1.loss_iou: 2.2971  mosaic_unsup_d2.loss_cls: 0.0386  mosaic_unsup_d2.loss_bbox: 1.4455  mosaic_unsup_d2.loss_iou: 2.2967  mosaic_unsup_d3.loss_cls: 0.0404  mosaic_unsup_d3.loss_bbox: 1.4492  mosaic_unsup_d3.loss_iou: 2.2886  mosaic_unsup_d4.loss_cls: 0.0416  mosaic_unsup_d4.loss_bbox: 1.4401  mosaic_unsup_d4.loss_iou: 2.3102
2025/06/23 22:59:22 - mmengine - INFO - Iter(train) [  3750/240000]  base_lr: 7.4997e-05 lr: 7.4997e-06  eta: 2 days, 4:31:03  time: 0.8026  data_time: 0.0242  memory: 9885  grad_norm: 693.0611  loss: 54.4837  sup_loss_cls: 0.6780  sup_loss_bbox: 0.7509  sup_loss_iou: 1.3011  sup_d0.loss_cls: 0.6496  sup_d0.loss_bbox: 0.5934  sup_d0.loss_iou: 1.2278  sup_d1.loss_cls: 0.7111  sup_d1.loss_bbox: 0.6131  sup_d1.loss_iou: 1.1947  sup_d2.loss_cls: 0.7487  sup_d2.loss_bbox: 0.6919  sup_d2.loss_iou: 1.3261  sup_d3.loss_cls: 0.7208  sup_d3.loss_bbox: 0.7060  sup_d3.loss_iou: 1.2877  sup_d4.loss_cls: 0.7124  sup_d4.loss_bbox: 0.7594  sup_d4.loss_iou: 1.2699  mixup_unsup_loss_cls: 0.3257  mixup_unsup_loss_bbox: 0.6255  mixup_unsup_loss_iou: 0.8540  mixup_unsup_d0.loss_cls: 0.3805  mixup_unsup_d0.loss_bbox: 0.6159  mixup_unsup_d0.loss_iou: 0.8843  mixup_unsup_d1.loss_cls: 0.3166  mixup_unsup_d1.loss_bbox: 0.6379  mixup_unsup_d1.loss_iou: 0.8824  mixup_unsup_d2.loss_cls: 0.3010  mixup_unsup_d2.loss_bbox: 0.7441  mixup_unsup_d2.loss_iou: 0.8737  mixup_unsup_d3.loss_cls: 0.2982  mixup_unsup_d3.loss_bbox: 0.6594  mixup_unsup_d3.loss_iou: 0.8596  mixup_unsup_d4.loss_cls: 0.3163  mixup_unsup_d4.loss_bbox: 0.6001  mixup_unsup_d4.loss_iou: 0.8548  mosaic_unsup_loss_cls: 0.0409  mosaic_unsup_loss_bbox: 1.7571  mosaic_unsup_loss_iou: 2.7764  mosaic_unsup_d0.loss_cls: 0.0555  mosaic_unsup_d0.loss_bbox: 1.7644  mosaic_unsup_d0.loss_iou: 2.7822  mosaic_unsup_d1.loss_cls: 0.0394  mosaic_unsup_d1.loss_bbox: 1.7671  mosaic_unsup_d1.loss_iou: 2.7810  mosaic_unsup_d2.loss_cls: 0.0444  mosaic_unsup_d2.loss_bbox: 1.7475  mosaic_unsup_d2.loss_iou: 2.7743  mosaic_unsup_d3.loss_cls: 0.0369  mosaic_unsup_d3.loss_bbox: 1.7612  mosaic_unsup_d3.loss_iou: 2.7800  mosaic_unsup_d4.loss_cls: 0.0378  mosaic_unsup_d4.loss_bbox: 1.7727  mosaic_unsup_d4.loss_iou: 2.7925
2025/06/23 23:00:01 - mmengine - INFO - Iter(train) [  3800/240000]  base_lr: 7.5998e-05 lr: 7.5998e-06  eta: 2 days, 4:29:30  time: 0.7834  data_time: 0.0256  memory: 9881  grad_norm: 541.9462  loss: 46.4783  sup_loss_cls: 0.5979  sup_loss_bbox: 0.6006  sup_loss_iou: 1.0761  sup_d0.loss_cls: 0.5586  sup_d0.loss_bbox: 0.5038  sup_d0.loss_iou: 1.0430  sup_d1.loss_cls: 0.5550  sup_d1.loss_bbox: 0.5846  sup_d1.loss_iou: 1.1542  sup_d2.loss_cls: 0.5605  sup_d2.loss_bbox: 0.6531  sup_d2.loss_iou: 1.0562  sup_d3.loss_cls: 0.6064  sup_d3.loss_bbox: 0.7395  sup_d3.loss_iou: 1.2071  sup_d4.loss_cls: 0.5867  sup_d4.loss_bbox: 0.6547  sup_d4.loss_iou: 1.1475  mixup_unsup_loss_cls: 0.0717  mixup_unsup_loss_bbox: 0.5441  mixup_unsup_loss_iou: 0.8009  mixup_unsup_d0.loss_cls: 0.0878  mixup_unsup_d0.loss_bbox: 0.5603  mixup_unsup_d0.loss_iou: 0.8026  mixup_unsup_d1.loss_cls: 0.0818  mixup_unsup_d1.loss_bbox: 0.5550  mixup_unsup_d1.loss_iou: 0.8059  mixup_unsup_d2.loss_cls: 0.0787  mixup_unsup_d2.loss_bbox: 0.5434  mixup_unsup_d2.loss_iou: 0.8062  mixup_unsup_d3.loss_cls: 0.0797  mixup_unsup_d3.loss_bbox: 0.5362  mixup_unsup_d3.loss_iou: 0.7982  mixup_unsup_d4.loss_cls: 0.0779  mixup_unsup_d4.loss_bbox: 0.5391  mixup_unsup_d4.loss_iou: 0.7977  mosaic_unsup_loss_cls: 0.0179  mosaic_unsup_loss_bbox: 1.5766  mosaic_unsup_loss_iou: 2.4007  mosaic_unsup_d0.loss_cls: 0.0183  mosaic_unsup_d0.loss_bbox: 1.5829  mosaic_unsup_d0.loss_iou: 2.4173  mosaic_unsup_d1.loss_cls: 0.0173  mosaic_unsup_d1.loss_bbox: 1.5733  mosaic_unsup_d1.loss_iou: 2.4107  mosaic_unsup_d2.loss_cls: 0.0176  mosaic_unsup_d2.loss_bbox: 1.5827  mosaic_unsup_d2.loss_iou: 2.4076  mosaic_unsup_d3.loss_cls: 0.0169  mosaic_unsup_d3.loss_bbox: 1.5824  mosaic_unsup_d3.loss_iou: 2.4082  mosaic_unsup_d4.loss_cls: 0.0163  mosaic_unsup_d4.loss_bbox: 1.5690  mosaic_unsup_d4.loss_iou: 2.4095
2025/06/23 23:00:40 - mmengine - INFO - Iter(train) [  3850/240000]  base_lr: 7.6998e-05 lr: 7.6998e-06  eta: 2 days, 4:27:58  time: 0.7832  data_time: 0.0241  memory: 9885  grad_norm: 489.4494  loss: 50.8501  sup_loss_cls: 0.5684  sup_loss_bbox: 0.4963  sup_loss_iou: 1.0909  sup_d0.loss_cls: 0.5309  sup_d0.loss_bbox: 0.5706  sup_d0.loss_iou: 1.1533  sup_d1.loss_cls: 0.5360  sup_d1.loss_bbox: 0.5325  sup_d1.loss_iou: 1.1222  sup_d2.loss_cls: 0.5573  sup_d2.loss_bbox: 0.5410  sup_d2.loss_iou: 1.0769  sup_d3.loss_cls: 0.5726  sup_d3.loss_bbox: 0.6711  sup_d3.loss_iou: 1.2215  sup_d4.loss_cls: 0.6097  sup_d4.loss_bbox: 0.6037  sup_d4.loss_iou: 1.2100  mixup_unsup_loss_cls: 0.0666  mixup_unsup_loss_bbox: 0.4364  mixup_unsup_loss_iou: 0.6566  mixup_unsup_d0.loss_cls: 0.0827  mixup_unsup_d0.loss_bbox: 0.4578  mixup_unsup_d0.loss_iou: 0.6627  mixup_unsup_d1.loss_cls: 0.0844  mixup_unsup_d1.loss_bbox: 0.4368  mixup_unsup_d1.loss_iou: 0.6596  mixup_unsup_d2.loss_cls: 0.0747  mixup_unsup_d2.loss_bbox: 0.4285  mixup_unsup_d2.loss_iou: 0.6569  mixup_unsup_d3.loss_cls: 0.0692  mixup_unsup_d3.loss_bbox: 0.4349  mixup_unsup_d3.loss_iou: 0.6462  mixup_unsup_d4.loss_cls: 0.0710  mixup_unsup_d4.loss_bbox: 0.4374  mixup_unsup_d4.loss_iou: 0.6565  mosaic_unsup_loss_cls: 0.0752  mosaic_unsup_loss_bbox: 2.1094  mosaic_unsup_loss_iou: 2.8391  mosaic_unsup_d0.loss_cls: 0.0884  mosaic_unsup_d0.loss_bbox: 2.1132  mosaic_unsup_d0.loss_iou: 2.8516  mosaic_unsup_d1.loss_cls: 0.0875  mosaic_unsup_d1.loss_bbox: 2.0949  mosaic_unsup_d1.loss_iou: 2.8543  mosaic_unsup_d2.loss_cls: 0.0765  mosaic_unsup_d2.loss_bbox: 2.1024  mosaic_unsup_d2.loss_iou: 2.8477  mosaic_unsup_d3.loss_cls: 0.0708  mosaic_unsup_d3.loss_bbox: 2.1041  mosaic_unsup_d3.loss_iou: 2.8327  mosaic_unsup_d4.loss_cls: 0.0744  mosaic_unsup_d4.loss_bbox: 2.1060  mosaic_unsup_d4.loss_iou: 2.8380
2025/06/23 23:01:19 - mmengine - INFO - Iter(train) [  3900/240000]  base_lr: 7.7998e-05 lr: 7.7998e-06  eta: 2 days, 4:26:08  time: 0.7766  data_time: 0.0243  memory: 9703  grad_norm: 499.2123  loss: 51.5288  sup_loss_cls: 0.6426  sup_loss_bbox: 0.6995  sup_loss_iou: 1.2518  sup_d0.loss_cls: 0.5893  sup_d0.loss_bbox: 0.5241  sup_d0.loss_iou: 1.1593  sup_d1.loss_cls: 0.6154  sup_d1.loss_bbox: 0.4999  sup_d1.loss_iou: 1.1267  sup_d2.loss_cls: 0.6416  sup_d2.loss_bbox: 0.5975  sup_d2.loss_iou: 1.1401  sup_d3.loss_cls: 0.6608  sup_d3.loss_bbox: 0.6728  sup_d3.loss_iou: 1.2187  sup_d4.loss_cls: 0.6572  sup_d4.loss_bbox: 0.7123  sup_d4.loss_iou: 1.2532  mixup_unsup_loss_cls: 0.0061  mixup_unsup_loss_bbox: 0.5739  mixup_unsup_loss_iou: 0.9075  mixup_unsup_d0.loss_cls: 0.0044  mixup_unsup_d0.loss_bbox: 0.5729  mixup_unsup_d0.loss_iou: 0.9076  mixup_unsup_d1.loss_cls: 0.0046  mixup_unsup_d1.loss_bbox: 0.5790  mixup_unsup_d1.loss_iou: 0.9080  mixup_unsup_d2.loss_cls: 0.0057  mixup_unsup_d2.loss_bbox: 0.5860  mixup_unsup_d2.loss_iou: 0.9098  mixup_unsup_d3.loss_cls: 0.0056  mixup_unsup_d3.loss_bbox: 0.5764  mixup_unsup_d3.loss_iou: 0.9077  mixup_unsup_d4.loss_cls: 0.0052  mixup_unsup_d4.loss_bbox: 0.5722  mixup_unsup_d4.loss_iou: 0.9070  mosaic_unsup_loss_cls: 0.0171  mosaic_unsup_loss_bbox: 1.9386  mosaic_unsup_loss_iou: 2.6964  mosaic_unsup_d0.loss_cls: 0.0125  mosaic_unsup_d0.loss_bbox: 1.9392  mosaic_unsup_d0.loss_iou: 2.7064  mosaic_unsup_d1.loss_cls: 0.0133  mosaic_unsup_d1.loss_bbox: 1.9290  mosaic_unsup_d1.loss_iou: 2.7101  mosaic_unsup_d2.loss_cls: 0.0162  mosaic_unsup_d2.loss_bbox: 1.9291  mosaic_unsup_d2.loss_iou: 2.7053  mosaic_unsup_d3.loss_cls: 0.0161  mosaic_unsup_d3.loss_bbox: 1.9228  mosaic_unsup_d3.loss_iou: 2.7167  mosaic_unsup_d4.loss_cls: 0.0150  mosaic_unsup_d4.loss_bbox: 1.9266  mosaic_unsup_d4.loss_iou: 2.7161
2025/06/23 23:01:57 - mmengine - INFO - Iter(train) [  3950/240000]  base_lr: 7.8998e-05 lr: 7.8998e-06  eta: 2 days, 4:23:49  time: 0.7663  data_time: 0.0237  memory: 9102  grad_norm: 449.0312  loss: 43.7791  sup_loss_cls: 0.5331  sup_loss_bbox: 0.6334  sup_loss_iou: 1.1608  sup_d0.loss_cls: 0.5385  sup_d0.loss_bbox: 0.5618  sup_d0.loss_iou: 1.1834  sup_d1.loss_cls: 0.5304  sup_d1.loss_bbox: 0.5440  sup_d1.loss_iou: 1.1889  sup_d2.loss_cls: 0.5374  sup_d2.loss_bbox: 0.5242  sup_d2.loss_iou: 1.0678  sup_d3.loss_cls: 0.5406  sup_d3.loss_bbox: 0.5307  sup_d3.loss_iou: 1.0647  sup_d4.loss_cls: 0.5142  sup_d4.loss_bbox: 0.6015  sup_d4.loss_iou: 1.1269  mixup_unsup_loss_cls: 0.0410  mixup_unsup_loss_bbox: 0.0657  mixup_unsup_loss_iou: 0.1275  mixup_unsup_d0.loss_cls: 0.0388  mixup_unsup_d0.loss_bbox: 0.0709  mixup_unsup_d0.loss_iou: 0.1283  mixup_unsup_d1.loss_cls: 0.0383  mixup_unsup_d1.loss_bbox: 0.0715  mixup_unsup_d1.loss_iou: 0.1270  mixup_unsup_d2.loss_cls: 0.0405  mixup_unsup_d2.loss_bbox: 0.0699  mixup_unsup_d2.loss_iou: 0.1258  mixup_unsup_d3.loss_cls: 0.0424  mixup_unsup_d3.loss_bbox: 0.0657  mixup_unsup_d3.loss_iou: 0.1242  mixup_unsup_d4.loss_cls: 0.0438  mixup_unsup_d4.loss_bbox: 0.0699  mixup_unsup_d4.loss_iou: 0.1237  mosaic_unsup_loss_cls: 0.0795  mosaic_unsup_loss_bbox: 1.9180  mosaic_unsup_loss_iou: 2.8249  mosaic_unsup_d0.loss_cls: 0.0847  mosaic_unsup_d0.loss_bbox: 1.9328  mosaic_unsup_d0.loss_iou: 2.8245  mosaic_unsup_d1.loss_cls: 0.0798  mosaic_unsup_d1.loss_bbox: 1.9187  mosaic_unsup_d1.loss_iou: 2.8325  mosaic_unsup_d2.loss_cls: 0.0825  mosaic_unsup_d2.loss_bbox: 1.9103  mosaic_unsup_d2.loss_iou: 2.8250  mosaic_unsup_d3.loss_cls: 0.0843  mosaic_unsup_d3.loss_bbox: 1.9105  mosaic_unsup_d3.loss_iou: 2.8430  mosaic_unsup_d4.loss_cls: 0.0823  mosaic_unsup_d4.loss_bbox: 1.9098  mosaic_unsup_d4.loss_iou: 2.8387
2025/06/23 23:02:35 - mmengine - INFO - Exp name: Newdatamixpl05_detr_r50_100_sonar-s1-p10_20250623_220902
2025/06/23 23:02:35 - mmengine - INFO - Iter(train) [  4000/240000]  base_lr: 7.9998e-05 lr: 7.9998e-06  eta: 2 days, 4:21:38  time: 0.7684  data_time: 0.0237  memory: 9627  grad_norm: 661.3432  loss: 44.6528  sup_loss_cls: 0.6758  sup_loss_bbox: 0.7754  sup_loss_iou: 1.4278  sup_d0.loss_cls: 0.6811  sup_d0.loss_bbox: 0.5708  sup_d0.loss_iou: 1.2315  sup_d1.loss_cls: 0.6921  sup_d1.loss_bbox: 0.6257  sup_d1.loss_iou: 1.2776  sup_d2.loss_cls: 0.6972  sup_d2.loss_bbox: 0.6413  sup_d2.loss_iou: 1.2577  sup_d3.loss_cls: 0.6640  sup_d3.loss_bbox: 0.6909  sup_d3.loss_iou: 1.3023  sup_d4.loss_cls: 0.6768  sup_d4.loss_bbox: 0.7277  sup_d4.loss_iou: 1.3508  mixup_unsup_loss_cls: 0.0356  mixup_unsup_loss_bbox: 0.0482  mixup_unsup_loss_iou: 0.1142  mixup_unsup_d0.loss_cls: 0.0396  mixup_unsup_d0.loss_bbox: 0.0531  mixup_unsup_d0.loss_iou: 0.1145  mixup_unsup_d1.loss_cls: 0.0359  mixup_unsup_d1.loss_bbox: 0.0488  mixup_unsup_d1.loss_iou: 0.1068  mixup_unsup_d2.loss_cls: 0.0335  mixup_unsup_d2.loss_bbox: 0.0487  mixup_unsup_d2.loss_iou: 0.1092  mixup_unsup_d3.loss_cls: 0.0337  mixup_unsup_d3.loss_bbox: 0.0465  mixup_unsup_d3.loss_iou: 0.1077  mixup_unsup_d4.loss_cls: 0.0361  mixup_unsup_d4.loss_bbox: 0.0478  mixup_unsup_d4.loss_iou: 0.1119  mosaic_unsup_loss_cls: 0.0335  mosaic_unsup_loss_bbox: 1.8240  mosaic_unsup_loss_iou: 2.7240  mosaic_unsup_d0.loss_cls: 0.0390  mosaic_unsup_d0.loss_bbox: 1.8355  mosaic_unsup_d0.loss_iou: 2.7221  mosaic_unsup_d1.loss_cls: 0.0341  mosaic_unsup_d1.loss_bbox: 1.8365  mosaic_unsup_d1.loss_iou: 2.7151  mosaic_unsup_d2.loss_cls: 0.0355  mosaic_unsup_d2.loss_bbox: 1.8354  mosaic_unsup_d2.loss_iou: 2.7194  mosaic_unsup_d3.loss_cls: 0.0286  mosaic_unsup_d3.loss_bbox: 1.8308  mosaic_unsup_d3.loss_iou: 2.7195  mosaic_unsup_d4.loss_cls: 0.0288  mosaic_unsup_d4.loss_bbox: 1.8264  mosaic_unsup_d4.loss_iou: 2.7261
2025/06/23 23:02:38 - mmengine - INFO - Iter(val) [ 50/785]    eta: 0:00:38  time: 0.0526  data_time: 0.0087  memory: 1031  
2025/06/23 23:02:40 - mmengine - INFO - Iter(val) [100/785]    eta: 0:00:32  time: 0.0429  data_time: 0.0022  memory: 1031  
2025/06/23 23:02:42 - mmengine - INFO - Iter(val) [150/785]    eta: 0:00:29  time: 0.0418  data_time: 0.0021  memory: 1031  
2025/06/23 23:02:45 - mmengine - INFO - Iter(val) [200/785]    eta: 0:00:27  time: 0.0488  data_time: 0.0029  memory: 1031  
2025/06/23 23:02:47 - mmengine - INFO - Iter(val) [250/785]    eta: 0:00:24  time: 0.0454  data_time: 0.0027  memory: 1031  
2025/06/23 23:02:49 - mmengine - INFO - Iter(val) [300/785]    eta: 0:00:22  time: 0.0483  data_time: 0.0027  memory: 1031  
2025/06/23 23:02:52 - mmengine - INFO - Iter(val) [350/785]    eta: 0:00:20  time: 0.0493  data_time: 0.0030  memory: 1031  
2025/06/23 23:02:54 - mmengine - INFO - Iter(val) [400/785]    eta: 0:00:18  time: 0.0450  data_time: 0.0024  memory: 1031  
2025/06/23 23:02:56 - mmengine - INFO - Iter(val) [450/785]    eta: 0:00:15  time: 0.0410  data_time: 0.0021  memory: 1031  
2025/06/23 23:02:58 - mmengine - INFO - Iter(val) [500/785]    eta: 0:00:13  time: 0.0422  data_time: 0.0021  memory: 1031  
2025/06/23 23:03:01 - mmengine - INFO - Iter(val) [550/785]    eta: 0:00:10  time: 0.0452  data_time: 0.0023  memory: 1031  
2025/06/23 23:03:03 - mmengine - INFO - Iter(val) [600/785]    eta: 0:00:08  time: 0.0451  data_time: 0.0023  memory: 1031  
2025/06/23 23:03:05 - mmengine - INFO - Iter(val) [650/785]    eta: 0:00:06  time: 0.0448  data_time: 0.0023  memory: 1031  
2025/06/23 23:03:07 - mmengine - INFO - Iter(val) [700/785]    eta: 0:00:03  time: 0.0409  data_time: 0.0020  memory: 1031  
2025/06/23 23:03:09 - mmengine - INFO - Iter(val) [750/785]    eta: 0:00:01  time: 0.0453  data_time: 0.0024  memory: 1031  
2025/06/23 23:03:13 - mmengine - INFO - Evaluating bbox...
2025/06/23 23:03:17 - mmengine - INFO - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 0.000 0.000
2025/06/23 23:03:19 - mmengine - INFO - Iter(val) [ 50/785]    eta: 0:10:38  time: 0.1564  data_time: 0.1130  memory: 1031  
2025/06/23 23:03:21 - mmengine - INFO - Iter(val) [100/785]    eta: 0:05:12  time: 0.0418  data_time: 0.0019  memory: 1031  
2025/06/23 23:03:23 - mmengine - INFO - Iter(val) [150/785]    eta: 0:03:22  time: 0.0436  data_time: 0.0021  memory: 1031  
2025/06/23 23:03:26 - mmengine - INFO - Iter(val) [200/785]    eta: 0:02:26  time: 0.0475  data_time: 0.0024  memory: 1031  
2025/06/23 23:03:28 - mmengine - INFO - Iter(val) [250/785]    eta: 0:01:52  time: 0.0469  data_time: 0.0024  memory: 1031  
2025/06/23 23:03:30 - mmengine - INFO - Iter(val) [300/785]    eta: 0:01:28  time: 0.0438  data_time: 0.0021  memory: 1031  
2025/06/23 23:03:32 - mmengine - INFO - Iter(val) [350/785]    eta: 0:01:10  time: 0.0442  data_time: 0.0021  memory: 1031  
2025/06/23 23:03:35 - mmengine - INFO - Iter(val) [400/785]    eta: 0:00:56  time: 0.0448  data_time: 0.0025  memory: 1031  
2025/06/23 23:03:37 - mmengine - INFO - Iter(val) [450/785]    eta: 0:00:45  time: 0.0475  data_time: 0.0041  memory: 1031  
2025/06/23 23:03:39 - mmengine - INFO - Iter(val) [500/785]    eta: 0:00:36  time: 0.0481  data_time: 0.0033  memory: 1031  
2025/06/23 23:03:42 - mmengine - INFO - Iter(val) [550/785]    eta: 0:00:28  time: 0.0439  data_time: 0.0022  memory: 1031  
2025/06/23 23:03:44 - mmengine - INFO - Iter(val) [600/785]    eta: 0:00:21  time: 0.0493  data_time: 0.0026  memory: 1031  
2025/06/23 23:03:47 - mmengine - INFO - Iter(val) [650/785]    eta: 0:00:14  time: 0.0470  data_time: 0.0023  memory: 1031  
2025/06/23 23:03:49 - mmengine - INFO - Iter(val) [700/785]    eta: 0:00:08  time: 0.0419  data_time: 0.0019  memory: 1031  
2025/06/23 23:03:51 - mmengine - INFO - Iter(val) [750/785]    eta: 0:00:03  time: 0.0427  data_time: 0.0020  memory: 1031  
2025/06/23 23:03:54 - mmengine - INFO - Evaluating bbox...
2025/06/23 23:03:57 - mmengine - INFO - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 0.000 0.000
2025/06/23 23:03:57 - mmengine - INFO - Iter(val) [785/785]    teacher/coco/bbox_mAP: 0.0000  teacher/coco/bbox_mAP_50: 0.0000  teacher/coco/bbox_mAP_75: 0.0000  teacher/coco/bbox_mAP_s: -1.0000  teacher/coco/bbox_mAP_m: 0.0000  teacher/coco/bbox_mAP_l: 0.0000  student/coco/bbox_mAP: 0.0000  student/coco/bbox_mAP_50: 0.0000  student/coco/bbox_mAP_75: 0.0000  student/coco/bbox_mAP_s: -1.0000  student/coco/bbox_mAP_m: 0.0000  student/coco/bbox_mAP_l: 0.0000  data_time: 0.0094  time: 0.0523
2025/06/23 23:04:36 - mmengine - INFO - Iter(train) [  4050/240000]  base_lr: 8.0998e-05 lr: 8.0998e-06  eta: 2 days, 4:24:28  time: 0.8709  data_time: 0.1229  memory: 9885  grad_norm: 3547.9740  loss: 49.5473  sup_loss_cls: 0.6188  sup_loss_bbox: 0.7066  sup_loss_iou: 1.2897  sup_d0.loss_cls: 0.5771  sup_d0.loss_bbox: 0.5190  sup_d0.loss_iou: 1.1623  sup_d1.loss_cls: 0.6157  sup_d1.loss_bbox: 0.6873  sup_d1.loss_iou: 1.2818  sup_d2.loss_cls: 0.6619  sup_d2.loss_bbox: 0.6569  sup_d2.loss_iou: 1.3287  sup_d3.loss_cls: 0.6644  sup_d3.loss_bbox: 0.6133  sup_d3.loss_iou: 1.2457  sup_d4.loss_cls: 0.6130  sup_d4.loss_bbox: 0.6101  sup_d4.loss_iou: 1.2333  mixup_unsup_loss_cls: 0.1137  mixup_unsup_loss_bbox: 0.3787  mixup_unsup_loss_iou: 0.7571  mixup_unsup_d0.loss_cls: 0.1544  mixup_unsup_d0.loss_bbox: 0.3750  mixup_unsup_d0.loss_iou: 0.7520  mixup_unsup_d1.loss_cls: 0.1469  mixup_unsup_d1.loss_bbox: 0.3860  mixup_unsup_d1.loss_iou: 0.7578  mixup_unsup_d2.loss_cls: 0.1271  mixup_unsup_d2.loss_bbox: 0.4165  mixup_unsup_d2.loss_iou: 0.7633  mixup_unsup_d3.loss_cls: 0.1137  mixup_unsup_d3.loss_bbox: 0.4048  mixup_unsup_d3.loss_iou: 0.7544  mixup_unsup_d4.loss_cls: 0.1292  mixup_unsup_d4.loss_bbox: 0.3792  mixup_unsup_d4.loss_iou: 0.7508  mosaic_unsup_loss_cls: 0.0215  mosaic_unsup_loss_bbox: 1.7268  mosaic_unsup_loss_iou: 2.7238  mosaic_unsup_d0.loss_cls: 0.0209  mosaic_unsup_d0.loss_bbox: 1.7252  mosaic_unsup_d0.loss_iou: 2.7312  mosaic_unsup_d1.loss_cls: 0.0172  mosaic_unsup_d1.loss_bbox: 1.7168  mosaic_unsup_d1.loss_iou: 2.7182  mosaic_unsup_d2.loss_cls: 0.0197  mosaic_unsup_d2.loss_bbox: 1.7228  mosaic_unsup_d2.loss_iou: 2.7159  mosaic_unsup_d3.loss_cls: 0.0176  mosaic_unsup_d3.loss_bbox: 1.7271  mosaic_unsup_d3.loss_iou: 2.7218  mosaic_unsup_d4.loss_cls: 0.0201  mosaic_unsup_d4.loss_bbox: 1.7285  mosaic_unsup_d4.loss_iou: 2.7262
2025/06/23 23:05:13 - mmengine - INFO - Iter(train) [  4100/240000]  base_lr: 8.1998e-05 lr: 8.1998e-06  eta: 2 days, 4:21:19  time: 0.7478  data_time: 0.0239  memory: 9885  grad_norm: 468.3350  loss: 41.5713  sup_loss_cls: 0.6034  sup_loss_bbox: 0.7110  sup_loss_iou: 1.2162  sup_d0.loss_cls: 0.5644  sup_d0.loss_bbox: 0.5408  sup_d0.loss_iou: 1.1518  sup_d1.loss_cls: 0.5717  sup_d1.loss_bbox: 0.5635  sup_d1.loss_iou: 1.1478  sup_d2.loss_cls: 0.6182  sup_d2.loss_bbox: 0.5126  sup_d2.loss_iou: 1.0780  sup_d3.loss_cls: 0.6106  sup_d3.loss_bbox: 0.5532  sup_d3.loss_iou: 1.2138  sup_d4.loss_cls: 0.6171  sup_d4.loss_bbox: 0.6742  sup_d4.loss_iou: 1.2706  mixup_unsup_loss_cls: 0.0015  mixup_unsup_loss_bbox: 0.2120  mixup_unsup_loss_iou: 0.2881  mixup_unsup_d0.loss_cls: 0.0013  mixup_unsup_d0.loss_bbox: 0.2138  mixup_unsup_d0.loss_iou: 0.2888  mixup_unsup_d1.loss_cls: 0.0012  mixup_unsup_d1.loss_bbox: 0.2190  mixup_unsup_d1.loss_iou: 0.2891  mixup_unsup_d2.loss_cls: 0.0017  mixup_unsup_d2.loss_bbox: 0.2194  mixup_unsup_d2.loss_iou: 0.2893  mixup_unsup_d3.loss_cls: 0.0015  mixup_unsup_d3.loss_bbox: 0.2157  mixup_unsup_d3.loss_iou: 0.2886  mixup_unsup_d4.loss_cls: 0.0015  mixup_unsup_d4.loss_bbox: 0.2172  mixup_unsup_d4.loss_iou: 0.2888  mosaic_unsup_loss_cls: 0.0792  mosaic_unsup_loss_bbox: 1.6420  mosaic_unsup_loss_iou: 2.3933  mosaic_unsup_d0.loss_cls: 0.0378  mosaic_unsup_d0.loss_bbox: 1.6079  mosaic_unsup_d0.loss_iou: 2.3980  mosaic_unsup_d1.loss_cls: 0.0340  mosaic_unsup_d1.loss_bbox: 1.5886  mosaic_unsup_d1.loss_iou: 2.3874  mosaic_unsup_d2.loss_cls: 0.0554  mosaic_unsup_d2.loss_bbox: 1.5955  mosaic_unsup_d2.loss_iou: 2.3746  mosaic_unsup_d3.loss_cls: 0.0530  mosaic_unsup_d3.loss_bbox: 1.5945  mosaic_unsup_d3.loss_iou: 2.3913  mosaic_unsup_d4.loss_cls: 0.0638  mosaic_unsup_d4.loss_bbox: 1.6137  mosaic_unsup_d4.loss_iou: 2.4036
2025/06/23 23:05:52 - mmengine - INFO - Iter(train) [  4150/240000]  base_lr: 8.2998e-05 lr: 8.2998e-06  eta: 2 days, 4:19:22  time: 0.7717  data_time: 0.0244  memory: 9887  grad_norm: 580.7148  loss: 50.2945  sup_loss_cls: 0.6229  sup_loss_bbox: 0.5304  sup_loss_iou: 1.0270  sup_d0.loss_cls: 0.6241  sup_d0.loss_bbox: 0.5574  sup_d0.loss_iou: 1.2299  sup_d1.loss_cls: 0.6252  sup_d1.loss_bbox: 0.5273  sup_d1.loss_iou: 1.1318  sup_d2.loss_cls: 0.6695  sup_d2.loss_bbox: 0.5209  sup_d2.loss_iou: 0.9917  sup_d3.loss_cls: 0.6356  sup_d3.loss_bbox: 0.5016  sup_d3.loss_iou: 1.0357  sup_d4.loss_cls: 0.6212  sup_d4.loss_bbox: 0.5768  sup_d4.loss_iou: 1.0529  mixup_unsup_loss_cls: 0.0342  mixup_unsup_loss_bbox: 0.4886  mixup_unsup_loss_iou: 0.9807  mixup_unsup_d0.loss_cls: 0.0334  mixup_unsup_d0.loss_bbox: 0.5082  mixup_unsup_d0.loss_iou: 0.9868  mixup_unsup_d1.loss_cls: 0.0315  mixup_unsup_d1.loss_bbox: 0.4954  mixup_unsup_d1.loss_iou: 0.9772  mixup_unsup_d2.loss_cls: 0.0282  mixup_unsup_d2.loss_bbox: 0.5014  mixup_unsup_d2.loss_iou: 0.9801  mixup_unsup_d3.loss_cls: 0.0295  mixup_unsup_d3.loss_bbox: 0.4859  mixup_unsup_d3.loss_iou: 0.9720  mixup_unsup_d4.loss_cls: 0.0341  mixup_unsup_d4.loss_bbox: 0.4831  mixup_unsup_d4.loss_iou: 0.9762  mosaic_unsup_loss_cls: 0.0061  mosaic_unsup_loss_bbox: 1.8984  mosaic_unsup_loss_iou: 2.7187  mosaic_unsup_d0.loss_cls: 0.0097  mosaic_unsup_d0.loss_bbox: 1.8863  mosaic_unsup_d0.loss_iou: 2.7257  mosaic_unsup_d1.loss_cls: 0.0074  mosaic_unsup_d1.loss_bbox: 1.9281  mosaic_unsup_d1.loss_iou: 2.7040  mosaic_unsup_d2.loss_cls: 0.0070  mosaic_unsup_d2.loss_bbox: 1.9230  mosaic_unsup_d2.loss_iou: 2.7078  mosaic_unsup_d3.loss_cls: 0.0086  mosaic_unsup_d3.loss_bbox: 1.9165  mosaic_unsup_d3.loss_iou: 2.7130  mosaic_unsup_d4.loss_cls: 0.0072  mosaic_unsup_d4.loss_bbox: 1.9002  mosaic_unsup_d4.loss_iou: 2.7186
2025/06/23 23:06:32 - mmengine - INFO - Iter(train) [  4200/240000]  base_lr: 8.3998e-05 lr: 8.3998e-06  eta: 2 days, 4:18:39  time: 0.7976  data_time: 0.0242  memory: 9676  grad_norm: 1078.0747  loss: 63.6579  sup_loss_cls: 0.9260  sup_loss_bbox: 0.9547  sup_loss_iou: 1.4870  sup_d0.loss_cls: 0.9243  sup_d0.loss_bbox: 0.8608  sup_d0.loss_iou: 1.5362  sup_d1.loss_cls: 0.9055  sup_d1.loss_bbox: 0.7789  sup_d1.loss_iou: 1.4171  sup_d2.loss_cls: 0.9423  sup_d2.loss_bbox: 0.8296  sup_d2.loss_iou: 1.3995  sup_d3.loss_cls: 0.9061  sup_d3.loss_bbox: 0.8241  sup_d3.loss_iou: 1.2731  sup_d4.loss_cls: 0.9164  sup_d4.loss_bbox: 0.9012  sup_d4.loss_iou: 1.4256  mixup_unsup_loss_cls: 0.1919  mixup_unsup_loss_bbox: 0.7915  mixup_unsup_loss_iou: 1.3333  mixup_unsup_d0.loss_cls: 0.2009  mixup_unsup_d0.loss_bbox: 0.8095  mixup_unsup_d0.loss_iou: 1.3474  mixup_unsup_d1.loss_cls: 0.2059  mixup_unsup_d1.loss_bbox: 0.8196  mixup_unsup_d1.loss_iou: 1.3424  mixup_unsup_d2.loss_cls: 0.1965  mixup_unsup_d2.loss_bbox: 0.8540  mixup_unsup_d2.loss_iou: 1.3267  mixup_unsup_d3.loss_cls: 0.2039  mixup_unsup_d3.loss_bbox: 0.7832  mixup_unsup_d3.loss_iou: 1.3211  mixup_unsup_d4.loss_cls: 0.2200  mixup_unsup_d4.loss_bbox: 0.7338  mixup_unsup_d4.loss_iou: 1.3128  mosaic_unsup_loss_cls: 0.0666  mosaic_unsup_loss_bbox: 2.0381  mosaic_unsup_loss_iou: 2.9575  mosaic_unsup_d0.loss_cls: 0.0706  mosaic_unsup_d0.loss_bbox: 2.0133  mosaic_unsup_d0.loss_iou: 2.9695  mosaic_unsup_d1.loss_cls: 0.0789  mosaic_unsup_d1.loss_bbox: 2.0462  mosaic_unsup_d1.loss_iou: 2.9562  mosaic_unsup_d2.loss_cls: 0.0787  mosaic_unsup_d2.loss_bbox: 2.0549  mosaic_unsup_d2.loss_iou: 2.9608  mosaic_unsup_d3.loss_cls: 0.0845  mosaic_unsup_d3.loss_bbox: 2.0442  mosaic_unsup_d3.loss_iou: 2.9582  mosaic_unsup_d4.loss_cls: 0.0753  mosaic_unsup_d4.loss_bbox: 2.0319  mosaic_unsup_d4.loss_iou: 2.9698
2025/06/23 23:07:10 - mmengine - INFO - Iter(train) [  4250/240000]  base_lr: 8.4998e-05 lr: 8.4998e-06  eta: 2 days, 4:16:26  time: 0.7650  data_time: 0.0250  memory: 9702  grad_norm: 478.5613  loss: 36.8533  sup_loss_cls: 0.5318  sup_loss_bbox: 0.5872  sup_loss_iou: 1.2185  sup_d0.loss_cls: 0.5137  sup_d0.loss_bbox: 0.4646  sup_d0.loss_iou: 1.0834  sup_d1.loss_cls: 0.5283  sup_d1.loss_bbox: 0.5419  sup_d1.loss_iou: 1.2090  sup_d2.loss_cls: 0.5786  sup_d2.loss_bbox: 0.6576  sup_d2.loss_iou: 1.1959  sup_d3.loss_cls: 0.5502  sup_d3.loss_bbox: 0.6207  sup_d3.loss_iou: 1.2636  sup_d4.loss_cls: 0.5245  sup_d4.loss_bbox: 0.6697  sup_d4.loss_iou: 1.2543  mixup_unsup_loss_cls: 0.0855  mixup_unsup_loss_bbox: 0.1163  mixup_unsup_loss_iou: 0.2182  mixup_unsup_d0.loss_cls: 0.0883  mixup_unsup_d0.loss_bbox: 0.1170  mixup_unsup_d0.loss_iou: 0.2252  mixup_unsup_d1.loss_cls: 0.0777  mixup_unsup_d1.loss_bbox: 0.1084  mixup_unsup_d1.loss_iou: 0.2166  mixup_unsup_d2.loss_cls: 0.0698  mixup_unsup_d2.loss_bbox: 0.1270  mixup_unsup_d2.loss_iou: 0.2212  mixup_unsup_d3.loss_cls: 0.0723  mixup_unsup_d3.loss_bbox: 0.1065  mixup_unsup_d3.loss_iou: 0.2181  mixup_unsup_d4.loss_cls: 0.0797  mixup_unsup_d4.loss_bbox: 0.1077  mixup_unsup_d4.loss_iou: 0.2227  mosaic_unsup_loss_cls: 0.1479  mosaic_unsup_loss_bbox: 1.3430  mosaic_unsup_loss_iou: 1.9207  mosaic_unsup_d0.loss_cls: 0.1673  mosaic_unsup_d0.loss_bbox: 1.3184  mosaic_unsup_d0.loss_iou: 1.9289  mosaic_unsup_d1.loss_cls: 0.1414  mosaic_unsup_d1.loss_bbox: 1.3286  mosaic_unsup_d1.loss_iou: 1.9249  mosaic_unsup_d2.loss_cls: 0.1181  mosaic_unsup_d2.loss_bbox: 1.3604  mosaic_unsup_d2.loss_iou: 1.9111  mosaic_unsup_d3.loss_cls: 0.1293  mosaic_unsup_d3.loss_bbox: 1.3369  mosaic_unsup_d3.loss_iou: 1.9196  mosaic_unsup_d4.loss_cls: 0.1424  mosaic_unsup_d4.loss_bbox: 1.3237  mosaic_unsup_d4.loss_iou: 1.9190
2025/06/23 23:07:48 - mmengine - INFO - Iter(train) [  4300/240000]  base_lr: 8.5999e-05 lr: 8.5999e-06  eta: 2 days, 4:13:48  time: 0.7551  data_time: 0.0247  memory: 9660  grad_norm: 1022.7242  loss: 42.6998  sup_loss_cls: 0.5648  sup_loss_bbox: 0.6295  sup_loss_iou: 1.2356  sup_d0.loss_cls: 0.5799  sup_d0.loss_bbox: 0.6256  sup_d0.loss_iou: 1.2440  sup_d1.loss_cls: 0.5765  sup_d1.loss_bbox: 0.6097  sup_d1.loss_iou: 1.2152  sup_d2.loss_cls: 0.5523  sup_d2.loss_bbox: 0.6375  sup_d2.loss_iou: 1.2487  sup_d3.loss_cls: 0.5588  sup_d3.loss_bbox: 0.7476  sup_d3.loss_iou: 1.3455  sup_d4.loss_cls: 0.5848  sup_d4.loss_bbox: 0.7263  sup_d4.loss_iou: 1.3452  mixup_unsup_loss_cls: 0.0482  mixup_unsup_loss_bbox: 0.3641  mixup_unsup_loss_iou: 0.5352  mixup_unsup_d0.loss_cls: 0.0535  mixup_unsup_d0.loss_bbox: 0.3529  mixup_unsup_d0.loss_iou: 0.5361  mixup_unsup_d1.loss_cls: 0.0536  mixup_unsup_d1.loss_bbox: 0.3487  mixup_unsup_d1.loss_iou: 0.5329  mixup_unsup_d2.loss_cls: 0.0548  mixup_unsup_d2.loss_bbox: 0.3477  mixup_unsup_d2.loss_iou: 0.5375  mixup_unsup_d3.loss_cls: 0.0476  mixup_unsup_d3.loss_bbox: 0.3369  mixup_unsup_d3.loss_iou: 0.5285  mixup_unsup_d4.loss_cls: 0.0511  mixup_unsup_d4.loss_bbox: 0.3302  mixup_unsup_d4.loss_iou: 0.5266  mosaic_unsup_loss_cls: 0.1791  mosaic_unsup_loss_bbox: 1.3206  mosaic_unsup_loss_iou: 2.2015  mosaic_unsup_d0.loss_cls: 0.1792  mosaic_unsup_d0.loss_bbox: 1.2978  mosaic_unsup_d0.loss_iou: 2.2050  mosaic_unsup_d1.loss_cls: 0.1739  mosaic_unsup_d1.loss_bbox: 1.2890  mosaic_unsup_d1.loss_iou: 2.2107  mosaic_unsup_d2.loss_cls: 0.1808  mosaic_unsup_d2.loss_bbox: 1.2710  mosaic_unsup_d2.loss_iou: 2.2040  mosaic_unsup_d3.loss_cls: 0.1626  mosaic_unsup_d3.loss_bbox: 1.3180  mosaic_unsup_d3.loss_iou: 2.1963  mosaic_unsup_d4.loss_cls: 0.1555  mosaic_unsup_d4.loss_bbox: 1.3435  mosaic_unsup_d4.loss_iou: 2.1978
2025/06/23 23:08:27 - mmengine - INFO - Iter(train) [  4350/240000]  base_lr: 8.6999e-05 lr: 8.6999e-06  eta: 2 days, 4:12:22  time: 0.7807  data_time: 0.0267  memory: 9885  grad_norm: 462.0806  loss: 44.4958  sup_loss_cls: 0.6057  sup_loss_bbox: 0.7888  sup_loss_iou: 1.2972  sup_d0.loss_cls: 0.6311  sup_d0.loss_bbox: 0.6282  sup_d0.loss_iou: 1.1757  sup_d1.loss_cls: 0.6713  sup_d1.loss_bbox: 0.6305  sup_d1.loss_iou: 1.2325  sup_d2.loss_cls: 0.7092  sup_d2.loss_bbox: 0.6955  sup_d2.loss_iou: 1.3216  sup_d3.loss_cls: 0.7200  sup_d3.loss_bbox: 0.7117  sup_d3.loss_iou: 1.2280  sup_d4.loss_cls: 0.6506  sup_d4.loss_bbox: 0.6776  sup_d4.loss_iou: 1.1964  mixup_unsup_loss_cls: 0.0022  mixup_unsup_loss_bbox: 0.1682  mixup_unsup_loss_iou: 0.2840  mixup_unsup_d0.loss_cls: 0.0020  mixup_unsup_d0.loss_bbox: 0.1661  mixup_unsup_d0.loss_iou: 0.2829  mixup_unsup_d1.loss_cls: 0.0019  mixup_unsup_d1.loss_bbox: 0.1684  mixup_unsup_d1.loss_iou: 0.2839  mixup_unsup_d2.loss_cls: 0.0020  mixup_unsup_d2.loss_bbox: 0.1685  mixup_unsup_d2.loss_iou: 0.2840  mixup_unsup_d3.loss_cls: 0.0022  mixup_unsup_d3.loss_bbox: 0.1681  mixup_unsup_d3.loss_iou: 0.2839  mixup_unsup_d4.loss_cls: 0.0022  mixup_unsup_d4.loss_bbox: 0.1683  mixup_unsup_d4.loss_iou: 0.2838  mosaic_unsup_loss_cls: 0.2577  mosaic_unsup_loss_bbox: 1.5724  mosaic_unsup_loss_iou: 2.4834  mosaic_unsup_d0.loss_cls: 0.2729  mosaic_unsup_d0.loss_bbox: 1.5910  mosaic_unsup_d0.loss_iou: 2.5050  mosaic_unsup_d1.loss_cls: 0.2535  mosaic_unsup_d1.loss_bbox: 1.6327  mosaic_unsup_d1.loss_iou: 2.4935  mosaic_unsup_d2.loss_cls: 0.2513  mosaic_unsup_d2.loss_bbox: 1.6764  mosaic_unsup_d2.loss_iou: 2.4814  mosaic_unsup_d3.loss_cls: 0.2606  mosaic_unsup_d3.loss_bbox: 1.6553  mosaic_unsup_d3.loss_iou: 2.4793  mosaic_unsup_d4.loss_cls: 0.2633  mosaic_unsup_d4.loss_bbox: 1.5794  mosaic_unsup_d4.loss_iou: 2.4928
2025/06/23 23:09:05 - mmengine - INFO - Iter(train) [  4400/240000]  base_lr: 8.7999e-05 lr: 8.7999e-06  eta: 2 days, 4:10:20  time: 0.7671  data_time: 0.0254  memory: 9885  grad_norm: 716.9658  loss: 54.7943  sup_loss_cls: 0.7954  sup_loss_bbox: 0.6152  sup_loss_iou: 1.3268  sup_d0.loss_cls: 0.7787  sup_d0.loss_bbox: 0.5459  sup_d0.loss_iou: 1.2924  sup_d1.loss_cls: 0.8244  sup_d1.loss_bbox: 0.6255  sup_d1.loss_iou: 1.4757  sup_d2.loss_cls: 0.8399  sup_d2.loss_bbox: 0.6336  sup_d2.loss_iou: 1.3479  sup_d3.loss_cls: 0.8478  sup_d3.loss_bbox: 0.7080  sup_d3.loss_iou: 1.4913  sup_d4.loss_cls: 0.8568  sup_d4.loss_bbox: 0.7016  sup_d4.loss_iou: 1.3767  mixup_unsup_loss_cls: 0.0336  mixup_unsup_loss_bbox: 0.3652  mixup_unsup_loss_iou: 0.6423  mixup_unsup_d0.loss_cls: 0.0374  mixup_unsup_d0.loss_bbox: 0.3560  mixup_unsup_d0.loss_iou: 0.6410  mixup_unsup_d1.loss_cls: 0.0358  mixup_unsup_d1.loss_bbox: 0.3645  mixup_unsup_d1.loss_iou: 0.6438  mixup_unsup_d2.loss_cls: 0.0389  mixup_unsup_d2.loss_bbox: 0.3614  mixup_unsup_d2.loss_iou: 0.6517  mixup_unsup_d3.loss_cls: 0.0355  mixup_unsup_d3.loss_bbox: 0.3738  mixup_unsup_d3.loss_iou: 0.6461  mixup_unsup_d4.loss_cls: 0.0314  mixup_unsup_d4.loss_bbox: 0.3825  mixup_unsup_d4.loss_iou: 0.6449  mosaic_unsup_loss_cls: 0.1040  mosaic_unsup_loss_bbox: 2.0919  mosaic_unsup_loss_iou: 3.1050  mosaic_unsup_d0.loss_cls: 0.1001  mosaic_unsup_d0.loss_bbox: 2.0644  mosaic_unsup_d0.loss_iou: 3.0942  mosaic_unsup_d1.loss_cls: 0.0746  mosaic_unsup_d1.loss_bbox: 2.0378  mosaic_unsup_d1.loss_iou: 3.0642  mosaic_unsup_d2.loss_cls: 0.0770  mosaic_unsup_d2.loss_bbox: 2.0389  mosaic_unsup_d2.loss_iou: 3.0502  mosaic_unsup_d3.loss_cls: 0.0825  mosaic_unsup_d3.loss_bbox: 2.0844  mosaic_unsup_d3.loss_iou: 3.0881  mosaic_unsup_d4.loss_cls: 0.1027  mosaic_unsup_d4.loss_bbox: 2.0701  mosaic_unsup_d4.loss_iou: 3.0948
2025/06/23 23:09:43 - mmengine - INFO - Iter(train) [  4450/240000]  base_lr: 8.8999e-05 lr: 8.8999e-06  eta: 2 days, 4:08:11  time: 0.7635  data_time: 0.0237  memory: 9885  grad_norm: 549.2834  loss: 48.4491  sup_loss_cls: 0.7604  sup_loss_bbox: 0.6551  sup_loss_iou: 1.2007  sup_d0.loss_cls: 0.7430  sup_d0.loss_bbox: 0.6364  sup_d0.loss_iou: 1.1642  sup_d1.loss_cls: 0.7097  sup_d1.loss_bbox: 0.5590  sup_d1.loss_iou: 1.1110  sup_d2.loss_cls: 0.7126  sup_d2.loss_bbox: 0.6597  sup_d2.loss_iou: 1.1900  sup_d3.loss_cls: 0.7486  sup_d3.loss_bbox: 0.7273  sup_d3.loss_iou: 1.2986  sup_d4.loss_cls: 0.7706  sup_d4.loss_bbox: 0.8626  sup_d4.loss_iou: 1.3653  mixup_unsup_loss_cls: 0.0722  mixup_unsup_loss_bbox: 0.2284  mixup_unsup_loss_iou: 0.3992  mixup_unsup_d0.loss_cls: 0.0698  mixup_unsup_d0.loss_bbox: 0.2471  mixup_unsup_d0.loss_iou: 0.4078  mixup_unsup_d1.loss_cls: 0.0748  mixup_unsup_d1.loss_bbox: 0.2304  mixup_unsup_d1.loss_iou: 0.4051  mixup_unsup_d2.loss_cls: 0.0761  mixup_unsup_d2.loss_bbox: 0.2370  mixup_unsup_d2.loss_iou: 0.4050  mixup_unsup_d3.loss_cls: 0.0702  mixup_unsup_d3.loss_bbox: 0.2332  mixup_unsup_d3.loss_iou: 0.4019  mixup_unsup_d4.loss_cls: 0.0766  mixup_unsup_d4.loss_bbox: 0.2459  mixup_unsup_d4.loss_iou: 0.4062  mosaic_unsup_loss_cls: 0.2180  mosaic_unsup_loss_bbox: 1.8700  mosaic_unsup_loss_iou: 2.6480  mosaic_unsup_d0.loss_cls: 0.2134  mosaic_unsup_d0.loss_bbox: 1.8170  mosaic_unsup_d0.loss_iou: 2.6562  mosaic_unsup_d1.loss_cls: 0.2576  mosaic_unsup_d1.loss_bbox: 1.7974  mosaic_unsup_d1.loss_iou: 2.6637  mosaic_unsup_d2.loss_cls: 0.2602  mosaic_unsup_d2.loss_bbox: 1.7738  mosaic_unsup_d2.loss_iou: 2.6776  mosaic_unsup_d3.loss_cls: 0.2466  mosaic_unsup_d3.loss_bbox: 1.8171  mosaic_unsup_d3.loss_iou: 2.6876  mosaic_unsup_d4.loss_cls: 0.2173  mosaic_unsup_d4.loss_bbox: 1.8268  mosaic_unsup_d4.loss_iou: 2.6389
2025/06/23 23:10:20 - mmengine - INFO - Iter(train) [  4500/240000]  base_lr: 8.9999e-05 lr: 8.9999e-06  eta: 2 days, 4:05:11  time: 0.7431  data_time: 0.0235  memory: 9885  grad_norm: 447.5981  loss: 49.7015  sup_loss_cls: 0.6891  sup_loss_bbox: 0.7172  sup_loss_iou: 1.2862  sup_d0.loss_cls: 0.6370  sup_d0.loss_bbox: 0.5051  sup_d0.loss_iou: 1.0753  sup_d1.loss_cls: 0.6911  sup_d1.loss_bbox: 0.5444  sup_d1.loss_iou: 1.1177  sup_d2.loss_cls: 0.6931  sup_d2.loss_bbox: 0.5652  sup_d2.loss_iou: 1.0903  sup_d3.loss_cls: 0.7085  sup_d3.loss_bbox: 0.5773  sup_d3.loss_iou: 1.1186  sup_d4.loss_cls: 0.6962  sup_d4.loss_bbox: 0.6846  sup_d4.loss_iou: 1.1635  mixup_unsup_loss_cls: 0.0375  mixup_unsup_loss_bbox: 0.4344  mixup_unsup_loss_iou: 0.8570  mixup_unsup_d0.loss_cls: 0.0496  mixup_unsup_d0.loss_bbox: 0.4158  mixup_unsup_d0.loss_iou: 0.8521  mixup_unsup_d1.loss_cls: 0.0412  mixup_unsup_d1.loss_bbox: 0.4273  mixup_unsup_d1.loss_iou: 0.8675  mixup_unsup_d2.loss_cls: 0.0405  mixup_unsup_d2.loss_bbox: 0.4315  mixup_unsup_d2.loss_iou: 0.8672  mixup_unsup_d3.loss_cls: 0.0455  mixup_unsup_d3.loss_bbox: 0.4494  mixup_unsup_d3.loss_iou: 0.8911  mixup_unsup_d4.loss_cls: 0.0342  mixup_unsup_d4.loss_bbox: 0.4327  mixup_unsup_d4.loss_iou: 0.8631  mosaic_unsup_loss_cls: 0.0623  mosaic_unsup_loss_bbox: 1.7781  mosaic_unsup_loss_iou: 2.6524  mosaic_unsup_d0.loss_cls: 0.0777  mosaic_unsup_d0.loss_bbox: 1.7925  mosaic_unsup_d0.loss_iou: 2.6688  mosaic_unsup_d1.loss_cls: 0.0691  mosaic_unsup_d1.loss_bbox: 1.7934  mosaic_unsup_d1.loss_iou: 2.6601  mosaic_unsup_d2.loss_cls: 0.0661  mosaic_unsup_d2.loss_bbox: 1.7593  mosaic_unsup_d2.loss_iou: 2.6728  mosaic_unsup_d3.loss_cls: 0.0661  mosaic_unsup_d3.loss_bbox: 1.7975  mosaic_unsup_d3.loss_iou: 2.7114  mosaic_unsup_d4.loss_cls: 0.0620  mosaic_unsup_d4.loss_bbox: 1.7755  mosaic_unsup_d4.loss_iou: 2.6385
2025/06/23 23:10:58 - mmengine - INFO - Iter(train) [  4550/240000]  base_lr: 9.0999e-05 lr: 9.0999e-06  eta: 2 days, 4:02:13  time: 0.7426  data_time: 0.0230  memory: 9884  grad_norm: 368.1863  loss: 44.3625  sup_loss_cls: 0.6618  sup_loss_bbox: 0.6137  sup_loss_iou: 1.2268  sup_d0.loss_cls: 0.6344  sup_d0.loss_bbox: 0.5488  sup_d0.loss_iou: 1.1932  sup_d1.loss_cls: 0.6601  sup_d1.loss_bbox: 0.5659  sup_d1.loss_iou: 1.2514  sup_d2.loss_cls: 0.6862  sup_d2.loss_bbox: 0.5811  sup_d2.loss_iou: 1.2016  sup_d3.loss_cls: 0.6649  sup_d3.loss_bbox: 0.5872  sup_d3.loss_iou: 1.2339  sup_d4.loss_cls: 0.6784  sup_d4.loss_bbox: 0.6107  sup_d4.loss_iou: 1.2249  mixup_unsup_loss_cls: 0.0028  mixup_unsup_loss_bbox: 0.1598  mixup_unsup_loss_iou: 0.2539  mixup_unsup_d0.loss_cls: 0.0035  mixup_unsup_d0.loss_bbox: 0.1580  mixup_unsup_d0.loss_iou: 0.2572  mixup_unsup_d1.loss_cls: 0.0032  mixup_unsup_d1.loss_bbox: 0.1607  mixup_unsup_d1.loss_iou: 0.2609  mixup_unsup_d2.loss_cls: 0.0026  mixup_unsup_d2.loss_bbox: 0.1550  mixup_unsup_d2.loss_iou: 0.2594  mixup_unsup_d3.loss_cls: 0.0027  mixup_unsup_d3.loss_bbox: 0.1538  mixup_unsup_d3.loss_iou: 0.2640  mixup_unsup_d4.loss_cls: 0.0029  mixup_unsup_d4.loss_bbox: 0.1585  mixup_unsup_d4.loss_iou: 0.2565  mosaic_unsup_loss_cls: 0.0422  mosaic_unsup_loss_bbox: 1.7361  mosaic_unsup_loss_iou: 2.6881  mosaic_unsup_d0.loss_cls: 0.0511  mosaic_unsup_d0.loss_bbox: 1.7461  mosaic_unsup_d0.loss_iou: 2.7097  mosaic_unsup_d1.loss_cls: 0.0444  mosaic_unsup_d1.loss_bbox: 1.7374  mosaic_unsup_d1.loss_iou: 2.6752  mosaic_unsup_d2.loss_cls: 0.0387  mosaic_unsup_d2.loss_bbox: 1.7563  mosaic_unsup_d2.loss_iou: 2.7441  mosaic_unsup_d3.loss_cls: 0.0419  mosaic_unsup_d3.loss_bbox: 1.7510  mosaic_unsup_d3.loss_iou: 2.8110  mosaic_unsup_d4.loss_cls: 0.0425  mosaic_unsup_d4.loss_bbox: 1.7355  mosaic_unsup_d4.loss_iou: 2.6707
2025/06/23 23:11:35 - mmengine - INFO - Iter(train) [  4600/240000]  base_lr: 9.1999e-05 lr: 9.1999e-06  eta: 2 days, 3:59:21  time: 0.7441  data_time: 0.0242  memory: 9885  grad_norm: 636.9415  loss: 46.9566  sup_loss_cls: 0.6459  sup_loss_bbox: 0.6822  sup_loss_iou: 1.2488  sup_d0.loss_cls: 0.6011  sup_d0.loss_bbox: 0.5526  sup_d0.loss_iou: 1.1770  sup_d1.loss_cls: 0.5978  sup_d1.loss_bbox: 0.6238  sup_d1.loss_iou: 1.1957  sup_d2.loss_cls: 0.6560  sup_d2.loss_bbox: 0.5820  sup_d2.loss_iou: 1.1665  sup_d3.loss_cls: 0.6457  sup_d3.loss_bbox: 0.6833  sup_d3.loss_iou: 1.3171  sup_d4.loss_cls: 0.6528  sup_d4.loss_bbox: 0.7622  sup_d4.loss_iou: 1.2815  mixup_unsup_loss_cls: 0.1081  mixup_unsup_loss_bbox: 0.2744  mixup_unsup_loss_iou: 0.5050  mixup_unsup_d0.loss_cls: 0.1256  mixup_unsup_d0.loss_bbox: 0.2614  mixup_unsup_d0.loss_iou: 0.5092  mixup_unsup_d1.loss_cls: 0.1140  mixup_unsup_d1.loss_bbox: 0.2526  mixup_unsup_d1.loss_iou: 0.5060  mixup_unsup_d2.loss_cls: 0.1080  mixup_unsup_d2.loss_bbox: 0.2679  mixup_unsup_d2.loss_iou: 0.5170  mixup_unsup_d3.loss_cls: 0.1070  mixup_unsup_d3.loss_bbox: 0.2899  mixup_unsup_d3.loss_iou: 0.5182  mixup_unsup_d4.loss_cls: 0.1007  mixup_unsup_d4.loss_bbox: 0.3058  mixup_unsup_d4.loss_iou: 0.5098  mosaic_unsup_loss_cls: 0.2104  mosaic_unsup_loss_bbox: 1.6923  mosaic_unsup_loss_iou: 2.5251  mosaic_unsup_d0.loss_cls: 0.2208  mosaic_unsup_d0.loss_bbox: 1.6762  mosaic_unsup_d0.loss_iou: 2.5305  mosaic_unsup_d1.loss_cls: 0.2143  mosaic_unsup_d1.loss_bbox: 1.6466  mosaic_unsup_d1.loss_iou: 2.5203  mosaic_unsup_d2.loss_cls: 0.1885  mosaic_unsup_d2.loss_bbox: 1.6666  mosaic_unsup_d2.loss_iou: 2.5401  mosaic_unsup_d3.loss_cls: 0.1973  mosaic_unsup_d3.loss_bbox: 1.6910  mosaic_unsup_d3.loss_iou: 2.5588  mosaic_unsup_d4.loss_cls: 0.2084  mosaic_unsup_d4.loss_bbox: 1.6985  mosaic_unsup_d4.loss_iou: 2.5183
2025/06/23 23:12:13 - mmengine - INFO - Iter(train) [  4650/240000]  base_lr: 9.2999e-05 lr: 9.2999e-06  eta: 2 days, 3:57:03  time: 0.7561  data_time: 0.0230  memory: 9885  grad_norm: 325.4873  loss: 51.7566  sup_loss_cls: 0.7761  sup_loss_bbox: 0.6029  sup_loss_iou: 1.1885  sup_d0.loss_cls: 0.7454  sup_d0.loss_bbox: 0.6462  sup_d0.loss_iou: 1.3089  sup_d1.loss_cls: 0.7497  sup_d1.loss_bbox: 0.5907  sup_d1.loss_iou: 1.2751  sup_d2.loss_cls: 0.8125  sup_d2.loss_bbox: 0.6841  sup_d2.loss_iou: 1.3502  sup_d3.loss_cls: 0.7591  sup_d3.loss_bbox: 0.6592  sup_d3.loss_iou: 1.3088  sup_d4.loss_cls: 0.7359  sup_d4.loss_bbox: 0.6749  sup_d4.loss_iou: 1.2910  mixup_unsup_loss_cls: 0.0337  mixup_unsup_loss_bbox: 0.2583  mixup_unsup_loss_iou: 0.5002  mixup_unsup_d0.loss_cls: 0.0369  mixup_unsup_d0.loss_bbox: 0.2697  mixup_unsup_d0.loss_iou: 0.5006  mixup_unsup_d1.loss_cls: 0.0464  mixup_unsup_d1.loss_bbox: 0.2641  mixup_unsup_d1.loss_iou: 0.5009  mixup_unsup_d2.loss_cls: 0.0397  mixup_unsup_d2.loss_bbox: 0.2780  mixup_unsup_d2.loss_iou: 0.5234  mixup_unsup_d3.loss_cls: 0.0318  mixup_unsup_d3.loss_bbox: 0.2630  mixup_unsup_d3.loss_iou: 0.5214  mixup_unsup_d4.loss_cls: 0.0345  mixup_unsup_d4.loss_bbox: 0.2521  mixup_unsup_d4.loss_iou: 0.4995  mosaic_unsup_loss_cls: 0.0689  mosaic_unsup_loss_bbox: 2.0514  mosaic_unsup_loss_iou: 2.9622  mosaic_unsup_d0.loss_cls: 0.0712  mosaic_unsup_d0.loss_bbox: 2.0995  mosaic_unsup_d0.loss_iou: 2.9804  mosaic_unsup_d1.loss_cls: 0.0777  mosaic_unsup_d1.loss_bbox: 2.0935  mosaic_unsup_d1.loss_iou: 2.9894  mosaic_unsup_d2.loss_cls: 0.0705  mosaic_unsup_d2.loss_bbox: 2.0542  mosaic_unsup_d2.loss_iou: 3.0217  mosaic_unsup_d3.loss_cls: 0.0667  mosaic_unsup_d3.loss_bbox: 2.0399  mosaic_unsup_d3.loss_iou: 3.0024  mosaic_unsup_d4.loss_cls: 0.0713  mosaic_unsup_d4.loss_bbox: 2.0593  mosaic_unsup_d4.loss_iou: 2.9629
2025/06/23 23:12:50 - mmengine - INFO - Iter(train) [  4700/240000]  base_lr: 9.3999e-05 lr: 9.3999e-06  eta: 2 days, 3:54:35  time: 0.7514  data_time: 0.0239  memory: 9885  grad_norm: 633.4842  loss: 43.7539  sup_loss_cls: 0.7793  sup_loss_bbox: 0.8841  sup_loss_iou: 1.4729  sup_d0.loss_cls: 0.7572  sup_d0.loss_bbox: 0.6822  sup_d0.loss_iou: 1.3226  sup_d1.loss_cls: 0.7811  sup_d1.loss_bbox: 0.8131  sup_d1.loss_iou: 1.4563  sup_d2.loss_cls: 0.7973  sup_d2.loss_bbox: 0.7210  sup_d2.loss_iou: 1.2147  sup_d3.loss_cls: 0.8042  sup_d3.loss_bbox: 0.7983  sup_d3.loss_iou: 1.2855  sup_d4.loss_cls: 0.8428  sup_d4.loss_bbox: 0.8420  sup_d4.loss_iou: 1.3498  mixup_unsup_loss_cls: 0.0028  mixup_unsup_loss_bbox: 0.1047  mixup_unsup_loss_iou: 0.2380  mixup_unsup_d0.loss_cls: 0.0035  mixup_unsup_d0.loss_bbox: 0.1072  mixup_unsup_d0.loss_iou: 0.2417  mixup_unsup_d1.loss_cls: 0.0025  mixup_unsup_d1.loss_bbox: 0.1043  mixup_unsup_d1.loss_iou: 0.2378  mixup_unsup_d2.loss_cls: 0.0030  mixup_unsup_d2.loss_bbox: 0.1090  mixup_unsup_d2.loss_iou: 0.2427  mixup_unsup_d3.loss_cls: 0.0035  mixup_unsup_d3.loss_bbox: 0.1090  mixup_unsup_d3.loss_iou: 0.2419  mixup_unsup_d4.loss_cls: 0.0027  mixup_unsup_d4.loss_bbox: 0.1037  mixup_unsup_d4.loss_iou: 0.2372  mosaic_unsup_loss_cls: 0.0256  mosaic_unsup_loss_bbox: 1.5314  mosaic_unsup_loss_iou: 2.4196  mosaic_unsup_d0.loss_cls: 0.0321  mosaic_unsup_d0.loss_bbox: 1.5586  mosaic_unsup_d0.loss_iou: 2.4667  mosaic_unsup_d1.loss_cls: 0.0242  mosaic_unsup_d1.loss_bbox: 1.5509  mosaic_unsup_d1.loss_iou: 2.4405  mosaic_unsup_d2.loss_cls: 0.0279  mosaic_unsup_d2.loss_bbox: 1.5369  mosaic_unsup_d2.loss_iou: 2.4425  mosaic_unsup_d3.loss_cls: 0.0300  mosaic_unsup_d3.loss_bbox: 1.5428  mosaic_unsup_d3.loss_iou: 2.4571  mosaic_unsup_d4.loss_cls: 0.0253  mosaic_unsup_d4.loss_bbox: 1.5313  mosaic_unsup_d4.loss_iou: 2.4110
2025/06/23 23:13:27 - mmengine - INFO - Iter(train) [  4750/240000]  base_lr: 9.4999e-05 lr: 9.4999e-06  eta: 2 days, 3:51:25  time: 0.7338  data_time: 0.0233  memory: 9627  grad_norm: 399.1784  loss: 44.1929  sup_loss_cls: 0.5339  sup_loss_bbox: 0.5753  sup_loss_iou: 1.0795  sup_d0.loss_cls: 0.5296  sup_d0.loss_bbox: 0.4533  sup_d0.loss_iou: 1.0421  sup_d1.loss_cls: 0.5623  sup_d1.loss_bbox: 0.5115  sup_d1.loss_iou: 1.0524  sup_d2.loss_cls: 0.6037  sup_d2.loss_bbox: 0.5110  sup_d2.loss_iou: 1.0323  sup_d3.loss_cls: 0.5760  sup_d3.loss_bbox: 0.6406  sup_d3.loss_iou: 1.1723  sup_d4.loss_cls: 0.5386  sup_d4.loss_bbox: 0.5534  sup_d4.loss_iou: 1.1008  mixup_unsup_loss_cls: 0.1307  mixup_unsup_loss_bbox: 0.3347  mixup_unsup_loss_iou: 0.6255  mixup_unsup_d0.loss_cls: 0.1410  mixup_unsup_d0.loss_bbox: 0.3687  mixup_unsup_d0.loss_iou: 0.6342  mixup_unsup_d1.loss_cls: 0.1270  mixup_unsup_d1.loss_bbox: 0.3641  mixup_unsup_d1.loss_iou: 0.6311  mixup_unsup_d2.loss_cls: 0.1126  mixup_unsup_d2.loss_bbox: 0.3462  mixup_unsup_d2.loss_iou: 0.6357  mixup_unsup_d3.loss_cls: 0.1392  mixup_unsup_d3.loss_bbox: 0.3540  mixup_unsup_d3.loss_iou: 0.6363  mixup_unsup_d4.loss_cls: 0.1289  mixup_unsup_d4.loss_bbox: 0.3729  mixup_unsup_d4.loss_iou: 0.6311  mosaic_unsup_loss_cls: 0.0253  mosaic_unsup_loss_bbox: 1.5999  mosaic_unsup_loss_iou: 2.4454  mosaic_unsup_d0.loss_cls: 0.0299  mosaic_unsup_d0.loss_bbox: 1.6053  mosaic_unsup_d0.loss_iou: 2.4488  mosaic_unsup_d1.loss_cls: 0.0253  mosaic_unsup_d1.loss_bbox: 1.6178  mosaic_unsup_d1.loss_iou: 2.4439  mosaic_unsup_d2.loss_cls: 0.0309  mosaic_unsup_d2.loss_bbox: 1.5843  mosaic_unsup_d2.loss_iou: 2.4319  mosaic_unsup_d3.loss_cls: 0.0337  mosaic_unsup_d3.loss_bbox: 1.5733  mosaic_unsup_d3.loss_iou: 2.4418  mosaic_unsup_d4.loss_cls: 0.0265  mosaic_unsup_d4.loss_bbox: 1.6049  mosaic_unsup_d4.loss_iou: 2.4418
2025/06/23 23:14:05 - mmengine - INFO - Iter(train) [  4800/240000]  base_lr: 9.6000e-05 lr: 9.6000e-06  eta: 2 days, 3:49:07  time: 0.7533  data_time: 0.0230  memory: 9614  grad_norm: 448.7974  loss: 49.6770  sup_loss_cls: 0.5922  sup_loss_bbox: 0.5369  sup_loss_iou: 1.0946  sup_d0.loss_cls: 0.6535  sup_d0.loss_bbox: 0.6653  sup_d0.loss_iou: 1.3398  sup_d1.loss_cls: 0.6252  sup_d1.loss_bbox: 0.5715  sup_d1.loss_iou: 1.1392  sup_d2.loss_cls: 0.6505  sup_d2.loss_bbox: 0.6011  sup_d2.loss_iou: 1.0464  sup_d3.loss_cls: 0.6205  sup_d3.loss_bbox: 0.6029  sup_d3.loss_iou: 1.1301  sup_d4.loss_cls: 0.6037  sup_d4.loss_bbox: 0.6669  sup_d4.loss_iou: 1.1889  mixup_unsup_loss_cls: 0.1651  mixup_unsup_loss_bbox: 0.3893  mixup_unsup_loss_iou: 0.7234  mixup_unsup_d0.loss_cls: 0.1406  mixup_unsup_d0.loss_bbox: 0.4970  mixup_unsup_d0.loss_iou: 0.7394  mixup_unsup_d1.loss_cls: 0.1656  mixup_unsup_d1.loss_bbox: 0.4557  mixup_unsup_d1.loss_iou: 0.7395  mixup_unsup_d2.loss_cls: 0.1525  mixup_unsup_d2.loss_bbox: 0.4081  mixup_unsup_d2.loss_iou: 0.7316  mixup_unsup_d3.loss_cls: 0.1509  mixup_unsup_d3.loss_bbox: 0.4206  mixup_unsup_d3.loss_iou: 0.7286  mixup_unsup_d4.loss_cls: 0.1507  mixup_unsup_d4.loss_bbox: 0.4002  mixup_unsup_d4.loss_iou: 0.7245  mosaic_unsup_loss_cls: 0.0156  mosaic_unsup_loss_bbox: 1.7730  mosaic_unsup_loss_iou: 2.7899  mosaic_unsup_d0.loss_cls: 0.0151  mosaic_unsup_d0.loss_bbox: 1.7856  mosaic_unsup_d0.loss_iou: 2.7939  mosaic_unsup_d1.loss_cls: 0.0134  mosaic_unsup_d1.loss_bbox: 1.7790  mosaic_unsup_d1.loss_iou: 2.7934  mosaic_unsup_d2.loss_cls: 0.0158  mosaic_unsup_d2.loss_bbox: 1.7653  mosaic_unsup_d2.loss_iou: 2.7811  mosaic_unsup_d3.loss_cls: 0.0148  mosaic_unsup_d3.loss_bbox: 1.7696  mosaic_unsup_d3.loss_iou: 2.7868  mosaic_unsup_d4.loss_cls: 0.0159  mosaic_unsup_d4.loss_bbox: 1.7758  mosaic_unsup_d4.loss_iou: 2.7807
2025/06/23 23:14:43 - mmengine - INFO - Iter(train) [  4850/240000]  base_lr: 9.7000e-05 lr: 9.7000e-06  eta: 2 days, 3:47:42  time: 0.7742  data_time: 0.0239  memory: 9883  grad_norm: 1044.8614  loss: 46.1380  sup_loss_cls: 0.5425  sup_loss_bbox: 0.5392  sup_loss_iou: 1.0567  sup_d0.loss_cls: 0.5095  sup_d0.loss_bbox: 0.5422  sup_d0.loss_iou: 1.1862  sup_d1.loss_cls: 0.5222  sup_d1.loss_bbox: 0.4328  sup_d1.loss_iou: 1.0004  sup_d2.loss_cls: 0.5423  sup_d2.loss_bbox: 0.5191  sup_d2.loss_iou: 1.0507  sup_d3.loss_cls: 0.5411  sup_d3.loss_bbox: 0.5010  sup_d3.loss_iou: 1.0412  sup_d4.loss_cls: 0.5246  sup_d4.loss_bbox: 0.5189  sup_d4.loss_iou: 1.0898  mixup_unsup_loss_cls: 0.0543  mixup_unsup_loss_bbox: 0.5069  mixup_unsup_loss_iou: 0.8729  mixup_unsup_d0.loss_cls: 0.0554  mixup_unsup_d0.loss_bbox: 0.5138  mixup_unsup_d0.loss_iou: 0.8799  mixup_unsup_d1.loss_cls: 0.0543  mixup_unsup_d1.loss_bbox: 0.4976  mixup_unsup_d1.loss_iou: 0.8736  mixup_unsup_d2.loss_cls: 0.0530  mixup_unsup_d2.loss_bbox: 0.4991  mixup_unsup_d2.loss_iou: 0.8751  mixup_unsup_d3.loss_cls: 0.0560  mixup_unsup_d3.loss_bbox: 0.5066  mixup_unsup_d3.loss_iou: 0.8775  mixup_unsup_d4.loss_cls: 0.0571  mixup_unsup_d4.loss_bbox: 0.5086  mixup_unsup_d4.loss_iou: 0.8764  mosaic_unsup_loss_cls: 0.0179  mosaic_unsup_loss_bbox: 1.6313  mosaic_unsup_loss_iou: 2.4826  mosaic_unsup_d0.loss_cls: 0.0220  mosaic_unsup_d0.loss_bbox: 1.6536  mosaic_unsup_d0.loss_iou: 2.4795  mosaic_unsup_d1.loss_cls: 0.0200  mosaic_unsup_d1.loss_bbox: 1.6379  mosaic_unsup_d1.loss_iou: 2.4941  mosaic_unsup_d2.loss_cls: 0.0228  mosaic_unsup_d2.loss_bbox: 1.6351  mosaic_unsup_d2.loss_iou: 2.4764  mosaic_unsup_d3.loss_cls: 0.0194  mosaic_unsup_d3.loss_bbox: 1.6551  mosaic_unsup_d3.loss_iou: 2.4822  mosaic_unsup_d4.loss_cls: 0.0195  mosaic_unsup_d4.loss_bbox: 1.6325  mosaic_unsup_d4.loss_iou: 2.4778
2025/06/23 23:15:22 - mmengine - INFO - Iter(train) [  4900/240000]  base_lr: 9.8000e-05 lr: 9.8000e-06  eta: 2 days, 3:46:11  time: 0.7717  data_time: 0.0237  memory: 9885  grad_norm: 383.3567  loss: 53.9917  sup_loss_cls: 0.6066  sup_loss_bbox: 0.6280  sup_loss_iou: 1.3040  sup_d0.loss_cls: 0.5899  sup_d0.loss_bbox: 0.5192  sup_d0.loss_iou: 1.1180  sup_d1.loss_cls: 0.6223  sup_d1.loss_bbox: 0.5147  sup_d1.loss_iou: 1.1541  sup_d2.loss_cls: 0.6314  sup_d2.loss_bbox: 0.5048  sup_d2.loss_iou: 1.0621  sup_d3.loss_cls: 0.6406  sup_d3.loss_bbox: 0.4945  sup_d3.loss_iou: 1.0901  sup_d4.loss_cls: 0.6265  sup_d4.loss_bbox: 0.5594  sup_d4.loss_iou: 1.1253  mixup_unsup_loss_cls: 0.0436  mixup_unsup_loss_bbox: 0.4352  mixup_unsup_loss_iou: 0.7588  mixup_unsup_d0.loss_cls: 0.0448  mixup_unsup_d0.loss_bbox: 0.4529  mixup_unsup_d0.loss_iou: 0.7655  mixup_unsup_d1.loss_cls: 0.0409  mixup_unsup_d1.loss_bbox: 0.4414  mixup_unsup_d1.loss_iou: 0.7615  mixup_unsup_d2.loss_cls: 0.0484  mixup_unsup_d2.loss_bbox: 0.4336  mixup_unsup_d2.loss_iou: 0.7620  mixup_unsup_d3.loss_cls: 0.0316  mixup_unsup_d3.loss_bbox: 0.4390  mixup_unsup_d3.loss_iou: 0.7625  mixup_unsup_d4.loss_cls: 0.0399  mixup_unsup_d4.loss_bbox: 0.4421  mixup_unsup_d4.loss_iou: 0.7637  mosaic_unsup_loss_cls: 0.0129  mosaic_unsup_loss_bbox: 2.2927  mosaic_unsup_loss_iou: 3.1390  mosaic_unsup_d0.loss_cls: 0.0171  mosaic_unsup_d0.loss_bbox: 2.2881  mosaic_unsup_d0.loss_iou: 3.1536  mosaic_unsup_d1.loss_cls: 0.0154  mosaic_unsup_d1.loss_bbox: 2.2937  mosaic_unsup_d1.loss_iou: 3.1455  mosaic_unsup_d2.loss_cls: 0.0160  mosaic_unsup_d2.loss_bbox: 2.2933  mosaic_unsup_d2.loss_iou: 3.1570  mosaic_unsup_d3.loss_cls: 0.0131  mosaic_unsup_d3.loss_bbox: 2.2960  mosaic_unsup_d3.loss_iou: 3.1510  mosaic_unsup_d4.loss_cls: 0.0143  mosaic_unsup_d4.loss_bbox: 2.2839  mosaic_unsup_d4.loss_iou: 3.1507
2025/06/23 23:16:00 - mmengine - INFO - Iter(train) [  4950/240000]  base_lr: 9.9000e-05 lr: 9.9000e-06  eta: 2 days, 3:44:23  time: 0.7640  data_time: 0.0237  memory: 9466  grad_norm: 744.7714  loss: 62.4710  sup_loss_cls: 0.7148  sup_loss_bbox: 0.6386  sup_loss_iou: 1.3124  sup_d0.loss_cls: 0.6095  sup_d0.loss_bbox: 0.5496  sup_d0.loss_iou: 1.1473  sup_d1.loss_cls: 0.6976  sup_d1.loss_bbox: 0.6055  sup_d1.loss_iou: 1.3156  sup_d2.loss_cls: 0.7168  sup_d2.loss_bbox: 0.6018  sup_d2.loss_iou: 1.2567  sup_d3.loss_cls: 0.6872  sup_d3.loss_bbox: 0.5932  sup_d3.loss_iou: 1.2885  sup_d4.loss_cls: 0.6260  sup_d4.loss_bbox: 0.6470  sup_d4.loss_iou: 1.3470  mixup_unsup_loss_cls: 0.2683  mixup_unsup_loss_bbox: 0.8074  mixup_unsup_loss_iou: 1.3573  mixup_unsup_d0.loss_cls: 0.2957  mixup_unsup_d0.loss_bbox: 0.7413  mixup_unsup_d0.loss_iou: 1.3440  mixup_unsup_d1.loss_cls: 0.2483  mixup_unsup_d1.loss_bbox: 0.7616  mixup_unsup_d1.loss_iou: 1.3488  mixup_unsup_d2.loss_cls: 0.2620  mixup_unsup_d2.loss_bbox: 0.7711  mixup_unsup_d2.loss_iou: 1.3485  mixup_unsup_d3.loss_cls: 0.2232  mixup_unsup_d3.loss_bbox: 0.7191  mixup_unsup_d3.loss_iou: 1.3241  mixup_unsup_d4.loss_cls: 0.2659  mixup_unsup_d4.loss_bbox: 0.6899  mixup_unsup_d4.loss_iou: 1.3036  mosaic_unsup_loss_cls: 0.0165  mosaic_unsup_loss_bbox: 2.3676  mosaic_unsup_loss_iou: 3.1254  mosaic_unsup_d0.loss_cls: 0.0169  mosaic_unsup_d0.loss_bbox: 2.3684  mosaic_unsup_d0.loss_iou: 3.1195  mosaic_unsup_d1.loss_cls: 0.0160  mosaic_unsup_d1.loss_bbox: 2.3711  mosaic_unsup_d1.loss_iou: 3.1212  mosaic_unsup_d2.loss_cls: 0.0191  mosaic_unsup_d2.loss_bbox: 2.3428  mosaic_unsup_d2.loss_iou: 3.1376  mosaic_unsup_d3.loss_cls: 0.0170  mosaic_unsup_d3.loss_bbox: 2.3764  mosaic_unsup_d3.loss_iou: 3.1157  mosaic_unsup_d4.loss_cls: 0.0162  mosaic_unsup_d4.loss_bbox: 2.3700  mosaic_unsup_d4.loss_iou: 3.1186
2025/06/23 23:16:38 - mmengine - INFO - Exp name: Newdatamixpl05_detr_r50_100_sonar-s1-p10_20250623_220902
2025/06/23 23:16:38 - mmengine - INFO - Iter(train) [  5000/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:42:03  time: 0.7499  data_time: 0.0242  memory: 9703  grad_norm: 429.7908  loss: 37.8978  sup_loss_cls: 0.6058  sup_loss_bbox: 0.7026  sup_loss_iou: 1.2013  sup_d0.loss_cls: 0.5607  sup_d0.loss_bbox: 0.5712  sup_d0.loss_iou: 1.1746  sup_d1.loss_cls: 0.5862  sup_d1.loss_bbox: 0.4936  sup_d1.loss_iou: 1.0726  sup_d2.loss_cls: 0.6228  sup_d2.loss_bbox: 0.5934  sup_d2.loss_iou: 1.1745  sup_d3.loss_cls: 0.5930  sup_d3.loss_bbox: 0.5806  sup_d3.loss_iou: 1.1435  sup_d4.loss_cls: 0.6013  sup_d4.loss_bbox: 0.6341  sup_d4.loss_iou: 1.1534  mixup_unsup_loss_cls: 0.0106  mixup_unsup_loss_bbox: 0.2627  mixup_unsup_loss_iou: 0.4298  mixup_unsup_d0.loss_cls: 0.0165  mixup_unsup_d0.loss_bbox: 0.2555  mixup_unsup_d0.loss_iou: 0.4244  mixup_unsup_d1.loss_cls: 0.0132  mixup_unsup_d1.loss_bbox: 0.2577  mixup_unsup_d1.loss_iou: 0.4257  mixup_unsup_d2.loss_cls: 0.0159  mixup_unsup_d2.loss_bbox: 0.2569  mixup_unsup_d2.loss_iou: 0.4247  mixup_unsup_d3.loss_cls: 0.0085  mixup_unsup_d3.loss_bbox: 0.2579  mixup_unsup_d3.loss_iou: 0.4246  mixup_unsup_d4.loss_cls: 0.0160  mixup_unsup_d4.loss_bbox: 0.2623  mixup_unsup_d4.loss_iou: 0.4284  mosaic_unsup_loss_cls: 0.0109  mosaic_unsup_loss_bbox: 1.1247  mosaic_unsup_loss_iou: 2.1258  mosaic_unsup_d0.loss_cls: 0.0109  mosaic_unsup_d0.loss_bbox: 1.1387  mosaic_unsup_d0.loss_iou: 2.1218  mosaic_unsup_d1.loss_cls: 0.0107  mosaic_unsup_d1.loss_bbox: 1.1237  mosaic_unsup_d1.loss_iou: 2.1198  mosaic_unsup_d2.loss_cls: 0.0101  mosaic_unsup_d2.loss_bbox: 1.1427  mosaic_unsup_d2.loss_iou: 2.1326  mosaic_unsup_d3.loss_cls: 0.0099  mosaic_unsup_d3.loss_bbox: 1.1487  mosaic_unsup_d3.loss_iou: 2.1348  mosaic_unsup_d4.loss_cls: 0.0085  mosaic_unsup_d4.loss_bbox: 1.1381  mosaic_unsup_d4.loss_iou: 2.1285
2025/06/23 23:17:15 - mmengine - INFO - Iter(train) [  5050/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:40:06  time: 0.7587  data_time: 0.0229  memory: 9819  grad_norm: 298.6174  loss: 42.7070  sup_loss_cls: 0.5253  sup_loss_bbox: 0.5339  sup_loss_iou: 1.1072  sup_d0.loss_cls: 0.4905  sup_d0.loss_bbox: 0.5230  sup_d0.loss_iou: 1.0728  sup_d1.loss_cls: 0.4968  sup_d1.loss_bbox: 0.5369  sup_d1.loss_iou: 1.1303  sup_d2.loss_cls: 0.5065  sup_d2.loss_bbox: 0.5472  sup_d2.loss_iou: 1.0665  sup_d3.loss_cls: 0.5159  sup_d3.loss_bbox: 0.6124  sup_d3.loss_iou: 1.1034  sup_d4.loss_cls: 0.5252  sup_d4.loss_bbox: 0.7431  sup_d4.loss_iou: 1.2002  mixup_unsup_loss_cls: 0.0439  mixup_unsup_loss_bbox: 0.2555  mixup_unsup_loss_iou: 0.3621  mixup_unsup_d0.loss_cls: 0.0457  mixup_unsup_d0.loss_bbox: 0.2347  mixup_unsup_d0.loss_iou: 0.3626  mixup_unsup_d1.loss_cls: 0.0440  mixup_unsup_d1.loss_bbox: 0.2362  mixup_unsup_d1.loss_iou: 0.3586  mixup_unsup_d2.loss_cls: 0.0503  mixup_unsup_d2.loss_bbox: 0.2499  mixup_unsup_d2.loss_iou: 0.3689  mixup_unsup_d3.loss_cls: 0.0427  mixup_unsup_d3.loss_bbox: 0.2426  mixup_unsup_d3.loss_iou: 0.3622  mixup_unsup_d4.loss_cls: 0.0430  mixup_unsup_d4.loss_bbox: 0.2579  mixup_unsup_d4.loss_iou: 0.3603  mosaic_unsup_loss_cls: 0.0094  mosaic_unsup_loss_bbox: 1.6980  mosaic_unsup_loss_iou: 2.5490  mosaic_unsup_d0.loss_cls: 0.0122  mosaic_unsup_d0.loss_bbox: 1.6980  mosaic_unsup_d0.loss_iou: 2.5503  mosaic_unsup_d1.loss_cls: 0.0101  mosaic_unsup_d1.loss_bbox: 1.6991  mosaic_unsup_d1.loss_iou: 2.5516  mosaic_unsup_d2.loss_cls: 0.0101  mosaic_unsup_d2.loss_bbox: 1.6945  mosaic_unsup_d2.loss_iou: 2.5493  mosaic_unsup_d3.loss_cls: 0.0100  mosaic_unsup_d3.loss_bbox: 1.6950  mosaic_unsup_d3.loss_iou: 2.5541  mosaic_unsup_d4.loss_cls: 0.0080  mosaic_unsup_d4.loss_bbox: 1.6962  mosaic_unsup_d4.loss_iou: 2.5541
2025/06/23 23:17:54 - mmengine - INFO - Iter(train) [  5100/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:38:24  time: 0.7647  data_time: 0.0230  memory: 9695  grad_norm: 798.4469  loss: 50.7252  sup_loss_cls: 0.7532  sup_loss_bbox: 0.6890  sup_loss_iou: 1.3327  sup_d0.loss_cls: 0.7564  sup_d0.loss_bbox: 0.5796  sup_d0.loss_iou: 1.2384  sup_d1.loss_cls: 0.8125  sup_d1.loss_bbox: 0.7085  sup_d1.loss_iou: 1.4686  sup_d2.loss_cls: 0.7367  sup_d2.loss_bbox: 0.6648  sup_d2.loss_iou: 1.3873  sup_d3.loss_cls: 0.7453  sup_d3.loss_bbox: 0.6604  sup_d3.loss_iou: 1.3048  sup_d4.loss_cls: 0.7408  sup_d4.loss_bbox: 0.6971  sup_d4.loss_iou: 1.3475  mixup_unsup_loss_cls: 0.0532  mixup_unsup_loss_bbox: 0.5551  mixup_unsup_loss_iou: 0.9037  mixup_unsup_d0.loss_cls: 0.0488  mixup_unsup_d0.loss_bbox: 0.5550  mixup_unsup_d0.loss_iou: 0.9062  mixup_unsup_d1.loss_cls: 0.0442  mixup_unsup_d1.loss_bbox: 0.5323  mixup_unsup_d1.loss_iou: 0.9060  mixup_unsup_d2.loss_cls: 0.0465  mixup_unsup_d2.loss_bbox: 0.5366  mixup_unsup_d2.loss_iou: 0.9046  mixup_unsup_d3.loss_cls: 0.0572  mixup_unsup_d3.loss_bbox: 0.5351  mixup_unsup_d3.loss_iou: 0.9022  mixup_unsup_d4.loss_cls: 0.0622  mixup_unsup_d4.loss_bbox: 0.5535  mixup_unsup_d4.loss_iou: 0.9032  mosaic_unsup_loss_cls: 0.0073  mosaic_unsup_loss_bbox: 1.5676  mosaic_unsup_loss_iou: 2.6103  mosaic_unsup_d0.loss_cls: 0.0087  mosaic_unsup_d0.loss_bbox: 1.5735  mosaic_unsup_d0.loss_iou: 2.6077  mosaic_unsup_d1.loss_cls: 0.0106  mosaic_unsup_d1.loss_bbox: 1.5653  mosaic_unsup_d1.loss_iou: 2.5907  mosaic_unsup_d2.loss_cls: 0.0081  mosaic_unsup_d2.loss_bbox: 1.5639  mosaic_unsup_d2.loss_iou: 2.5989  mosaic_unsup_d3.loss_cls: 0.0097  mosaic_unsup_d3.loss_bbox: 1.5703  mosaic_unsup_d3.loss_iou: 2.6113  mosaic_unsup_d4.loss_cls: 0.0068  mosaic_unsup_d4.loss_bbox: 1.5684  mosaic_unsup_d4.loss_iou: 2.6168
2025/06/23 23:18:31 - mmengine - INFO - Iter(train) [  5150/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:36:07  time: 0.7485  data_time: 0.0233  memory: 9619  grad_norm: 392.0025  loss: 45.1678  sup_loss_cls: 0.5606  sup_loss_bbox: 0.6173  sup_loss_iou: 1.2244  sup_d0.loss_cls: 0.5518  sup_d0.loss_bbox: 0.7352  sup_d0.loss_iou: 1.3602  sup_d1.loss_cls: 0.5680  sup_d1.loss_bbox: 0.6359  sup_d1.loss_iou: 1.3118  sup_d2.loss_cls: 0.5845  sup_d2.loss_bbox: 0.5990  sup_d2.loss_iou: 1.1948  sup_d3.loss_cls: 0.5402  sup_d3.loss_bbox: 0.5584  sup_d3.loss_iou: 1.2704  sup_d4.loss_cls: 0.5419  sup_d4.loss_bbox: 0.5616  sup_d4.loss_iou: 1.1884  mixup_unsup_loss_cls: 0.0132  mixup_unsup_loss_bbox: 0.4211  mixup_unsup_loss_iou: 0.7494  mixup_unsup_d0.loss_cls: 0.0309  mixup_unsup_d0.loss_bbox: 0.4190  mixup_unsup_d0.loss_iou: 0.7417  mixup_unsup_d1.loss_cls: 0.0209  mixup_unsup_d1.loss_bbox: 0.4150  mixup_unsup_d1.loss_iou: 0.7487  mixup_unsup_d2.loss_cls: 0.0045  mixup_unsup_d2.loss_bbox: 0.4147  mixup_unsup_d2.loss_iou: 0.7554  mixup_unsup_d3.loss_cls: 0.0204  mixup_unsup_d3.loss_bbox: 0.4237  mixup_unsup_d3.loss_iou: 0.7509  mixup_unsup_d4.loss_cls: 0.0172  mixup_unsup_d4.loss_bbox: 0.4187  mixup_unsup_d4.loss_iou: 0.7503  mosaic_unsup_loss_cls: 0.0086  mosaic_unsup_loss_bbox: 1.4056  mosaic_unsup_loss_iou: 2.4859  mosaic_unsup_d0.loss_cls: 0.0086  mosaic_unsup_d0.loss_bbox: 1.4183  mosaic_unsup_d0.loss_iou: 2.4971  mosaic_unsup_d1.loss_cls: 0.0111  mosaic_unsup_d1.loss_bbox: 1.4084  mosaic_unsup_d1.loss_iou: 2.4798  mosaic_unsup_d2.loss_cls: 0.0083  mosaic_unsup_d2.loss_bbox: 1.4152  mosaic_unsup_d2.loss_iou: 2.4839  mosaic_unsup_d3.loss_cls: 0.0084  mosaic_unsup_d3.loss_bbox: 1.4089  mosaic_unsup_d3.loss_iou: 2.4911  mosaic_unsup_d4.loss_cls: 0.0073  mosaic_unsup_d4.loss_bbox: 1.4061  mosaic_unsup_d4.loss_iou: 2.4951
2025/06/23 23:19:09 - mmengine - INFO - Iter(train) [  5200/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:34:06  time: 0.7551  data_time: 0.0234  memory: 9887  grad_norm: 393.6540  loss: 42.5256  sup_loss_cls: 0.5974  sup_loss_bbox: 0.6217  sup_loss_iou: 1.1615  sup_d0.loss_cls: 0.4730  sup_d0.loss_bbox: 0.4399  sup_d0.loss_iou: 1.0327  sup_d1.loss_cls: 0.5354  sup_d1.loss_bbox: 0.4637  sup_d1.loss_iou: 1.1271  sup_d2.loss_cls: 0.5883  sup_d2.loss_bbox: 0.4578  sup_d2.loss_iou: 1.0301  sup_d3.loss_cls: 0.5309  sup_d3.loss_bbox: 0.5185  sup_d3.loss_iou: 1.1046  sup_d4.loss_cls: 0.5568  sup_d4.loss_bbox: 0.5000  sup_d4.loss_iou: 1.0541  mixup_unsup_loss_cls: 0.0513  mixup_unsup_loss_bbox: 0.3181  mixup_unsup_loss_iou: 0.4178  mixup_unsup_d0.loss_cls: 0.0709  mixup_unsup_d0.loss_bbox: 0.2849  mixup_unsup_d0.loss_iou: 0.4213  mixup_unsup_d1.loss_cls: 0.0602  mixup_unsup_d1.loss_bbox: 0.2850  mixup_unsup_d1.loss_iou: 0.4186  mixup_unsup_d2.loss_cls: 0.0507  mixup_unsup_d2.loss_bbox: 0.2821  mixup_unsup_d2.loss_iou: 0.4135  mixup_unsup_d3.loss_cls: 0.0588  mixup_unsup_d3.loss_bbox: 0.2897  mixup_unsup_d3.loss_iou: 0.4192  mixup_unsup_d4.loss_cls: 0.0553  mixup_unsup_d4.loss_bbox: 0.2978  mixup_unsup_d4.loss_iou: 0.4204  mosaic_unsup_loss_cls: 0.0049  mosaic_unsup_loss_bbox: 1.6985  mosaic_unsup_loss_iou: 2.4869  mosaic_unsup_d0.loss_cls: 0.0064  mosaic_unsup_d0.loss_bbox: 1.6874  mosaic_unsup_d0.loss_iou: 2.4901  mosaic_unsup_d1.loss_cls: 0.0065  mosaic_unsup_d1.loss_bbox: 1.6865  mosaic_unsup_d1.loss_iou: 2.4866  mosaic_unsup_d2.loss_cls: 0.0054  mosaic_unsup_d2.loss_bbox: 1.7175  mosaic_unsup_d2.loss_iou: 2.4686  mosaic_unsup_d3.loss_cls: 0.0047  mosaic_unsup_d3.loss_bbox: 1.6967  mosaic_unsup_d3.loss_iou: 2.4875  mosaic_unsup_d4.loss_cls: 0.0047  mosaic_unsup_d4.loss_bbox: 1.6926  mosaic_unsup_d4.loss_iou: 2.4850
2025/06/23 23:19:46 - mmengine - INFO - Iter(train) [  5250/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:31:17  time: 0.7324  data_time: 0.0228  memory: 9627  grad_norm: 845.3657  loss: 41.3413  sup_loss_cls: 0.7223  sup_loss_bbox: 0.6386  sup_loss_iou: 1.2466  sup_d0.loss_cls: 0.6358  sup_d0.loss_bbox: 0.6640  sup_d0.loss_iou: 1.2701  sup_d1.loss_cls: 0.6347  sup_d1.loss_bbox: 0.5604  sup_d1.loss_iou: 1.1978  sup_d2.loss_cls: 0.6793  sup_d2.loss_bbox: 0.5076  sup_d2.loss_iou: 1.1063  sup_d3.loss_cls: 0.6753  sup_d3.loss_bbox: 0.5218  sup_d3.loss_iou: 1.1367  sup_d4.loss_cls: 0.6426  sup_d4.loss_bbox: 0.5819  sup_d4.loss_iou: 1.2383  mixup_unsup_loss_cls: 0.0078  mixup_unsup_loss_bbox: 0.1249  mixup_unsup_loss_iou: 0.2748  mixup_unsup_d0.loss_cls: 0.0265  mixup_unsup_d0.loss_bbox: 0.1265  mixup_unsup_d0.loss_iou: 0.2779  mixup_unsup_d1.loss_cls: 0.0167  mixup_unsup_d1.loss_bbox: 0.1248  mixup_unsup_d1.loss_iou: 0.2739  mixup_unsup_d2.loss_cls: 0.0149  mixup_unsup_d2.loss_bbox: 0.1220  mixup_unsup_d2.loss_iou: 0.2662  mixup_unsup_d3.loss_cls: 0.0140  mixup_unsup_d3.loss_bbox: 0.1303  mixup_unsup_d3.loss_iou: 0.2755  mixup_unsup_d4.loss_cls: 0.0283  mixup_unsup_d4.loss_bbox: 0.1277  mixup_unsup_d4.loss_iou: 0.2746  mosaic_unsup_loss_cls: 0.0328  mosaic_unsup_loss_bbox: 1.4723  mosaic_unsup_loss_iou: 2.5009  mosaic_unsup_d0.loss_cls: 0.0284  mosaic_unsup_d0.loss_bbox: 1.4745  mosaic_unsup_d0.loss_iou: 2.5098  mosaic_unsup_d1.loss_cls: 0.0346  mosaic_unsup_d1.loss_bbox: 1.4553  mosaic_unsup_d1.loss_iou: 2.5121  mosaic_unsup_d2.loss_cls: 0.0495  mosaic_unsup_d2.loss_bbox: 1.5056  mosaic_unsup_d2.loss_iou: 2.5297  mosaic_unsup_d3.loss_cls: 0.0239  mosaic_unsup_d3.loss_bbox: 1.5108  mosaic_unsup_d3.loss_iou: 2.4965  mosaic_unsup_d4.loss_cls: 0.0324  mosaic_unsup_d4.loss_bbox: 1.5036  mosaic_unsup_d4.loss_iou: 2.5008
2025/06/23 23:20:24 - mmengine - INFO - Iter(train) [  5300/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:29:40  time: 0.7644  data_time: 0.0228  memory: 9886  grad_norm: 525.1467  loss: 50.5414  sup_loss_cls: 0.6546  sup_loss_bbox: 0.6606  sup_loss_iou: 1.2300  sup_d0.loss_cls: 0.6471  sup_d0.loss_bbox: 0.6658  sup_d0.loss_iou: 1.3151  sup_d1.loss_cls: 0.6349  sup_d1.loss_bbox: 0.5535  sup_d1.loss_iou: 1.1248  sup_d2.loss_cls: 0.6641  sup_d2.loss_bbox: 0.6101  sup_d2.loss_iou: 1.1617  sup_d3.loss_cls: 0.6690  sup_d3.loss_bbox: 0.6710  sup_d3.loss_iou: 1.3146  sup_d4.loss_cls: 0.6669  sup_d4.loss_bbox: 0.6548  sup_d4.loss_iou: 1.2444  mixup_unsup_loss_cls: 0.1169  mixup_unsup_loss_bbox: 0.4369  mixup_unsup_loss_iou: 0.7870  mixup_unsup_d0.loss_cls: 0.1337  mixup_unsup_d0.loss_bbox: 0.4156  mixup_unsup_d0.loss_iou: 0.7954  mixup_unsup_d1.loss_cls: 0.1418  mixup_unsup_d1.loss_bbox: 0.4312  mixup_unsup_d1.loss_iou: 0.7962  mixup_unsup_d2.loss_cls: 0.1112  mixup_unsup_d2.loss_bbox: 0.4694  mixup_unsup_d2.loss_iou: 0.8046  mixup_unsup_d3.loss_cls: 0.1115  mixup_unsup_d3.loss_bbox: 0.4829  mixup_unsup_d3.loss_iou: 0.8088  mixup_unsup_d4.loss_cls: 0.1028  mixup_unsup_d4.loss_bbox: 0.4684  mixup_unsup_d4.loss_iou: 0.7996  mosaic_unsup_loss_cls: 0.0486  mosaic_unsup_loss_bbox: 1.7567  mosaic_unsup_loss_iou: 2.7624  mosaic_unsup_d0.loss_cls: 0.0304  mosaic_unsup_d0.loss_bbox: 1.7155  mosaic_unsup_d0.loss_iou: 2.7745  mosaic_unsup_d1.loss_cls: 0.0423  mosaic_unsup_d1.loss_bbox: 1.7102  mosaic_unsup_d1.loss_iou: 2.7751  mosaic_unsup_d2.loss_cls: 0.0386  mosaic_unsup_d2.loss_bbox: 1.7064  mosaic_unsup_d2.loss_iou: 2.7866  mosaic_unsup_d3.loss_cls: 0.0355  mosaic_unsup_d3.loss_bbox: 1.7049  mosaic_unsup_d3.loss_iou: 2.7787  mosaic_unsup_d4.loss_cls: 0.0325  mosaic_unsup_d4.loss_bbox: 1.7113  mosaic_unsup_d4.loss_iou: 2.7746
2025/06/23 23:21:00 - mmengine - INFO - Iter(train) [  5350/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:26:58  time: 0.7339  data_time: 0.0234  memory: 9885  grad_norm: 504.7047  loss: 43.4759  sup_loss_cls: 0.5898  sup_loss_bbox: 0.5859  sup_loss_iou: 1.0815  sup_d0.loss_cls: 0.5243  sup_d0.loss_bbox: 0.5444  sup_d0.loss_iou: 1.1569  sup_d1.loss_cls: 0.5532  sup_d1.loss_bbox: 0.4893  sup_d1.loss_iou: 1.0700  sup_d2.loss_cls: 0.5927  sup_d2.loss_bbox: 0.4783  sup_d2.loss_iou: 1.0341  sup_d3.loss_cls: 0.5550  sup_d3.loss_bbox: 0.4735  sup_d3.loss_iou: 1.0741  sup_d4.loss_cls: 0.5411  sup_d4.loss_bbox: 0.4834  sup_d4.loss_iou: 1.1201  mixup_unsup_loss_cls: 0.0729  mixup_unsup_loss_bbox: 0.2834  mixup_unsup_loss_iou: 0.5395  mixup_unsup_d0.loss_cls: 0.0876  mixup_unsup_d0.loss_bbox: 0.2530  mixup_unsup_d0.loss_iou: 0.5381  mixup_unsup_d1.loss_cls: 0.0657  mixup_unsup_d1.loss_bbox: 0.2550  mixup_unsup_d1.loss_iou: 0.5453  mixup_unsup_d2.loss_cls: 0.0663  mixup_unsup_d2.loss_bbox: 0.2573  mixup_unsup_d2.loss_iou: 0.5471  mixup_unsup_d3.loss_cls: 0.0909  mixup_unsup_d3.loss_bbox: 0.2862  mixup_unsup_d3.loss_iou: 0.5443  mixup_unsup_d4.loss_cls: 0.0987  mixup_unsup_d4.loss_bbox: 0.2963  mixup_unsup_d4.loss_iou: 0.5380  mosaic_unsup_loss_cls: 0.0133  mosaic_unsup_loss_bbox: 1.5951  mosaic_unsup_loss_iou: 2.5855  mosaic_unsup_d0.loss_cls: 0.0159  mosaic_unsup_d0.loss_bbox: 1.5945  mosaic_unsup_d0.loss_iou: 2.5835  mosaic_unsup_d1.loss_cls: 0.0156  mosaic_unsup_d1.loss_bbox: 1.5992  mosaic_unsup_d1.loss_iou: 2.5863  mosaic_unsup_d2.loss_cls: 0.0165  mosaic_unsup_d2.loss_bbox: 1.5918  mosaic_unsup_d2.loss_iou: 2.5878  mosaic_unsup_d3.loss_cls: 0.0153  mosaic_unsup_d3.loss_bbox: 1.5871  mosaic_unsup_d3.loss_iou: 2.5839  mosaic_unsup_d4.loss_cls: 0.0132  mosaic_unsup_d4.loss_bbox: 1.5903  mosaic_unsup_d4.loss_iou: 2.5879
2025/06/23 23:21:38 - mmengine - INFO - Iter(train) [  5400/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:24:59  time: 0.7529  data_time: 0.0223  memory: 9885  grad_norm: 696.6827  loss: 41.9271  sup_loss_cls: 0.6021  sup_loss_bbox: 0.6296  sup_loss_iou: 1.1719  sup_d0.loss_cls: 0.5703  sup_d0.loss_bbox: 0.4877  sup_d0.loss_iou: 1.0729  sup_d1.loss_cls: 0.6164  sup_d1.loss_bbox: 0.5185  sup_d1.loss_iou: 1.1230  sup_d2.loss_cls: 0.6391  sup_d2.loss_bbox: 0.5618  sup_d2.loss_iou: 1.1795  sup_d3.loss_cls: 0.6124  sup_d3.loss_bbox: 0.4557  sup_d3.loss_iou: 1.1014  sup_d4.loss_cls: 0.6053  sup_d4.loss_bbox: 0.4993  sup_d4.loss_iou: 1.0960  mixup_unsup_loss_cls: 0.0009  mixup_unsup_loss_bbox: 0.1375  mixup_unsup_loss_iou: 0.2761  mixup_unsup_d0.loss_cls: 0.0012  mixup_unsup_d0.loss_bbox: 0.1386  mixup_unsup_d0.loss_iou: 0.2769  mixup_unsup_d1.loss_cls: 0.0014  mixup_unsup_d1.loss_bbox: 0.1394  mixup_unsup_d1.loss_iou: 0.2782  mixup_unsup_d2.loss_cls: 0.0013  mixup_unsup_d2.loss_bbox: 0.1386  mixup_unsup_d2.loss_iou: 0.2772  mixup_unsup_d3.loss_cls: 0.0010  mixup_unsup_d3.loss_bbox: 0.1393  mixup_unsup_d3.loss_iou: 0.2771  mixup_unsup_d4.loss_cls: 0.0010  mixup_unsup_d4.loss_bbox: 0.1404  mixup_unsup_d4.loss_iou: 0.2779  mosaic_unsup_loss_cls: 0.0212  mosaic_unsup_loss_bbox: 1.5905  mosaic_unsup_loss_iou: 2.7187  mosaic_unsup_d0.loss_cls: 0.0217  mosaic_unsup_d0.loss_bbox: 1.5875  mosaic_unsup_d0.loss_iou: 2.7024  mosaic_unsup_d1.loss_cls: 0.0214  mosaic_unsup_d1.loss_bbox: 1.5859  mosaic_unsup_d1.loss_iou: 2.7045  mosaic_unsup_d2.loss_cls: 0.0222  mosaic_unsup_d2.loss_bbox: 1.5816  mosaic_unsup_d2.loss_iou: 2.7175  mosaic_unsup_d3.loss_cls: 0.0202  mosaic_unsup_d3.loss_bbox: 1.5758  mosaic_unsup_d3.loss_iou: 2.7074  mosaic_unsup_d4.loss_cls: 0.0131  mosaic_unsup_d4.loss_bbox: 1.5706  mosaic_unsup_d4.loss_iou: 2.7178
2025/06/23 23:22:16 - mmengine - INFO - Iter(train) [  5450/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:23:06  time: 0.7548  data_time: 0.0232  memory: 9883  grad_norm: 961.4042  loss: 41.6120  sup_loss_cls: 0.6358  sup_loss_bbox: 0.5761  sup_loss_iou: 1.1621  sup_d0.loss_cls: 0.6339  sup_d0.loss_bbox: 0.4843  sup_d0.loss_iou: 1.1865  sup_d1.loss_cls: 0.6525  sup_d1.loss_bbox: 0.5129  sup_d1.loss_iou: 1.1994  sup_d2.loss_cls: 0.7157  sup_d2.loss_bbox: 0.5849  sup_d2.loss_iou: 1.2564  sup_d3.loss_cls: 0.6355  sup_d3.loss_bbox: 0.5071  sup_d3.loss_iou: 1.1684  sup_d4.loss_cls: 0.6588  sup_d4.loss_bbox: 0.5685  sup_d4.loss_iou: 1.2701  mixup_unsup_loss_cls: 0.0139  mixup_unsup_loss_bbox: 0.0611  mixup_unsup_loss_iou: 0.1297  mixup_unsup_d0.loss_cls: 0.0088  mixup_unsup_d0.loss_bbox: 0.0579  mixup_unsup_d0.loss_iou: 0.1264  mixup_unsup_d1.loss_cls: 0.0161  mixup_unsup_d1.loss_bbox: 0.0577  mixup_unsup_d1.loss_iou: 0.1252  mixup_unsup_d2.loss_cls: 0.0098  mixup_unsup_d2.loss_bbox: 0.0579  mixup_unsup_d2.loss_iou: 0.1296  mixup_unsup_d3.loss_cls: 0.0078  mixup_unsup_d3.loss_bbox: 0.0589  mixup_unsup_d3.loss_iou: 0.1279  mixup_unsup_d4.loss_cls: 0.0086  mixup_unsup_d4.loss_bbox: 0.0637  mixup_unsup_d4.loss_iou: 0.1305  mosaic_unsup_loss_cls: 0.0065  mosaic_unsup_loss_bbox: 1.7740  mosaic_unsup_loss_iou: 2.5478  mosaic_unsup_d0.loss_cls: 0.0088  mosaic_unsup_d0.loss_bbox: 1.7846  mosaic_unsup_d0.loss_iou: 2.5447  mosaic_unsup_d1.loss_cls: 0.0108  mosaic_unsup_d1.loss_bbox: 1.7844  mosaic_unsup_d1.loss_iou: 2.5420  mosaic_unsup_d2.loss_cls: 0.0121  mosaic_unsup_d2.loss_bbox: 1.7813  mosaic_unsup_d2.loss_iou: 2.5451  mosaic_unsup_d3.loss_cls: 0.0071  mosaic_unsup_d3.loss_bbox: 1.7854  mosaic_unsup_d3.loss_iou: 2.5442  mosaic_unsup_d4.loss_cls: 0.0080  mosaic_unsup_d4.loss_bbox: 1.7780  mosaic_unsup_d4.loss_iou: 2.5466
2025/06/23 23:22:53 - mmengine - INFO - Iter(train) [  5500/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:21:12  time: 0.7536  data_time: 0.0229  memory: 9885  grad_norm: 1247.4475  loss: 45.6973  sup_loss_cls: 0.7393  sup_loss_bbox: 0.6583  sup_loss_iou: 1.1738  sup_d0.loss_cls: 0.7047  sup_d0.loss_bbox: 0.5806  sup_d0.loss_iou: 1.1237  sup_d1.loss_cls: 0.7279  sup_d1.loss_bbox: 0.6449  sup_d1.loss_iou: 1.2056  sup_d2.loss_cls: 0.8177  sup_d2.loss_bbox: 0.7148  sup_d2.loss_iou: 1.1536  sup_d3.loss_cls: 0.8652  sup_d3.loss_bbox: 0.6770  sup_d3.loss_iou: 1.1949  sup_d4.loss_cls: 0.7996  sup_d4.loss_bbox: 0.7845  sup_d4.loss_iou: 1.2594  mixup_unsup_loss_cls: 0.1003  mixup_unsup_loss_bbox: 0.3994  mixup_unsup_loss_iou: 0.7358  mixup_unsup_d0.loss_cls: 0.0936  mixup_unsup_d0.loss_bbox: 0.3777  mixup_unsup_d0.loss_iou: 0.7349  mixup_unsup_d1.loss_cls: 0.0859  mixup_unsup_d1.loss_bbox: 0.3779  mixup_unsup_d1.loss_iou: 0.7405  mixup_unsup_d2.loss_cls: 0.0765  mixup_unsup_d2.loss_bbox: 0.4008  mixup_unsup_d2.loss_iou: 0.7450  mixup_unsup_d3.loss_cls: 0.0819  mixup_unsup_d3.loss_bbox: 0.4174  mixup_unsup_d3.loss_iou: 0.7442  mixup_unsup_d4.loss_cls: 0.1048  mixup_unsup_d4.loss_bbox: 0.4439  mixup_unsup_d4.loss_iou: 0.7507  mosaic_unsup_loss_cls: 0.0091  mosaic_unsup_loss_bbox: 1.3565  mosaic_unsup_loss_iou: 2.3804  mosaic_unsup_d0.loss_cls: 0.0105  mosaic_unsup_d0.loss_bbox: 1.3608  mosaic_unsup_d0.loss_iou: 2.3713  mosaic_unsup_d1.loss_cls: 0.0110  mosaic_unsup_d1.loss_bbox: 1.3543  mosaic_unsup_d1.loss_iou: 2.3751  mosaic_unsup_d2.loss_cls: 0.0115  mosaic_unsup_d2.loss_bbox: 1.3525  mosaic_unsup_d2.loss_iou: 2.3764  mosaic_unsup_d3.loss_cls: 0.0080  mosaic_unsup_d3.loss_bbox: 1.3710  mosaic_unsup_d3.loss_iou: 2.3717  mosaic_unsup_d4.loss_cls: 0.0090  mosaic_unsup_d4.loss_bbox: 1.3565  mosaic_unsup_d4.loss_iou: 2.3749
2025/06/23 23:23:31 - mmengine - INFO - Iter(train) [  5550/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:19:23  time: 0.7552  data_time: 0.0227  memory: 9880  grad_norm: 1344.5280  loss: 42.5385  sup_loss_cls: 0.6500  sup_loss_bbox: 0.7194  sup_loss_iou: 1.2624  sup_d0.loss_cls: 0.6687  sup_d0.loss_bbox: 0.4986  sup_d0.loss_iou: 1.1495  sup_d1.loss_cls: 0.6908  sup_d1.loss_bbox: 0.5579  sup_d1.loss_iou: 1.2567  sup_d2.loss_cls: 0.7811  sup_d2.loss_bbox: 0.6980  sup_d2.loss_iou: 1.2370  sup_d3.loss_cls: 0.8123  sup_d3.loss_bbox: 0.6036  sup_d3.loss_iou: 1.2725  sup_d4.loss_cls: 0.7255  sup_d4.loss_bbox: 0.6743  sup_d4.loss_iou: 1.3256  mixup_unsup_loss_cls: 0.1359  mixup_unsup_loss_bbox: 0.2566  mixup_unsup_loss_iou: 0.3914  mixup_unsup_d0.loss_cls: 0.1174  mixup_unsup_d0.loss_bbox: 0.2329  mixup_unsup_d0.loss_iou: 0.3913  mixup_unsup_d1.loss_cls: 0.0998  mixup_unsup_d1.loss_bbox: 0.2167  mixup_unsup_d1.loss_iou: 0.3840  mixup_unsup_d2.loss_cls: 0.0902  mixup_unsup_d2.loss_bbox: 0.2251  mixup_unsup_d2.loss_iou: 0.3830  mixup_unsup_d3.loss_cls: 0.1297  mixup_unsup_d3.loss_bbox: 0.2385  mixup_unsup_d3.loss_iou: 0.3910  mixup_unsup_d4.loss_cls: 0.1215  mixup_unsup_d4.loss_bbox: 0.2745  mixup_unsup_d4.loss_iou: 0.3998  mosaic_unsup_loss_cls: 0.0258  mosaic_unsup_loss_bbox: 1.3602  mosaic_unsup_loss_iou: 2.3778  mosaic_unsup_d0.loss_cls: 0.0262  mosaic_unsup_d0.loss_bbox: 1.3623  mosaic_unsup_d0.loss_iou: 2.3557  mosaic_unsup_d1.loss_cls: 0.0231  mosaic_unsup_d1.loss_bbox: 1.3542  mosaic_unsup_d1.loss_iou: 2.3570  mosaic_unsup_d2.loss_cls: 0.0286  mosaic_unsup_d2.loss_bbox: 1.3526  mosaic_unsup_d2.loss_iou: 2.3757  mosaic_unsup_d3.loss_cls: 0.0484  mosaic_unsup_d3.loss_bbox: 1.3422  mosaic_unsup_d3.loss_iou: 2.3399  mosaic_unsup_d4.loss_cls: 0.0270  mosaic_unsup_d4.loss_bbox: 1.3460  mosaic_unsup_d4.loss_iou: 2.3726
2025/06/23 23:24:10 - mmengine - INFO - Iter(train) [  5600/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:18:00  time: 0.7673  data_time: 0.0246  memory: 9886  grad_norm: 1503.9560  loss: 58.8908  sup_loss_cls: 0.9925  sup_loss_bbox: 0.8658  sup_loss_iou: 1.4354  sup_d0.loss_cls: 0.9251  sup_d0.loss_bbox: 0.8209  sup_d0.loss_iou: 1.5330  sup_d1.loss_cls: 0.9996  sup_d1.loss_bbox: 0.8177  sup_d1.loss_iou: 1.5306  sup_d2.loss_cls: 1.0439  sup_d2.loss_bbox: 0.8863  sup_d2.loss_iou: 1.5200  sup_d3.loss_cls: 1.0257  sup_d3.loss_bbox: 0.8646  sup_d3.loss_iou: 1.4721  sup_d4.loss_cls: 1.0144  sup_d4.loss_bbox: 0.9218  sup_d4.loss_iou: 1.4583  mixup_unsup_loss_cls: 0.1435  mixup_unsup_loss_bbox: 0.1875  mixup_unsup_loss_iou: 0.4825  mixup_unsup_d0.loss_cls: 0.0994  mixup_unsup_d0.loss_bbox: 0.1683  mixup_unsup_d0.loss_iou: 0.4601  mixup_unsup_d1.loss_cls: 0.1347  mixup_unsup_d1.loss_bbox: 0.1807  mixup_unsup_d1.loss_iou: 0.4655  mixup_unsup_d2.loss_cls: 0.1443  mixup_unsup_d2.loss_bbox: 0.1914  mixup_unsup_d2.loss_iou: 0.4758  mixup_unsup_d3.loss_cls: 0.1083  mixup_unsup_d3.loss_bbox: 0.1757  mixup_unsup_d3.loss_iou: 0.4579  mixup_unsup_d4.loss_cls: 0.1380  mixup_unsup_d4.loss_bbox: 0.2024  mixup_unsup_d4.loss_iou: 0.4899  mosaic_unsup_loss_cls: 0.7051  mosaic_unsup_loss_bbox: 2.2072  mosaic_unsup_loss_iou: 2.8882  mosaic_unsup_d0.loss_cls: 0.6823  mosaic_unsup_d0.loss_bbox: 2.1428  mosaic_unsup_d0.loss_iou: 2.8895  mosaic_unsup_d1.loss_cls: 0.6179  mosaic_unsup_d1.loss_bbox: 2.1753  mosaic_unsup_d1.loss_iou: 2.8995  mosaic_unsup_d2.loss_cls: 0.5869  mosaic_unsup_d2.loss_bbox: 2.2241  mosaic_unsup_d2.loss_iou: 2.9184  mosaic_unsup_d3.loss_cls: 0.5000  mosaic_unsup_d3.loss_bbox: 2.1197  mosaic_unsup_d3.loss_iou: 2.8618  mosaic_unsup_d4.loss_cls: 0.5872  mosaic_unsup_d4.loss_bbox: 2.1842  mosaic_unsup_d4.loss_iou: 2.8671
2025/06/23 23:24:48 - mmengine - INFO - Iter(train) [  5650/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:16:28  time: 0.7627  data_time: 0.0235  memory: 9884  grad_norm: 640.8272  loss: 52.4737  sup_loss_cls: 0.7742  sup_loss_bbox: 0.5880  sup_loss_iou: 1.1517  sup_d0.loss_cls: 0.7738  sup_d0.loss_bbox: 0.4807  sup_d0.loss_iou: 1.1338  sup_d1.loss_cls: 0.7890  sup_d1.loss_bbox: 0.6124  sup_d1.loss_iou: 1.2886  sup_d2.loss_cls: 0.8227  sup_d2.loss_bbox: 0.7472  sup_d2.loss_iou: 1.3537  sup_d3.loss_cls: 0.8122  sup_d3.loss_bbox: 0.7658  sup_d3.loss_iou: 1.4501  sup_d4.loss_cls: 0.8050  sup_d4.loss_bbox: 0.6986  sup_d4.loss_iou: 1.3253  mixup_unsup_loss_cls: 0.1343  mixup_unsup_loss_bbox: 0.3644  mixup_unsup_loss_iou: 0.7230  mixup_unsup_d0.loss_cls: 0.1350  mixup_unsup_d0.loss_bbox: 0.3471  mixup_unsup_d0.loss_iou: 0.7248  mixup_unsup_d1.loss_cls: 0.1133  mixup_unsup_d1.loss_bbox: 0.3705  mixup_unsup_d1.loss_iou: 0.7319  mixup_unsup_d2.loss_cls: 0.0993  mixup_unsup_d2.loss_bbox: 0.3365  mixup_unsup_d2.loss_iou: 0.7539  mixup_unsup_d3.loss_cls: 0.1002  mixup_unsup_d3.loss_bbox: 0.3589  mixup_unsup_d3.loss_iou: 0.7595  mixup_unsup_d4.loss_cls: 0.1163  mixup_unsup_d4.loss_bbox: 0.3934  mixup_unsup_d4.loss_iou: 0.7621  mosaic_unsup_loss_cls: 0.3228  mosaic_unsup_loss_bbox: 1.8532  mosaic_unsup_loss_iou: 2.6784  mosaic_unsup_d0.loss_cls: 0.3528  mosaic_unsup_d0.loss_bbox: 1.8581  mosaic_unsup_d0.loss_iou: 2.6465  mosaic_unsup_d1.loss_cls: 0.3053  mosaic_unsup_d1.loss_bbox: 1.8842  mosaic_unsup_d1.loss_iou: 2.6634  mosaic_unsup_d2.loss_cls: 0.2806  mosaic_unsup_d2.loss_bbox: 1.7690  mosaic_unsup_d2.loss_iou: 2.6839  mosaic_unsup_d3.loss_cls: 0.3107  mosaic_unsup_d3.loss_bbox: 1.7315  mosaic_unsup_d3.loss_iou: 2.6803  mosaic_unsup_d4.loss_cls: 0.3089  mosaic_unsup_d4.loss_bbox: 1.7746  mosaic_unsup_d4.loss_iou: 2.6723
2025/06/23 23:25:26 - mmengine - INFO - Iter(train) [  5700/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:14:47  time: 0.7577  data_time: 0.0233  memory: 9885  grad_norm: 753.2731  loss: 51.1814  sup_loss_cls: 0.8812  sup_loss_bbox: 0.5979  sup_loss_iou: 1.2346  sup_d0.loss_cls: 0.8988  sup_d0.loss_bbox: 0.5500  sup_d0.loss_iou: 1.2948  sup_d1.loss_cls: 0.8556  sup_d1.loss_bbox: 0.5287  sup_d1.loss_iou: 1.3529  sup_d2.loss_cls: 0.8450  sup_d2.loss_bbox: 0.6050  sup_d2.loss_iou: 1.2423  sup_d3.loss_cls: 0.8262  sup_d3.loss_bbox: 0.6683  sup_d3.loss_iou: 1.3635  sup_d4.loss_cls: 0.8331  sup_d4.loss_bbox: 0.6578  sup_d4.loss_iou: 1.3046  mixup_unsup_loss_cls: 0.0097  mixup_unsup_loss_bbox: 0.2750  mixup_unsup_loss_iou: 0.5328  mixup_unsup_d0.loss_cls: 0.0092  mixup_unsup_d0.loss_bbox: 0.2861  mixup_unsup_d0.loss_iou: 0.5383  mixup_unsup_d1.loss_cls: 0.0116  mixup_unsup_d1.loss_bbox: 0.3038  mixup_unsup_d1.loss_iou: 0.5424  mixup_unsup_d2.loss_cls: 0.0157  mixup_unsup_d2.loss_bbox: 0.2991  mixup_unsup_d2.loss_iou: 0.5445  mixup_unsup_d3.loss_cls: 0.0142  mixup_unsup_d3.loss_bbox: 0.2884  mixup_unsup_d3.loss_iou: 0.5332  mixup_unsup_d4.loss_cls: 0.0134  mixup_unsup_d4.loss_bbox: 0.2943  mixup_unsup_d4.loss_iou: 0.5343  mosaic_unsup_loss_cls: 0.0332  mosaic_unsup_loss_bbox: 2.0267  mosaic_unsup_loss_iou: 2.9324  mosaic_unsup_d0.loss_cls: 0.0296  mosaic_unsup_d0.loss_bbox: 2.0294  mosaic_unsup_d0.loss_iou: 2.8295  mosaic_unsup_d1.loss_cls: 0.0369  mosaic_unsup_d1.loss_bbox: 1.9958  mosaic_unsup_d1.loss_iou: 2.8435  mosaic_unsup_d2.loss_cls: 0.0485  mosaic_unsup_d2.loss_bbox: 1.9894  mosaic_unsup_d2.loss_iou: 2.8787  mosaic_unsup_d3.loss_cls: 0.0506  mosaic_unsup_d3.loss_bbox: 2.0473  mosaic_unsup_d3.loss_iou: 2.8985  mosaic_unsup_d4.loss_cls: 0.0412  mosaic_unsup_d4.loss_bbox: 2.0033  mosaic_unsup_d4.loss_iou: 2.8807
2025/06/23 23:26:04 - mmengine - INFO - Iter(train) [  5750/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:13:35  time: 0.7713  data_time: 0.0231  memory: 9885  grad_norm: 1550.3312  loss: 56.8857  sup_loss_cls: 0.6452  sup_loss_bbox: 0.6883  sup_loss_iou: 1.3241  sup_d0.loss_cls: 0.6404  sup_d0.loss_bbox: 0.5446  sup_d0.loss_iou: 1.1334  sup_d1.loss_cls: 0.6363  sup_d1.loss_bbox: 0.5116  sup_d1.loss_iou: 1.1224  sup_d2.loss_cls: 0.6461  sup_d2.loss_bbox: 0.5963  sup_d2.loss_iou: 1.1486  sup_d3.loss_cls: 0.6450  sup_d3.loss_bbox: 0.5023  sup_d3.loss_iou: 1.1027  sup_d4.loss_cls: 0.6474  sup_d4.loss_bbox: 0.7600  sup_d4.loss_iou: 1.3769  mixup_unsup_loss_cls: 0.1676  mixup_unsup_loss_bbox: 0.5398  mixup_unsup_loss_iou: 1.1617  mixup_unsup_d0.loss_cls: 0.1688  mixup_unsup_d0.loss_bbox: 0.5406  mixup_unsup_d0.loss_iou: 1.1671  mixup_unsup_d1.loss_cls: 0.1859  mixup_unsup_d1.loss_bbox: 0.5908  mixup_unsup_d1.loss_iou: 1.1921  mixup_unsup_d2.loss_cls: 0.1884  mixup_unsup_d2.loss_bbox: 0.5661  mixup_unsup_d2.loss_iou: 1.1723  mixup_unsup_d3.loss_cls: 0.1836  mixup_unsup_d3.loss_bbox: 0.5667  mixup_unsup_d3.loss_iou: 1.1733  mixup_unsup_d4.loss_cls: 0.1758  mixup_unsup_d4.loss_bbox: 0.5588  mixup_unsup_d4.loss_iou: 1.1796  mosaic_unsup_loss_cls: 0.0960  mosaic_unsup_loss_bbox: 2.0524  mosaic_unsup_loss_iou: 2.9663  mosaic_unsup_d0.loss_cls: 0.0869  mosaic_unsup_d0.loss_bbox: 2.0846  mosaic_unsup_d0.loss_iou: 2.9451  mosaic_unsup_d1.loss_cls: 0.1024  mosaic_unsup_d1.loss_bbox: 2.0225  mosaic_unsup_d1.loss_iou: 2.9449  mosaic_unsup_d2.loss_cls: 0.1094  mosaic_unsup_d2.loss_bbox: 2.0619  mosaic_unsup_d2.loss_iou: 2.9602  mosaic_unsup_d3.loss_cls: 0.1142  mosaic_unsup_d3.loss_bbox: 2.1011  mosaic_unsup_d3.loss_iou: 2.9554  mosaic_unsup_d4.loss_cls: 0.1051  mosaic_unsup_d4.loss_bbox: 2.0555  mosaic_unsup_d4.loss_iou: 2.9712
2025/06/23 23:26:43 - mmengine - INFO - Iter(train) [  5800/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:12:16  time: 0.7675  data_time: 0.0231  memory: 9886  grad_norm: 309.2523  loss: 47.6226  sup_loss_cls: 0.5918  sup_loss_bbox: 0.6758  sup_loss_iou: 1.2510  sup_d0.loss_cls: 0.6096  sup_d0.loss_bbox: 0.5408  sup_d0.loss_iou: 1.0895  sup_d1.loss_cls: 0.6661  sup_d1.loss_bbox: 0.5470  sup_d1.loss_iou: 1.1265  sup_d2.loss_cls: 0.6570  sup_d2.loss_bbox: 0.5969  sup_d2.loss_iou: 1.2087  sup_d3.loss_cls: 0.5885  sup_d3.loss_bbox: 0.5176  sup_d3.loss_iou: 1.0772  sup_d4.loss_cls: 0.5808  sup_d4.loss_bbox: 0.7097  sup_d4.loss_iou: 1.2248  mixup_unsup_loss_cls: 0.0602  mixup_unsup_loss_bbox: 0.4566  mixup_unsup_loss_iou: 0.8889  mixup_unsup_d0.loss_cls: 0.0556  mixup_unsup_d0.loss_bbox: 0.4462  mixup_unsup_d0.loss_iou: 0.8779  mixup_unsup_d1.loss_cls: 0.0460  mixup_unsup_d1.loss_bbox: 0.4876  mixup_unsup_d1.loss_iou: 0.8780  mixup_unsup_d2.loss_cls: 0.0517  mixup_unsup_d2.loss_bbox: 0.4697  mixup_unsup_d2.loss_iou: 0.8795  mixup_unsup_d3.loss_cls: 0.0617  mixup_unsup_d3.loss_bbox: 0.4773  mixup_unsup_d3.loss_iou: 0.8888  mixup_unsup_d4.loss_cls: 0.0661  mixup_unsup_d4.loss_bbox: 0.4662  mixup_unsup_d4.loss_iou: 0.8914  mosaic_unsup_loss_cls: 0.0861  mosaic_unsup_loss_bbox: 1.4809  mosaic_unsup_loss_iou: 2.6098  mosaic_unsup_d0.loss_cls: 0.0783  mosaic_unsup_d0.loss_bbox: 1.4852  mosaic_unsup_d0.loss_iou: 2.5975  mosaic_unsup_d1.loss_cls: 0.0727  mosaic_unsup_d1.loss_bbox: 1.4067  mosaic_unsup_d1.loss_iou: 2.5691  mosaic_unsup_d2.loss_cls: 0.0842  mosaic_unsup_d2.loss_bbox: 1.4654  mosaic_unsup_d2.loss_iou: 2.5887  mosaic_unsup_d3.loss_cls: 0.0970  mosaic_unsup_d3.loss_bbox: 1.4894  mosaic_unsup_d3.loss_iou: 2.5985  mosaic_unsup_d4.loss_cls: 0.0953  mosaic_unsup_d4.loss_bbox: 1.4944  mosaic_unsup_d4.loss_iou: 2.6148
2025/06/23 23:27:20 - mmengine - INFO - Iter(train) [  5850/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:10:36  time: 0.7568  data_time: 0.0242  memory: 9703  grad_norm: 1326.7699  loss: 47.7629  sup_loss_cls: 0.8711  sup_loss_bbox: 0.7416  sup_loss_iou: 1.3921  sup_d0.loss_cls: 0.8045  sup_d0.loss_bbox: 0.7047  sup_d0.loss_iou: 1.3220  sup_d1.loss_cls: 0.8341  sup_d1.loss_bbox: 0.6953  sup_d1.loss_iou: 1.2988  sup_d2.loss_cls: 0.7971  sup_d2.loss_bbox: 0.6693  sup_d2.loss_iou: 1.2253  sup_d3.loss_cls: 0.8174  sup_d3.loss_bbox: 0.7267  sup_d3.loss_iou: 1.4434  sup_d4.loss_cls: 0.8264  sup_d4.loss_bbox: 0.7907  sup_d4.loss_iou: 1.4158  mixup_unsup_loss_cls: 0.0788  mixup_unsup_loss_bbox: 0.4022  mixup_unsup_loss_iou: 0.6226  mixup_unsup_d0.loss_cls: 0.0997  mixup_unsup_d0.loss_bbox: 0.3506  mixup_unsup_d0.loss_iou: 0.6228  mixup_unsup_d1.loss_cls: 0.1048  mixup_unsup_d1.loss_bbox: 0.3611  mixup_unsup_d1.loss_iou: 0.6187  mixup_unsup_d2.loss_cls: 0.1005  mixup_unsup_d2.loss_bbox: 0.3642  mixup_unsup_d2.loss_iou: 0.6219  mixup_unsup_d3.loss_cls: 0.1088  mixup_unsup_d3.loss_bbox: 0.3511  mixup_unsup_d3.loss_iou: 0.6178  mixup_unsup_d4.loss_cls: 0.1015  mixup_unsup_d4.loss_bbox: 0.3736  mixup_unsup_d4.loss_iou: 0.6233  mosaic_unsup_loss_cls: 0.0941  mosaic_unsup_loss_bbox: 1.4062  mosaic_unsup_loss_iou: 2.4588  mosaic_unsup_d0.loss_cls: 0.0964  mosaic_unsup_d0.loss_bbox: 1.4368  mosaic_unsup_d0.loss_iou: 2.4575  mosaic_unsup_d1.loss_cls: 0.0926  mosaic_unsup_d1.loss_bbox: 1.4224  mosaic_unsup_d1.loss_iou: 2.4460  mosaic_unsup_d2.loss_cls: 0.0876  mosaic_unsup_d2.loss_bbox: 1.4035  mosaic_unsup_d2.loss_iou: 2.4570  mosaic_unsup_d3.loss_cls: 0.0992  mosaic_unsup_d3.loss_bbox: 1.4771  mosaic_unsup_d3.loss_iou: 2.4625  mosaic_unsup_d4.loss_cls: 0.1087  mosaic_unsup_d4.loss_bbox: 1.3955  mosaic_unsup_d4.loss_iou: 2.4605
2025/06/23 23:27:59 - mmengine - INFO - Iter(train) [  5900/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:09:17  time: 0.7671  data_time: 0.0239  memory: 9885  grad_norm: 337.0808  loss: 43.8746  sup_loss_cls: 0.5226  sup_loss_bbox: 0.5315  sup_loss_iou: 1.1170  sup_d0.loss_cls: 0.5112  sup_d0.loss_bbox: 0.4863  sup_d0.loss_iou: 1.0599  sup_d1.loss_cls: 0.5216  sup_d1.loss_bbox: 0.6005  sup_d1.loss_iou: 1.2215  sup_d2.loss_cls: 0.4836  sup_d2.loss_bbox: 0.5868  sup_d2.loss_iou: 1.4492  sup_d3.loss_cls: 0.5259  sup_d3.loss_bbox: 0.5214  sup_d3.loss_iou: 1.3268  sup_d4.loss_cls: 0.5437  sup_d4.loss_bbox: 0.4834  sup_d4.loss_iou: 1.1219  mixup_unsup_loss_cls: 0.0439  mixup_unsup_loss_bbox: 0.2401  mixup_unsup_loss_iou: 0.5467  mixup_unsup_d0.loss_cls: 0.0517  mixup_unsup_d0.loss_bbox: 0.2142  mixup_unsup_d0.loss_iou: 0.5326  mixup_unsup_d1.loss_cls: 0.0474  mixup_unsup_d1.loss_bbox: 0.2294  mixup_unsup_d1.loss_iou: 0.5457  mixup_unsup_d2.loss_cls: 0.0445  mixup_unsup_d2.loss_bbox: 0.2289  mixup_unsup_d2.loss_iou: 0.5499  mixup_unsup_d3.loss_cls: 0.0503  mixup_unsup_d3.loss_bbox: 0.2325  mixup_unsup_d3.loss_iou: 0.5556  mixup_unsup_d4.loss_cls: 0.0454  mixup_unsup_d4.loss_bbox: 0.2203  mixup_unsup_d4.loss_iou: 0.5498  mosaic_unsup_loss_cls: 0.1556  mosaic_unsup_loss_bbox: 1.5045  mosaic_unsup_loss_iou: 2.5495  mosaic_unsup_d0.loss_cls: 0.1632  mosaic_unsup_d0.loss_bbox: 1.4976  mosaic_unsup_d0.loss_iou: 2.5507  mosaic_unsup_d1.loss_cls: 0.1493  mosaic_unsup_d1.loss_bbox: 1.5379  mosaic_unsup_d1.loss_iou: 2.5434  mosaic_unsup_d2.loss_cls: 0.1531  mosaic_unsup_d2.loss_bbox: 1.5380  mosaic_unsup_d2.loss_iou: 2.5502  mosaic_unsup_d3.loss_cls: 0.1393  mosaic_unsup_d3.loss_bbox: 1.5554  mosaic_unsup_d3.loss_iou: 2.5683  mosaic_unsup_d4.loss_cls: 0.1339  mosaic_unsup_d4.loss_bbox: 1.4958  mosaic_unsup_d4.loss_iou: 2.5453
2025/06/23 23:28:37 - mmengine - INFO - Iter(train) [  5950/240000]  base_lr: 1.0000e-04 lr: 1.0000e-05  eta: 2 days, 3:08:03  time: 0.7690  data_time: 0.0244  memory: 9702  grad_norm: 290.8157  loss: 46.7990  sup_loss_cls: 0.7428  sup_loss_bbox: 0.7383  sup_loss_iou: 1.3573  sup_d0.loss_cls: 0.7325  sup_d0.loss_bbox: 0.5707  sup_d0.loss_iou: 1.2503  sup_d1.loss_cls: 0.7278  sup_d1.loss_bbox: 0.7416  sup_d1.loss_iou: 1.3273  sup_d2.loss_cls: 0.7294  sup_d2.loss_bbox: 0.6418  sup_d2.loss_iou: 1.3133  sup_d3.loss_cls: 0.7267  sup_d3.loss_bbox: 0.5549  sup_d3.loss_iou: 1.3020  sup_d4.loss_cls: 0.7469  sup_d4.loss_bbox: 0.8192  sup_d4.loss_iou: 1.4508  mixup_unsup_loss_cls: 0.0030  mixup_unsup_loss_bbox: 0.3252  mixup_unsup_loss_iou: 0.5365  mixup_unsup_d0.loss_cls: 0.0032  mixup_unsup_d0.loss_bbox: 0.3219  mixup_unsup_d0.loss_iou: 0.5346  mixup_unsup_d1.loss_cls: 0.0030  mixup_unsup_d1.loss_bbox: 0.3240  mixup_unsup_d1.loss_iou: 0.5359  mixup_unsup_d2.loss_cls: 0.0029  mixup_unsup_d2.loss_bbox: 0.3200  mixup_unsup_d2.loss_iou: 0.5323  mixup_unsup_d3.loss_cls: 0.0027  mixup_unsup_d3.loss_bbox: 0.3260  mixup_unsup_d3.loss_iou: 0.5372  mixup_unsup_d4.loss_cls: 0.0023  mixup_unsup_d4.loss_bbox: 0.3198  mixup_unsup_d4.loss_iou: 0.5352  mosaic_unsup_loss_cls: 0.0213  mosaic_unsup_loss_bbox: 1.6382  mosaic_unsup_loss_iou: 2.5191  mosaic_unsup_d0.loss_cls: 0.0218  mosaic_unsup_d0.loss_bbox: 1.6579  mosaic_unsup_d0.loss_iou: 2.5114  mosaic_unsup_d1.loss_cls: 0.0217  mosaic_unsup_d1.loss_bbox: 1.6559  mosaic_unsup_d1.loss_iou: 2.5099  mosaic_unsup_d2.loss_cls: 0.0202  mosaic_unsup_d2.loss_bbox: 1.6506  mosaic_unsup_d2.loss_iou: 2.5158  mosaic_unsup_d3.loss_cls: 0.0229  mosaic_unsup_d3.loss_bbox: 1.6670  mosaic_unsup_d3.loss_iou: 2.5311  mosaic_unsup_d4.loss_cls: 0.0178  mosaic_unsup_d4.loss_bbox: 1.6590  mosaic_unsup_d4.loss_iou: 2.5180
